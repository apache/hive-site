<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Design Documents on Hive Site</title><link>https://hive.apache.org/development/desingdocs/</link><description>Recent content in Design Documents on Hive Site</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 24 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://hive.apache.org/development/desingdocs/index.xml" rel="self" type="application/rss+xml"/><item><title>Apache Hive : AccessServer Design Proposal</title><link>https://hive.apache.org/development/desingdocs/accessserver-design-proposal/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/accessserver-design-proposal/</guid><description>Apache Hive : AccessServer Design Proposal AccessServer Proposal Author: Carl Steinbach Overview The technical approach described in the this document addresses the following high-level requirements:
Make Apache Hive’s data model and metadata services accessible to users of the Apache Pig dataflow programming language as well as other Hadoop language runtimes. Make it possible for Hive users and users of other Hadoop language runtimes to share data stored in Hive’s HDFS data warehouse.</description></item><item><title>Apache Hive : Binary DataType Proposal</title><link>https://hive.apache.org/development/desingdocs/binary-datatype-proposal/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/binary-datatype-proposal/</guid><description>Apache Hive : Binary DataType Proposal Binary Type in Hive Motivation: Hive is designed to work with big data. Often in such cases, a row in a data might be very wide with hundreds of columns. Sometimes, user is just interested in few of those columns and doesn&amp;rsquo;t want to bother about exact type information for rest of columns. In such cases, he may just declare the types of those columns as binary and Hive will not try to interpret those columns.</description></item><item><title>Apache Hive : Column Statistics in Hive</title><link>https://hive.apache.org/development/desingdocs/column-statistics-in-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/column-statistics-in-hive/</guid><description>Apache Hive : Column Statistics in Hive Apache Hive : Column Statistics in Hive Introduction HiveQL changes Metastore Schema Metastore Thrift API Introduction This document describes changes to a) HiveQL, b) metastore schema, and c) metastore Thrift API to support column level statistics in Hive. Please note that the document doesn’t describe the changes needed to persist histograms in the metastore yet.</description></item><item><title>Apache Hive : Correlation Optimizer</title><link>https://hive.apache.org/development/desingdocs/correlation-optimizer/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/correlation-optimizer/</guid><description>Apache Hive : Correlation Optimizer This page documents Correlation Optimizer. It was originally introduced by HIVE-2206 and based on the idea of YSmart [1]. To turn on this optimizer, you can use &amp;hellip;
set hive.optimize.correlation=true; 1. Overview In Hadoop environments, an SQL query submitted to Hive will be evaluated in distributed systems. Thus, after generating a query operator tree representing the submitted SQL query, Hive needs to determine what operations can be executed in a task which will be evalauted in a single node.</description></item><item><title>Apache Hive : Default Constraint (HIVE-18726)</title><link>https://hive.apache.org/development/desingdocs/default-constraint/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/default-constraint/</guid><description>Apache Hive : Default Constraint (HIVE-18726) Introduction This document proposes the addition of DEFAULT clause to Hive. DEFAULT clause is a domain constraint which lets user specify a value for domain i.e. column to be used in absence of user specified value i.e. in absence of column reference. Note that this does not propose to implement DEFAULT ON NULL like ORACLE which lets user specify DEFAULT value for explicit NULLs.</description></item><item><title>Apache Hive : DEFAULT Keyword (HIVE-19059)</title><link>https://hive.apache.org/development/desingdocs/default-keyword/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/default-keyword/</guid><description>Apache Hive : DEFAULT Keyword (HIVE-19059) Goal We propose to add DEFAULT keyword in INSERT INTO, UPDATE and MERGE statements to let user add DEFAULT values without specifying column schema.
Background With the addition of DEFAULT constraint (HIVE-18726) user can define columns to have default value which will be used in case user doesn’t explicitly specify it while INSERTING data. For DEFAULT constraint to kick in user has to explicitly specify column schema leaving out the column name for which user would like the sytem to use DEFAULT value.</description></item><item><title>Apache Hive : Dependent Tables</title><link>https://hive.apache.org/development/desingdocs/dependent-tables/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/dependent-tables/</guid><description>Apache Hive : Dependent Tables Hive supports both partitioned and unpartitioned external tables. In both cases, when a new table/partition is being added, the location is also specified for the new table/partition. Let us consider a specific example:
create table T (key string, value string) partitioned by (ds string, hr string);
insert overwrite table T partition (ds=&amp;lsquo;1&amp;rsquo;, hr=&amp;lsquo;1&amp;rsquo;) &amp;hellip;;
..
insert overwrite table T partition (ds=&amp;lsquo;1&amp;rsquo;, hr=&amp;lsquo;24&amp;rsquo;) &amp;hellip;;
T is a partitioned table by date and hour, and Tsignal is an external table which conceptually denotes the creation of the signal table.</description></item><item><title>Apache Hive : Design</title><link>https://hive.apache.org/development/desingdocs/design/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/design/</guid><description>Apache Hive : Design This page contains details about the Hive design and architecture. A brief technical report about Hive is available at hive.pdf.
Apache Hive : Design Hive Architecture Hive Data Model Metastore Motivation Metadata Objects Metastore Architecture Metastore Interface Hive Query Language Compiler Optimizer Hive APIs Attachments: Hive Architecture Figure 1
Figure 1 shows the major components of Hive and its interactions with Hadoop.</description></item><item><title>Apache Hive : DesignDocs</title><link>https://hive.apache.org/development/desingdocs/designdocs/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/designdocs/</guid><description>Apache Hive : DesignDocs Hive Design Documents Proposals that appear in the &amp;ldquo;Completed&amp;rdquo; and &amp;ldquo;In Progress&amp;rdquo; sections should include a link to a JIRA ticket
Completed Views (HIVE-1143) Partitioned Views (HIVE-1941) Storage Handlers (HIVE-705) HBase Integration HBase Bulk Load Locking (HIVE-1293) Indexes (HIVE-417) Bitmap Indexes (HIVE-1803) Filter Pushdown (HIVE-279) Table-level Statistics (HIVE-1361) Dynamic Partitions Binary Data Type (HIVE-2380) Decimal Precision and Scale Support HCatalog (formerly Howl) HiveServer2 (HIVE-2935) Column Statistics in Hive (HIVE-1362) List Bucketing (HIVE-3026) Group By With Rollup (HIVE-2397) Enhanced Aggregation, Cube, Grouping and Rollup (HIVE-3433) Optimizing Skewed Joins (HIVE-3086) Correlation Optimizer (HIVE-2206) Hive on Tez (HIVE-4660) Hive-Tez Compatibility Vectorized Query Execution (HIVE-4160) Cost Based Optimizer in Hive (HIVE-5775) Atomic Insert/Update/Delete (HIVE-5317) Transaction Manager (HIVE-5843) SQL Standard based secure authorization (HIVE-5837) Hybrid Hybrid Grace Hash Join (HIVE-9277) LLAP Daemons (HIVE-7926) Support for Hive Replication (HIVE-7973) In Progress Column Level Top K Statistics (HIVE-3421) Hive on Spark (HIVE-7292) Hive on Spark: Join Design (HIVE-7613) Improve ACID Performance – download docx file (HIVE-14035, HIVE-14199, HIVE-14233) Query Results Caching (HIVE-18513) Default Constraint (HIVE-18726) Different TIMESTAMP types (HIVE-21348) Support SAML 2.</description></item><item><title>Apache Hive : Different TIMESTAMP types</title><link>https://hive.apache.org/development/desingdocs/different-timestamp-types/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/different-timestamp-types/</guid><description>Apache Hive : Different TIMESTAMP types Overview The following overview depicts the desired timestamp semantics in comparison to the SQL standard and selected database vendors:
TIMESTAMP and TIMESTAMP WITHOUT TIME ZONE The TIMESTAMP and TIMESTAMP WITHOUT TIME ZONE types shall behave like the LocalDateTime class of Java, i.e., each value is a recording of what can be seen on a calendar and a clock hanging on the wall, for example &amp;ldquo;1969-07-20 16:17:39&amp;rdquo;.</description></item><item><title>Apache Hive : DynamicPartitions</title><link>https://hive.apache.org/development/desingdocs/dynamicpartitions/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/dynamicpartitions/</guid><description>Apache Hive : DynamicPartitions Apache Hive : DynamicPartitions Documentation Terminology Syntax Design Design issues Documentation This is the design document for dynamic partitions in Hive. Usage information is also available:
Tutorial: Dynamic-Partition Insert Hive DML: Dynamic Partition Inserts HCatalog Dynamic Partitioning Usage with Pig Usage from MapReduce References:
Original design doc HIVE-936 Terminology Static Partition (SP) columns: in DML/DDL involving multiple partitioning columns, the columns whose values are known at COMPILE TIME (given by user).</description></item><item><title>Apache Hive : Enabling gRPC in Hive/Hive Metastore (Proposal)</title><link>https://hive.apache.org/development/desingdocs/enabling-grpc-in-hive-metastore/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/enabling-grpc-in-hive-metastore/</guid><description>Apache Hive : Enabling gRPC in Hive/Hive Metastore (Proposal) Apache Hive : Enabling gRPC in Hive/Hive Metastore (Proposal) Contacts Objective Background Design Overview Implementation Pluggable gRPC Support Hive Metastore Server Hive Metastore Client Summary Future Work Attachments: Contacts Cameron Moberg (Google), Zhou Fang (Google), Feng Lu (Google), Thejas Nair (Cloudera), Vihang Karajgaonkar (Cloudera), Naveen Gangam (Cloudera)</description></item><item><title>Apache Hive : FilterPushdownDev</title><link>https://hive.apache.org/development/desingdocs/filterpushdowndev/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/filterpushdowndev/</guid><description>Apache Hive : Filter Pushdown This document explains how we are planning to add support in Hive&amp;rsquo;s optimizer for pushing filters down into physical access methods. This is an important optimization for minimizing the amount of data scanned and processed by an access method (e.g. for an indexed key lookup), as well as reducing the amount of data passed into Hive for further query evaluation.
Apache Hive : Filter Pushdown Use Cases Components Involved Primary Filter Representation Other Filter Representations Filter Passing Filter Collection Filter Decomposition Use Cases Below are the main use cases we are targeting.</description></item><item><title>Apache Hive : GroupByWithRollup</title><link>https://hive.apache.org/development/desingdocs/groupbywithrollup/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/groupbywithrollup/</guid><description>Apache Hive : Group By With Rollup Apache Hive : Group By With Rollup Terminology Design Map Aggr &amp;amp; No Skew: Map Aggr &amp;amp; Skew No Map Aggr &amp;amp; No Skew &amp;amp; No Rollup No Map Aggr &amp;amp; No Skew &amp;amp; With Rollup No Map Aggr &amp;amp; Skew &amp;amp; (No Distinct or No Rollup) No Map Aggr &amp;amp; Skew &amp;amp; Distinct &amp;amp; Rollup References Terminology (No) Map Aggr: Shorthand for whether the configuration variable hive.</description></item><item><title>Apache Hive : Hadoop-compatible Input-Output Format for Hive</title><link>https://hive.apache.org/development/desingdocs/hadoop-compatible-input-output-format-for-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hadoop-compatible-input-output-format-for-hive/</guid><description>Apache Hive : Hadoop-compatible Input-Output Format for Hive Overview This is a proposal for adding API to Hive which allows reading and writing using a Hadoop compatible API. Specifically, the interfaces being implemented are:
InputFormat: http://hadoop.apache.org/docs/mapreduce/r0.21.0/api/org/apache/hadoop/mapreduce/InputFormat.html OutputFormat: http://hadoop.apache.org/docs/mapreduce/r0.21.0/api/org/apache/hadoop/mapreduce/OutputFormat.html The classes will be named HiveApiInputFormat and HiveApiOutputFormat.
See HIVE-3752 for discussion of this proposal.
InputFormat (reading from Hive) Usage:
Create a HiveInputDescription object. Fill it with information about the table to read from (with database, partition, columns).</description></item><item><title>Apache Hive : Hbase execution plans for RawStore partition filter condition</title><link>https://hive.apache.org/development/desingdocs/hbase-execution-plans-for-rawstore-partition-filter-condition/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hbase-execution-plans-for-rawstore-partition-filter-condition/</guid><description>Apache Hive : Hbase execution plans for RawStore partition filter condition (Apologies for this doc being organized properly, I thought something is better than nothing - Thejas)
This is part of metastore on hbase work - HIVE-9452 Use HBase to store Hive metadata Open
Functionality needed
RawStore functions that support partition filtering are the following -
getPartitionsByExpr getPartitionsByFilter (takes filter string as argument, used from hcatalog) We need to generate a query execution plan in terms of Hbase scan api calls for a given filter condition.</description></item><item><title>Apache Hive : HBaseBulkLoad</title><link>https://hive.apache.org/development/desingdocs/hbasebulkload/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hbasebulkload/</guid><description>Apache Hive : HBase Bulk Load This page explains how to use Hive to bulk load data into a new (empty) HBase table per HIVE-1295. (If you&amp;rsquo;re not using a build which contains this functionality yet, you&amp;rsquo;ll need to build from source and make sure this patch and HIVE-1321 are both applied.)
Apache Hive : HBase Bulk Load Overview Decide on Target HBase Schema Estimate Resources Needed Add necessary JARs Prepare Range Partitioning Prepare Staging Location Sort Data Run HBase Script Map New Table Back Into Hive Followups Needed Overview Ideally, bulk load from Hive into HBase would be part of HBaseIntegration, making it as simple as this:</description></item><item><title>Apache Hive : HBaseMetastoreDevelopmentGuide</title><link>https://hive.apache.org/development/desingdocs/hbasemetastoredevelopmentguide/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hbasemetastoredevelopmentguide/</guid><description>Apache Hive : HBaseMetastoreDevelopmentGuide  Guide for contributors to the metastore on hbase development work. Umbrella JIRA - HIVE-9452
This work is discontinued and the code is removed in release 3.0.0 (HIVE-17234).
Apache Hive : HBaseMetastoreDevelopmentGuide Building Setup for running hive against hbase metastore - Importing metadata from rdbms to hbase Design Docs Building You will need to download the source for Tephra and build it from the develop branch.</description></item><item><title>Apache Hive : Hive across Multiple Data Centers (Physical Clusters)</title><link>https://hive.apache.org/development/desingdocs/hive-across-multiple-data-centers/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hive-across-multiple-data-centers/</guid><description>Apache Hive : Hive across Multiple Data Centers (Physical Clusters) This project has been abandoned. We&amp;rsquo;re leaving the design doc here in case someone decides to attempt this project in the future.
Apache Hive : Hive across Multiple Data Centers (Physical Clusters) Use Cases Requirements Use Cases Inside facebook, we are running out of power inside a data center (physical cluster), and we have a need to have a bigger cluster.</description></item><item><title>Apache Hive : Hive Metadata Caching Proposal</title><link>https://hive.apache.org/development/desingdocs/hive-metadata-caching-proposal/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hive-metadata-caching-proposal/</guid><description>Apache Hive : Hive Metadata Caching Proposal Why Metastore Cache During Hive 2 benchmark, we find Hive metastore operation take a lot of time and thus slow down Hive compilation. In some extreme case, it takes much longer than the actual query run time. Especially, we find the latency of cloud db is very high and 90% of total query runtime is waiting for metastore SQL database operations. Based on this observation, the metastore operation performance will be greatly enhanced if we have a memory structure which cache the database query result.</description></item><item><title>Apache Hive : Hive on Spark: Join Design Master</title><link>https://hive.apache.org/development/desingdocs/hive-on-spark-join-design-master/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hive-on-spark-join-design-master/</guid><description>Apache Hive : Hive on Spark: Join Design Master Apache Hive : Hive on Spark: Join Design Master Purpose and Prerequisites MapReduce Summary Figure 1. Join Processors for Hive on MapReduce Tez Comparison Spark MapJoin Spark Join Design Figure 2: Join Processors for Hive on Spark Attachments: Purpose and Prerequisites The purpose of this document is to summarize the findings of all the research of different joins and describe a unified design to attack the problem in Spark.</description></item><item><title>Apache Hive : Hive on Tez</title><link>https://hive.apache.org/development/desingdocs/hive-on-tez/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hive-on-tez/</guid><description>Apache Hive : Hive on Tez Apache Hive : Hive on Tez Overview Multiple reduce stages Pipelining In memory versus disk writes Joins Fine-tuned algorithms Limit processing Scope Functional requirements of phase I Example Plan with TEZ Plan without TEZ Design Summary of changes Execution layer Job submission Job monitoring Job diagnostics Counters Job execution Query planning MapRedWork Semantic analysis and logical optimizations Physical Optimizations and Task generation Local Job Runner Number of tasks Explain statements Hive variables Build infrastructure Testing Mini Tez Cluster Installation and Configuration Hive-Tez Compatibility Overview Tez is a new application framework built on Hadoop Yarn that can execute complex directed acyclic graphs of general data processing tasks.</description></item><item><title>Apache Hive : Hive remote databases/tables</title><link>https://hive.apache.org/development/desingdocs/hive-remote-databases-tables/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hive-remote-databases-tables/</guid><description>Apache Hive : Hive remote databases/tables Abstract At the 2018 DataWorks conference in Berlin, Hotels.com presented Waggle Dance, a tool for federating multiple Hive clusters and providing the illusion of a unified data catalog from disparate instances. We’ve been running Waggle Dance in production for well over a year and it has formed a critical part of our data platform architecture and infrastructure.
We believe that this type of functionality will be of increasing importance as Hadoop and Hive workloads migrate to the cloud.</description></item><item><title>Apache Hive : HIVE-24543: Support SAML 2.0 authentication mode</title><link>https://hive.apache.org/development/desingdocs/support-saml-2-0-authentication-mode/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/support-saml-2-0-authentication-mode/</guid><description>Apache Hive : HIVE-24543: Support SAML 2.0 authentication mode Description In cloud based deployments, it is common that the user identity is federated and managed externally by an identity provider (e.g Okta, PingIndentity, Azure AD). Integrating with such external identity providers (IDP) would help adoption and unlock use-cases where Hive is deployed in a cloud based environment and doesn&amp;rsquo;t need user managed authentication mechanisms (e.g Ldap, Kerberos). There are primarily two authentication protocols which are standardized with such external identity providers namely (SAML 2.</description></item><item><title>Apache Hive : Hive-Tez Compatibility</title><link>https://hive.apache.org/development/desingdocs/hive-tez-compatibility/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hive-tez-compatibility/</guid><description>Apache Hive : Hive-Tez Compatibility This is derived from the pom files of the respective releases. Other releases with compatibility are listed in parenthesis.
Hive (Works with) Tez 0.13 0.4.0-incubating 0.14 0.5.2+, (through 0.7.0) 1.0 0.5.2, (through 0.7.0) 1.1 0.5.2, (through 0.7.0) 1.2* 0.5.3, (through 0.7.0) 2.0 0.8.2 *Hive-1.2 is the latest release of Hive as of 07/2015.</description></item><item><title>Apache Hive : HiveReplicationDevelopment</title><link>https://hive.apache.org/development/desingdocs/hivereplicationdevelopment/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hivereplicationdevelopment/</guid><description>Apache Hive : HiveReplicationDevelopment Apache Hive : HiveReplicationDevelopment Introduction Purposes of Replication Disaster Recovery Load Balancing Replication Taxonomy Transaction Source Synchronization Strategy Design Taxonomy Design Choices Primary-Copy vs Update-Anywhere Eager vs Lazy Other Design Choices Basic Approach Implementation Events Event IDs, State IDs, and Sequencing of Exports/Imports Handling of Events Future Features References Introduction Replication in the context of databases and warehouses is the process of duplication of entities from one warehouse to another.</description></item><item><title>Apache Hive : HiveReplicationv2Development</title><link>https://hive.apache.org/development/desingdocs/hivereplicationv2development/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hivereplicationv2development/</guid><description>Apache Hive : HiveReplicationv2Development This document describes the second version of Hive Replication. Please refer to the first version of Hive Replication for details on prior implementation.
This work is under development and interfaces are subject to change. This has been designed for use in conjunction with external orchestration tools, which would be responsible for co-ordinating the right sequence of commands between source and target clusters, fault tolerance/failure handling, and also providing correct configuration options that are necessary to be able to do cross cluster replication.</description></item><item><title>Apache Hive : HiveServer2 Thrift API</title><link>https://hive.apache.org/development/desingdocs/hiveserver2-thrift-api/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hiveserver2-thrift-api/</guid><description>Apache Hive : HiveServer2 Thrift API Introduction This document is a proposal for a new HiveServer2 Thrift API.
Motivations Concurrency Many users have reported that the current HiveServer implementation has concurrency bugs (for example, see HIVE-80). In fact, it&amp;rsquo;s impossible for HiveServer to support concurrent connections using the current Thrift API, a result of the fact that Thrift doesn&amp;rsquo;t provide server-side access to connection handles. Since the current API does not provide explicit support for sessions or connections, HiveServer has no way of mapping incoming requests to client sessions, which makes it impossible for HiveServer to maintain session state in between calls.</description></item><item><title>Apache Hive : Howl</title><link>https://hive.apache.org/development/desingdocs/howl/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/howl/</guid><description>Apache Hive : Howl This page collects some pointers to resources about Howl (an effort to create a metastore for all of Hadoop) and how its first incarnation is being built by reusing and extending Hive&amp;rsquo;s metastore and CLI.
Howl wiki Yahoo group for Howl developers (including mailing list archive) Howl source code at github Howl CLI functional spec Original plans for Owl (predecessor to Howl)</description></item><item><title>Apache Hive : Hybrid Hybrid Grace Hash Join, v1.0</title><link>https://hive.apache.org/development/desingdocs/hybrid-grace-hash-join-v1-0/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hybrid-grace-hash-join-v1-0/</guid><description>Apache Hive : Hybrid Hybrid Grace Hash Join, v1.0 Apache Hive : Hybrid Hybrid Grace Hash Join, v1.0 Overview Scope Notation and Assumptions Brief Review on Hash Join Algorithms Simple Hash Join GRACE Hash Join Hybrid GRACE Hash Join Hash Join in Hive Motivation for “Hybrid Hybrid GRACE Hash Join” Algorithm Recursive Hashing and Spilling Skewed Data Distribution Bloom Filter References Overview We are proposing an enhanced hash join algorithm called “hybrid hybrid grace hash join”.</description></item><item><title>Apache Hive : IndexDev</title><link>https://hive.apache.org/development/desingdocs/indexdev/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/indexdev/</guid><description>Apache Hive : Indexes Apache Hive : Indexes Indexing Is Removed since 3.0 Introduction Scope CREATE INDEX Metastore Model Metastore Upgrades REBUILD DROP INDEX Plugin Interface Reference Implementation TBD Current Status (JIRA) Indexing Is Removed since 3.0 There are alternate options which might work similarily to indexing:
Materialized views with automatic rewriting can result in very similar results. Hive 2.3.0 adds support for materialzed views.</description></item><item><title>Apache Hive : IndexDev Bitmap</title><link>https://hive.apache.org/development/desingdocs/indexdev-bitmap/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/indexdev-bitmap/</guid><description>Apache Hive : Bitmap Indexing Apache Hive : Bitmap Indexing Introduction Approach Proposal First implementation Second iteration Example Introduction This document explains the proposed design for adding a bitmap index handler (https://issues.apache.org/jira/browse/HIVE-1803).
Bitmap indexing (http://en.wikipedia.org/wiki/Bitmap_index) is a standard technique for indexing columns with few distinct
values, such as gender.
Approach We want to develop a bitmap index that can reuse as much of the existing Compact Index code as possible.</description></item><item><title>Apache Hive : Links</title><link>https://hive.apache.org/development/desingdocs/links/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/links/</guid><description>Apache Hive : Links Motivation Today, the infrastructure provided by Hive allows for the setup of a single shared warehouse and the authorization model allows for access control within this warehouse if needed. Growth beyond a single warehouse (when datacenter capacity limits are reached) OR separation of capacity usage and allocation requires the creation of multiple warehouses with each warehouse mapping to it&amp;rsquo;s own Hive metastore. Let&amp;rsquo;s define the term physical warehouse to map to a single Hive metastore, the Hadoop cluster it maps to and the data in it.</description></item><item><title>Apache Hive : ListBucketing</title><link>https://hive.apache.org/development/desingdocs/listbucketing/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/listbucketing/</guid><description>Apache Hive : ListBucketing Apache Hive : ListBucketing Goal Basic Partitioning List Bucketing Skewed Table vs. List Bucketing Table List Bucketing Validation DDL DML Alter Table Concatenate Hive Enhancements Create Table Alter Table Design Implementation Goal The top level problem is as follows:
There are many tables of the following format:
create table T(a, b, c, .</description></item><item><title>Apache Hive : LLAP</title><link>https://hive.apache.org/development/desingdocs/llap/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/llap/</guid><description>Apache Hive : LLAP Live Long And Process (LLAP) functionality was added in Hive 2.0 (HIVE-7926 and associated tasks). HIVE-9850 links documentation, features, and issues for this enhancement. For configuration of LLAP, see the LLAP Section of Configuration Properties.
Apache Hive : LLAP Overview Persistent Daemon Execution Engine Query Fragment Execution I/O Caching Workload Management ACID Support Security Monitoring Web Services SLIDER on YARN Deployment LLAP Status Resources Attachments: Overview Hive has become significantly faster thanks to various features and improvements that were built by the community in recent years, including Tez and Cost-based-optimization.</description></item><item><title>Apache Hive : Locking</title><link>https://hive.apache.org/development/desingdocs/locking/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/locking/</guid><description>Apache Hive : Locking Apache Hive : Locking Hive Concurrency Model Use Cases Turn Off Concurrency Debugging Configuration Locking in Hive Transactions Hive Concurrency Model Use Cases Concurrency support (http://issues.apache.org/jira/browse/HIVE-1293) is a must in databases and their use cases are well understood. At a minimum, we want to support concurrent readers and writers whenever possible. It would be useful to add a mechanism to discover the current locks which have been acquired.</description></item><item><title>Apache Hive : MapJoin and Partition Pruning</title><link>https://hive.apache.org/development/desingdocs/mapjoin-and-partition-pruning/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/mapjoin-and-partition-pruning/</guid><description>Apache Hive : MapJoin and Partition Pruning Apache Hive : MapJoin and Partition Pruning Overview Problem Proposed Solution Possible Extensions Optimization Details Compile Time Runtime Pseudo Code Overview In Hive, Map-Join is a technique that materializes data for all tables involved in the join except for the largest table and then large table is streamed over the materialized data from small tables.</description></item><item><title>Apache Hive : MapJoinOptimization</title><link>https://hive.apache.org/development/desingdocs/mapjoinoptimization/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/mapjoinoptimization/</guid><description>Apache Hive : MapJoinOptimization Apache Hive : MapJoinOptimization 1. Map Join Optimization 1.1 Using Distributed Cache to Propagate Hashtable File 1.2 Removing JDBM 1.3 Performance Evaluation 2. Converting Join into Map Join Automatically 2.1 New Join Execution Flow 2.2 Resolving the Join Operation at Run Time 2.3 Backup Task 2.4 Performance Evaluation 1. Map Join Optimization 1.1 Using Distributed Cache to Propagate Hashtable File Previously, when 2 large data tables need to do a join, there will be 2 different Mappers to sort these tables based on the join key and emit an intermediate file, and the Reducer will take the intermediate file as input file and do the real join work.</description></item><item><title>Apache Hive : Metastore TLP Proposal</title><link>https://hive.apache.org/development/desingdocs/metastore-tlp-proposal/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/metastore-tlp-proposal/</guid><description>Apache Hive : Metastore TLP Proposal Summary of the Proposal from the Email Hive’s metastore has long been used by other projects in the Hadoop ecosystem to store and access metadata. Apache Impala, Apache Spark, Apache Drill, Presto, and other systems all use Hive’s metastore. Some, like Impala and Presto, can use it as their own metadata system with the rest of Hive not present.
This sharing is excellent for the ecosystem.</description></item><item><title>Apache Hive : OuterJoinBehavior</title><link>https://hive.apache.org/development/desingdocs/outerjoinbehavior/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/outerjoinbehavior/</guid><description>Apache Hive : OuterJoinBehavior Hive Outer Join Behavior Apache Hive : OuterJoinBehavior Hive Outer Join Behavior Definitions Predicate Pushdown Rules Hive Implementation Examples Case J1: Join Predicate on Preserved Row Table Case J2: Join Predicate on Null Supplying Table Case W1: Where Predicate on Preserved Row Table Case W2: Where Predicate on Null Supplying Table This document is based on a writeup of DB2 Outer Join Behavior.</description></item><item><title>Apache Hive : PartitionedViews</title><link>https://hive.apache.org/development/desingdocs/partitionedviews/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/partitionedviews/</guid><description>Apache Hive : PartitionedViews This is a followup to ViewDev for adding partition-awareness to views.
Apache Hive : PartitionedViews Use Cases Approaches Syntax Metastore Strict Mode View Definition Changes Hook Information Use Cases An administrator wants to create a set of views as a table/column renaming layer on top of an existing set of base tables, without breaking any existing dependencies on those tables.</description></item><item><title>Apache Hive : Query Results Caching (HIVE-18513)</title><link>https://hive.apache.org/development/desingdocs/query-results-caching/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/query-results-caching/</guid><description>Apache Hive : Query Results Caching (HIVE-18513) Introduction This document proposes the addition of a query results cache to Hive. Caching query results allows a previously computed query result to be re-used in the event that the same query is processed by Hive. This can save both time and resources spent running the cluster tasks required for the query.
Background Existing behavior for Hive query processing (very simplified):
Hive query compilation takes the query string and produces a QueryPlan.</description></item><item><title>Apache Hive : Security</title><link>https://hive.apache.org/development/desingdocs/security/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/security/</guid><description>Apache Hive : Security This page collects some resources and pointers for various efforts underway to add security features to Hive and related projects.
Authorization modes
The links below refer to the original Hive authorization mode. See Authorization for an overview of authorization modes, which include storage based authorization and SQL standards based authorization.
Thoughts on security from Venkatesh Howl&amp;rsquo;s approach for persisting and validating DDL authorization via HDFS permissions HIVE-1264: Hadoop security integration THRIFT-889: allow Kerberos authentication over Thrift HTTP THRIFT-876: SASL integration Howl Authorization Proposal Hive Authorization Proposal Note that Howl was the precursor to HCatalog.</description></item><item><title>Apache Hive : Skewed Join Optimization</title><link>https://hive.apache.org/development/desingdocs/skewed-join-optimization/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/skewed-join-optimization/</guid><description>Apache Hive : Skewed Join Optimization Optimizing Skewed Joins The Problem A join of 2 large data tables is done by a set of MapReduce jobs which first sorts the tables based on the join key and then joins them. The Mapper gives all rows with a particular key to the same Reducer.
e.g., Suppose we have table A with a key column, &amp;ldquo;id&amp;rdquo; which has values 1, 2, 3 and 4, and table B with a similar column, which has values 1, 2 and 3.</description></item><item><title>Apache Hive : Spatial queries</title><link>https://hive.apache.org/development/desingdocs/spatial-queries/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/spatial-queries/</guid><description>Apache Hive : Spatial queries Overview Hadoop-GIS is a scalable and high performance spatial data warehousing system for running large-scale spatial queries on Hadoop. Hadoop-GIS relies on RESQUE for spatial query processing. RESQUE is a internally developed tile based spatial query engine which is written in C++ and deployed as shared library.
Hive****SP: we integrate Hadoop-GIS with Hive, to support both structured queries and spatial queries with a unified query language (HQL) and interface (Hive Shell).</description></item><item><title>Apache Hive : StatsDev</title><link>https://hive.apache.org/development/desingdocs/statsdev/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/statsdev/</guid><description>Apache Hive : Statistics This document describes the support of statistics for Hive tables (see HIVE-33).
Apache Hive : Statistics Motivation Scope Table and Partition Statistics Column Statistics Top K Statistics Quick overview Implementation Usage Configuration Variables Newly Created Tables Existing Tables – ANALYZE Examples ANALYZE TABLE &amp;lt;table1&amp;gt; CACHE METADATA Current Status (JIRA) Motivation Statistics such as the number of rows of a table or partition and the histograms of a particular interesting column are important in many ways.</description></item><item><title>Apache Hive : Storage API Release Proposal</title><link>https://hive.apache.org/development/desingdocs/storage-api-release-proposal/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/storage-api-release-proposal/</guid><description>Apache Hive : Storage API Release Proposal To enable faster and more direct integration of file formats like ORC and Parquet, Hive has separated out the Storage API as a distinct subproject and will release it independently of the rest of Hive. The storage-api source code will remain in the Hive git repository. The initial work on the pom files was done in HIVE-15419. The plan is to start the Storage API releases at 2.</description></item><item><title>Apache Hive : StorageHandlers</title><link>https://hive.apache.org/development/desingdocs/storagehandlers/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/storagehandlers/</guid><description>Apache Hive : StorageHandlers Hive Storage Handlers Hive Storage Handlers Introduction Terminology DDL Storage Handler Interface HiveMetaHook Interface Open Issues Introduction This page documents the storage handler support being added to Hive as part of work on HBaseIntegration. The motivation is to make it possible to allow Hive to access data stored and managed by other systems in a modular, extensible fashion.
Besides HBase, a storage handler implementation is also available for Hypertable, and others are being developed for Cassandra, Azure Table, JDBC (MySQL and others), MongoDB, ElasticSearch, Phoenix HBase, VoltDB and Google Spreadsheets.</description></item><item><title>Apache Hive : Subqueries in SELECT</title><link>https://hive.apache.org/development/desingdocs/subqueries-in-select/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/subqueries-in-select/</guid><description>Apache Hive : Subqueries in SELECT Problem Currently Hive doesn&amp;rsquo;t support subqueries in a SELECT statement, for example, the following query will not run on Hive:
SELECT customer.customer_num, (SELECT SUM(ship_charge) FROM orders WHERE customer.customer_num = orders.customer_num ) AS total_ship_chg FROM customer Recently a lot of work has been done to extend support for subqueries (HIVE-15456). But this work primarily targeted extending subquery support in WHERE and HAVING clauses. We plan to continue the work done in HIVE-15456 to support subqueries in a select list (see HIVE-16091).</description></item><item><title>Apache Hive : Suggestion for DDL Commands in HMS schema upgrade scripts</title><link>https://hive.apache.org/development/desingdocs/suggestion-for-ddl-commands-in-hms-schema-upgrade-scripts/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/suggestion-for-ddl-commands-in-hms-schema-upgrade-scripts/</guid><description>Apache Hive : Suggestion for DDL Commands in HMS schema upgrade scripts In this page, I would like to share the information I learned from Braintree&amp;rsquo;s Blog about how they handle DB schema migration while application is up and serving requests. I think this should benefits to developer who is working on HMS&amp;rsquo;s schema upgrade scripts. As for some DDL commands, they can lock out updates to a table for a long time and database operation that locks for more than a few seconds is indistinguishable from an outage for customers.</description></item><item><title>Apache Hive : Synchronized Metastore Cache</title><link>https://hive.apache.org/development/desingdocs/synchronized-metastore-cache/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/synchronized-metastore-cache/</guid><description>Apache Hive : Synchronized Metastore Cache Overview This work is to solve the consistency problem if we use HMS HA with metadata cache. Note it does not aim to address any existing consistency issues already exist in non-cached HMS. For example, it won’t fix the transaction semantic between metadata and data. If the problem exists today in non-cached HMS, it stays a problem after this work.
The problem we try to solve here is the cache consistency issue.</description></item><item><title>Apache Hive : Theta Join</title><link>https://hive.apache.org/development/desingdocs/theta-join/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/theta-join/</guid><description>Apache Hive : Theta Join Apache Hive : Theta Join Preliminaries Overview Specific Use Cases Requirements Literature Review Map-Reduce-Merge: Simplified Relational Data Processing on Large Clusters [1] Efficient Parallel Set-Similarity Joins Using MapReduce [2] Processing Theta-Joins using MapReduce [3] Efficient Multi-way Theta-Join Processing Using MapReduce [4] Design Map-side Reduce-side References Preliminaries Overview HIVE-556 requests that Hive support non-equality joins commonly called theta joins.</description></item><item><title>Apache Hive : Top K Stats</title><link>https://hive.apache.org/development/desingdocs/top-k-stats/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/top-k-stats/</guid><description>Apache Hive : Column Level Top K Statistics This document is an addition to Statistics in Hive. It describes the support of collecting column level top K values for Hive tables (see HIVE-3421).
Apache Hive : Column Level Top K Statistics Scope Implementation Usage Example Newly Created Tables Existing Tables Current Status (JIRA) Scope In addition to the partition statistics, column level top K values can also be estimated for Hive tables.</description></item><item><title>Apache Hive : Type Qualifiers in Hive</title><link>https://hive.apache.org/development/desingdocs/type-qualifiers-in-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/type-qualifiers-in-hive/</guid><description>Apache Hive : Type Qualifiers in Hive Intro Hive will need to support some kind of type qualifiers/parameters in its type metadata to be able to enforce type features such as decimal precision/scale or char/varchar length and collation. This involves changes to the PrimitiveTypeEntry/TypeInfo/ObjectInspectors, possibly metastore changes,
My impression is that the actual enforcement of the type qualifiers should be done by the ObjectInspectors/Converters/casts operations. It should be ok to do col * col when col is a decimal(2) value of 99, it would fail if you try to cast the result to decimal(2) or try to insert it to a decimal(2) column.</description></item><item><title>Apache Hive : UpdatableViews</title><link>https://hive.apache.org/development/desingdocs/updatableviews/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/updatableviews/</guid><description>Apache Hive : UpdatableViews Proposal Hive will consider a view updatable if:
The view refers to exactly one base table or updatable view in the FROM clause without a WHERE clause. Each column in the view is a column in the underlying table/updatable view with no underlying columns duplicated. Views must have the same partition columns as the underlying table/updatable view. When inserting into a view:
If a view does not specify all underlying columns, NULL will be inserted for each column not specified.</description></item><item><title>Apache Hive : Vectorized Query Execution</title><link>https://hive.apache.org/development/desingdocs/vectorized-query-execution/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/vectorized-query-execution/</guid><description>Apache Hive : Vectorized Query Execution Apache Hive : Vectorized Query Execution Introduction Using Vectorized Query Execution Enabling vectorized execution Supported data types and operations Seeing whether vectorization is used for a query Limitations Version Information Introduction Vectorized query execution is a Hive feature that greatly reduces the CPU usage for typical query operations like scans, filters, aggregates, and joins. A standard query execution system processes one row at a time.</description></item><item><title>Apache Hive : ViewDev</title><link>https://hive.apache.org/development/desingdocs/viewdev/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/viewdev/</guid><description>Apache Hive : Views Apache Hive : Views Use Cases Scope Syntax Implementation Sketch Issues Stored View Definition Metastore Modeling Dependency Tracking Dependency Invalidation View Modification Fast Path Execution ORDER BY and LIMIT in view definition Underlying Partition Dependencies Metastore Upgrades Automatic ALTER TABLE Explicit ALTER TABLE Existing Row UPDATE Use Cases Views (http://issues.apache.org/jira/browse/HIVE-972) are a standard DBMS feature and their uses are well understood.</description></item></channel></rss>