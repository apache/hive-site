<!doctype html><html><!doctype html>
<html>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content>
<meta name=author content>
<title>Apache Hive : FilterPushdownDev</title>
<link rel=icon href=/images/hive.svg sizes=any type=image/svg+xml>
<link rel=stylesheet href=https://hive.apache.org/css/hive-theme.css>
<link rel=stylesheet href=https://hive.apache.org/css/font-awesome.all.min.css>
<link rel=stylesheet href=https://hive.apache.org/css/bootstrap.min.css>
<link rel=stylesheet href=https://hive.apache.org/css/termynal.css>
<link rel=apple-touch-icon sizes=180x180 href=https://hive.apache.org/images/apple-touch-icon.png>
<link rel=icon type=image/png sizes=32x32 href=https://hive.apache.org/images/favicon-32x32.png>
<link rel=icon type=image/png sizes=16x16 href=https://hive.apache.org/images/favicon-16x16.png>
<link rel=manifest href=https://hive.apache.org/images/site.webmanifest>
<link rel=mask-icon href=https://hive.apache.org/images/safari-pinned-tab.svg color=#5bbad5>
<meta name=msapplication-TileColor content="#da532c">
<meta name=theme-color content="#ffffff">
<script>var _paq=window._paq=window._paq||[];_paq.push(['disableCookies']),_paq.push(['trackPageView']),_paq.push(['enableLinkTracking']),function(){var b="https://analytics.apache.org/",c,a,d;_paq.push(['setTrackerUrl',b+'matomo.php']),_paq.push(['setSiteId','30']),c=document,a=c.createElement('script'),d=c.getElementsByTagName('script')[0],a.async=!0,a.src=b+'matomo.js',d.parentNode.insertBefore(a,d)}()</script>
</head>
<body>
<body>
<header>
<menu style=background:#000;margin:0>
<nav class="navbar navbar-expand-lg navbar-dark bg-black">
<div class=container-fluid>
<a href=https://hive.apache.org> <img src=https://hive.apache.org/images/hive.svg width=60 height=35 alt="Apache Software Foundation"></a>
<a class="header-text navbar-brand" href=https://hive.apache.org>Apache Hive</a>
<button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span>
</button>
<div class="collapse navbar-collapse" id=navbarSupportedContent>
<ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item dropdown">
<a class=nav-link href=/general/downloads id=navbarDropdown role=button aria-expanded=false>
Releases
</a>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=/Document id=navbarDropdown role=button data-bs-toggle=dropdown aria-expanded=false>
Documentation
</a>
<ul class=dropdown-menu aria-labelledby=navbarDropdown>
<li><a class=dropdown-item href=/docs/latest/>Latest</a></li>
<li><a class=dropdown-item href=https://hive.apache.org/docs/javadocs/>Javadocs</a></li>
<li><a class=dropdown-item href=https://cwiki.apache.org/confluence/display/Hive/LanguageManual>Language Manual</a></li>
</ul>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=/general id=navbarDropdown role=button data-bs-toggle=dropdown aria-expanded=false>
General
</a>
<ul class=dropdown-menu aria-labelledby=navbarDropdown>
<li><a class=dropdown-item href=https://www.apache.org/licenses/LICENSE-2.0.html>License</a></li>
<li><a class=dropdown-item href=https://hive.apache.org/general/privacypolicy/>Privacy Policy</a></li>
</ul>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-expanded=false>
Development
</a>
<ul class=dropdown-menu aria-labelledby=navbarDropdown>
<li><a class=dropdown-item href=https://hive.apache.org/development/gettingstarted/>Getting Started</a></li>
<li><a class=dropdown-item href=https://hive.apache.org/development/quickstart/>Quickstart with Docker</a></li>
<li><a class=dropdown-item href=https://cwiki.apache.org/confluence/display/Hive/DesignDocs>Design Docs</a></li>
<li><a class=dropdown-item href=https://issues.apache.org/jira/projects/HIVE/issues>Hive JIRA</a></li>
<li><a class=dropdown-item href=https://cwiki.apache.org/confluence/display/Hive/HiveDeveloperFAQ>Hive Developer FAQ</a></li>
<li><a class=dropdown-item href=https://cwiki.apache.org/confluence/display/Hive/Hive+PreCommit+Patch+Testing>Precommit Patch Testing</a></li>
<li><a class=dropdown-item href=https://hive.apache.org/development/versioncontrol/>Version Control</a></li>
</ul>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-expanded=false>
Community
</a>
<ul class=dropdown-menu aria-labelledby=navbarDropdown>
<li><a class=dropdown-item href=/community/becomingcommitter/>Becoming A Committer</a></li>
<li><a class=dropdown-item href=https://cwiki.apache.org/confluence/display/Hive/HowToContribute>How To Contribute</a></li>
<li><a class=dropdown-item href=https://cwiki.apache.org/confluence/display/Hive/Home#Home-ResourcesforContributors>Resources for Contributors</a></li>
<li><a class=dropdown-item href=https://hive.apache.org/community/mailinglists/>Mailing Lists</a></li>
<li><a class=dropdown-item href=https://hive.apache.org/community/issuetracking/>Issue Tracking</a></li>
<li><a class=dropdown-item href=https://hive.apache.org/community/people/>People</a></li>
<li>
<hr class=dropdown-divider>
</li>
<li><a class=dropdown-item href=/community/bylaws/>By Laws</a></li>
<li><a class=dropdown-item href=https://cwiki.apache.org/confluence/display/Hive/HowToRelease>How To Release</a></li>
</ul>
</li>
<li class="nav-item dropdown">
<a class=nav-link href=https://hive.blog.apache.org/ id=navbarDropdown role=button aria-expanded=false>
Blogs
</a>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-expanded=false>
ASF
</a>
<ul class=dropdown-menu aria-labelledby=navbarDropdown>
<li><a class=dropdown-item href=https://www.apache.org/foundation/contributing.html>Donations</a></li>
<li><a class=dropdown-item href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a></li>
<li><a class=dropdown-item href=https://www.apache.org/foundation/thanks.html>Thanks</a></li>
<li><a class=dropdown-item href=https://www.apache.org/>Website</a></li>
</ul>
</li>
<li>
<form action=/search method=get class=search-bar>
<input type=search name=q id=search-query placeholder=Search... class=search-input>
<button type=submit class=search-button>Search</button>
</form>
</li>
</ul>
</div>
</div>
</nav>
</menu>
</header>
<div class=content>
<div class=docs>
<h1 id=apache-hive--filterpushdowndev>Apache Hive : FilterPushdownDev</h1>
<h1 id=filter-pushdown>Filter Pushdown</h1>
<ul>
<li><a href=#filter-pushdown>Filter Pushdown</a>
<ul>
<li><a href=#introduction>Introduction</a></li>
<li><a href=#use-cases>Use Cases</a></li>
<li><a href=#components-involved>Components Involved</a></li>
<li><a href=#primary-filter-representation>Primary Filter Representation</a></li>
<li><a href=#other-filter-representations>Other Filter Representations</a></li>
<li><a href=#filter-passing>Filter Passing</a></li>
<li><a href=#filter-collection>Filter Collection</a></li>
<li><a href=#filter-decomposition>Filter Decomposition</a></li>
</ul>
</li>
</ul>
<h2 id=introduction>Introduction</h2>
<p>This document explains how we are planning to add support in Hive&rsquo;s optimizer for pushing filters down into physical access methods. This is an important optimization for minimizing the amount of data scanned and processed by an access method (e.g. for an indexed key lookup), as well as reducing the amount of data passed into Hive for further query evaluation.</p>
<h2 id=use-cases>Use Cases</h2>
<p>Below are the main use cases we are targeting.</p>
<ul>
<li>Pushing filters down into Hive&rsquo;s builtin storage formats such as RCFile</li>
<li>Pushing filters down into storage handlers such as the <a href=https://hive.apache.org/docs/latest/hbaseintegration_27362089/>HBase handler</a> (<a href=http://issues.apache.org/jira/browse/HIVE-1226>http://issues.apache.org/jira/browse/HIVE-1226</a>)</li>
<li>Pushing filters down into index access plans once an indexing framework is added to Hive (<a href=http://issues.apache.org/jira/browse/HIVE-417>http://issues.apache.org/jira/browse/HIVE-417</a>)</li>
</ul>
<h2 id=components-involved>Components Involved</h2>
<p>There are a number of different parts to the overall effort.</p>
<ol>
<li>Propagating the result of Hive&rsquo;s existing predicate pushdown. Hive&rsquo;s optimizer already takes care of the hard work of pushing predicates down through the query plan (controlled via configuration parameter <strong>hive.optimize.ppd=true/false</strong>). The &ldquo;last mile&rdquo; remaining is to send the table-level filters down into the corresponding input formats.</li>
<li>Selection of a primary filter representation to be passed to input formats. This representation needs to be neutral (independent of the access plans which will use it) and loosely coupled with Hive (so that storage handlers can choose to minimize their dependencies on Hive internals).</li>
<li>Helper classes for interpreting the primary representation. Many access plans will need to analyze filters in a similar fashion, e.g. decomposing conjunctions and detecting supported column comparison patterns. Hive should provide sharable utilities for such cases so that they don&rsquo;t need to be duplicated in each access method&rsquo;s code.</li>
<li>Converting filters into a form specific to the access method. This part is dependent on the particular access method; e.g. for HBase, it involves converting the filter condition into corresponding calls to set up an <a href=http://hbase.apache.org/docs/r0.20.5/api/org/apache/hadoop/hbase/client/Scan.html>HBase scan</a> object.</li>
</ol>
<h2 id=primary-filter-representation>Primary Filter Representation</h2>
<p>To achieve the loosest possible coupling, we are going to use a string as the primary representation for the filter. In particular, the string will be in the form produced when Hive unparses an <code>ExprNodeDesc</code>, e.g.</p>
<pre tabindex=0><code>((key &gt;= 100) and (key &lt; 200))

</code></pre><p>In general, this comes out as valid SQL, although it may not always match the original SQL exactly, e.g.</p>
<pre tabindex=0><code>cast(x as int)

</code></pre><p>becomes</p>
<pre tabindex=0><code>UDFToInteger(x)

</code></pre><p>Column names in this string are unqualified references to the columns of the table over which the filter operates, as they are known in the Hive metastore. These column names may be different from those known to the underlying storage; for example, the HBase storage handler maps Hive column names to HBase column names (qualified by column family). Mapping from Hive column names is the responsibility of the code interpreting the filter string.</p>
<h2 id=other-filter-representations>Other Filter Representations</h2>
<p>As mentioned above, we want to avoid duplication in code which interprets the filter string (e.g. parsing). As a first cut, we will provide access to the <code>ExprNodeDesc</code> tree by passing it along in serialized form as an optional companion to the filter string. In followups, we will provide parsing utilities for the string form.</p>
<p>We will also provide an IndexPredicateAnalyzer class capable of detecting simple <a href=http://en.wikipedia.org/wiki/Sargable>sargable</a><br>
subexpressions in an <code>ExprNodeDesc</code> tree. In followups, we will provide support for discriminating and combining more complex indexable subexpressions.</p>
<pre tabindex=0><code>public class IndexPredicateAnalyzer
{
  public IndexPredicateAnalyzer();

  /**
 * Registers a comparison operator as one which can be satisfied
 * by an index search.  Unless this is called, analyzePredicate
 * will never find any indexable conditions.
   *
 * @param udfName name of comparison operator as returned
 * by either {@link GenericUDFBridge#getUdfName} (for simple UDF's)
 * or udf.getClass().getName() (for generic UDF's).
   */
  public void addComparisonOp(String udfName);

  /**
 * Clears the set of column names allowed in comparisons.  (Initially, all
 * column names are allowed.)
   */
  public void clearAllowedColumnNames();

  /**
 * Adds a column name to the set of column names allowed.
   *
 * @param columnName name of column to be allowed
   */
  public void allowColumnName(String columnName);

  /**
 * Analyzes a predicate.
   *
 * @param predicate predicate to be analyzed
   *
 * @param searchConditions receives conditions produced by analysis
   *
 * @return residual predicate which could not be translated to
 * searchConditions
   */
  public ExprNodeDesc analyzePredicate(
    ExprNodeDesc predicate,
    final List&lt;IndexSearchCondition&gt; searchConditions);

  /**
 * Translates search conditions back to ExprNodeDesc form (as
 * a left-deep conjunction).
   *
 * @param searchConditions (typically produced by analyzePredicate)
   *
 * @return ExprNodeDesc form of search conditions
   */
  public ExprNodeDesc translateSearchConditions(
    List&lt;IndexSearchCondition&gt; searchConditions);
}

public class IndexSearchCondition
{
  /**
 * Constructs a search condition, which takes the form
 * &lt;pre&gt;column-ref comparison-op constant-value&lt;/pre&gt;.
   *
 * @param columnDesc column being compared
   *
 * @param comparisonOp comparison operator, e.g. &quot;=&quot;
 * (taken from GenericUDFBridge.getUdfName())
   *
 * @param constantDesc constant value to search for
   *
 * @Param comparisonExpr the original comparison expression
   */
  public IndexSearchCondition(
    ExprNodeColumnDesc columnDesc,
    String comparisonOp,
    ExprNodeConstantDesc constantDesc,
    ExprNodeDesc comparisonExpr);
}

</code></pre><h2 id=filter-passing>Filter Passing</h2>
<p>The approach for passing the filter down to the input format will follow a pattern similar to what is already in place for pushing column projections down.</p>
<ul>
<li><code>org.apache.hadoop.hive.serde2.ColumnProjectionUtils</code> encapsulates the pushdown communication</li>
<li>classes such as <code>HiveInputFormat</code> call <code>ColumnProjectionUtils</code> to set the projection pushdown property (READ_COLUMN_IDS_CONF_STR) on a jobConf before instantiating a <code>RecordReader</code></li>
<li>the factory method for the <code>RecordReader</code> calls <code>ColumnProjectionUtils</code> to access this property</li>
</ul>
<p>For filter pushdown:</p>
<ul>
<li><code>HiveInputFormat</code> sets properties <code>hive.io.filter.text</code> (string form) and <code>hive.io.filter.expr.serialized</code> (serialized form of ExprNodeDesc) in the job conf before calling getSplits as well as before instantiating a record reader</li>
<li>the storage handler&rsquo;s input format reads these properties and processes the filter expression</li>
<li>there is a separate optimizer interaction for negotiation of filter decomposition (described in a later section)</li>
</ul>
<p>Note that getSplits needs to be involved since the selectivity of the filter may prune away some of the splits which would otherwise be accessed. (In theory column projection could also influence the split boundaries, but we&rsquo;ll leave that for a followup.)</p>
<h2 id=filter-collection>Filter Collection</h2>
<p>So, where will <code>HiveInputFormat</code> get the filter expression to be passed down? Again, we can start with the pattern for column projections:</p>
<ul>
<li>during optimization, <code>org.apache.hadoop.hive.ql.optimizer.ColumnPrunerProcFactory's</code> <code>ColumnPrunerTableScanProc</code> populates the pushdown information in <code>TableScanOperator</code></li>
<li>later, <code>HiveInputFormat.initColumnsNeeded</code> retrieves this information from the <code>TableScanOperator</code></li>
</ul>
<p>For filter pushdown, the equivalent is <code>TableScanPPD</code> in <code>org.apache.hadoop.hive.ql.ppd.OpProcFactory</code>. Currently, it calls <code>createFilter</code>, which collapsed expressions into a single expression called condn, and then sticks that on a new <code>FilterOperator</code>. We can call condn.getExprString() and store the result on <code>TableScanOperator</code>.</p>
<p>Hive configuration parameter <code>hive.optimize.ppd.storage</code> can be used to enable or disable pushing filters down to the storage handler. This will be enabled by default. However, if <code>hive.optimize.ppd</code> is disabled, then this implicitly prevents pushdown to storage handlers as well.</p>
<p>We are starting with non-native tables only; we&rsquo;ll revisit this for pushing filters down to indexes and builtin storage formats such as RCFile.</p>
<h2 id=filter-decomposition>Filter Decomposition</h2>
<p>Consider a filter like</p>
<pre tabindex=0><code>x &gt; 3 AND upper(y) = 'XYZ'

</code></pre><p>Suppose a storage handler is capable of implementing the range scanfor <code>x > 3</code>, but does not have a facility for evaluating {{upper(y) =<br>
&lsquo;XYZ&rsquo;}}. In this case, the optimal plan would involve decomposing the filter, pushing just the first part down into the storage handler, and<br>
leaving only the remainder for Hive to evaluate via its own executor.</p>
<p>In order for this to be possible, the storage handler needs to be able to negotiate the decomposition with Hive. This means that Hive gives<br>
the storage handler the entire filter, and the storage handler passes back a &ldquo;residual&rdquo;: the portion that needs to be evaluated by Hive. A null residual indicates that the storage handler was able to deal with the entire filter on its own (in which case no <code>FilterOperator</code> is needed).</p>
<p>In order to support this interaction, we will introduce a new (optional) interface to be implemented by storage handlers:</p>
<pre tabindex=0><code>public interface HiveStoragePredicateHandler {
  public DecomposedPredicate decomposePredicate(
    JobConf jobConf,
    Deserializer deserializer,
    ExprNodeDesc predicate);

  public static class DecomposedPredicate {
    public ExprNodeDesc pushedPredicate;
    public ExprNodeDesc residualPredicate;
  }
}

</code></pre><p>Hive&rsquo;s optimizer (during predicate pushdown) calls the decomposePredicate method, passing in the full expression and receiving back the decomposition (or null to indicate that no pushdown was possible). The <code>pushedPredicate</code> gets passed back to the storage handler&rsquo;s input format later, and the <code>residualPredicate</code> is attached to the <code>FilterOperator</code>.</p>
<p>It is assumed that storage handlers which are sophisticated enough to implement this interface are suitable for tight coupling to the <code>ExprNodeDesc</code> representation.</p>
<p>Again, this interface is optional, and pushdown is still possible even without it. If the storage handler does not implement this interface, Hive will always implement the entire expression in the <code>FilterOperator</code>, but it will still provide the expression to the storage handler&rsquo;s input format; the storage handler is free to implement as much or as little as it wants.</p>
</div>
</div>
<footer class="black-background static-bottom" style=padding:30px>
<div class=row>
<div class=col-3>
<a href=https://www.apache.org/>
<img src=https://hive.apache.org/images/asf_logo.png width=270 height=100 alt="Apache Software Foundation"></a>
</a>
</div>
<div class=col-9>
<p class=footer-text>Apache is a non-profit organization helping open-source
software projects released under the Apache
<a href=https://www.apache.org/licenses/>license</a>
and managed with
<a href=https://www.apache.org/foundation/how-it-works.html>
open governance</a> and
<a href=https://privacy.apache.org/policies/privacy-policy-public.html>
privacy policy</a>. See upcoming
<a href=https://www.apache.org/events/current-event>Apache Events</a>.
If you discover any
<a href=https://www.apache.org/security/>security</a> vulnerabilities, please
report them privately. Finally,
<a href=https://www.apache.org/foundation/sponsorship.html>thanks
</a> to the sponsors who
<a href=https://www.apache.org/foundation/contributing.html>
donate</a> to the Apache Foundation.
</p>
</div>
</div>
<div class="copyright row">
<a href=https://hive.apache.org style=color:grey>
The contents of this website are © 2023 Apache Software Foundation under the terms of the Apache License v2. Apache Hive and its logo are trademarks of the Apache Software Foundation.
</a>
</div>
</footer>
<script src=https://hive.apache.org/js/bootstrap.bundle.min.js></script>
</body>
</html>