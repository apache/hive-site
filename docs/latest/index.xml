<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Space Details: on Hive Site</title><link>https://hive.apache.org/docs/latest/</link><description>Recent content in Space Details: on Hive Site</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 12 Dec 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://hive.apache.org/docs/latest/index.xml" rel="self" type="application/rss+xml"/><item><title>Apache Hive : AccessServer Design Proposal</title><link>https://hive.apache.org/docs/latest/accessserver-design-proposal_31823045/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/accessserver-design-proposal_31823045/</guid><description>Apache Hive : AccessServer Design Proposal AccessServer Proposal Author: Carl Steinbach Overview The technical approach described in the this document addresses the following high-level requirements:
Make Apache Hive’s data model and metadata services accessible to users of the Apache Pig dataflow programming language as well as other Hadoop language runtimes. Make it possible for Hive users and users of other Hadoop language runtimes to share data stored in Hive’s HDFS data warehouse.</description></item><item><title>Apache Hive : AccumuloIntegration</title><link>https://hive.apache.org/docs/latest/accumulointegration_46633569/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/accumulointegration_46633569/</guid><description>Apache Hive : AccumuloIntegration Hive Accumulo Integration Hive Accumulo Integration Overview Implementation Accumulo Configuration Usage Column Mapping Indexing Other options Examples Override the Accumulo table name Store a Hive map with binary serialization Register an external table Create an indexed table Acknowledgements Overview Apache Accumulo is a sorted, distributed key-value store based on the Google BigTable paper. The API methods that Accumulo provides are in terms of Keys and Values which present the highest level of flexibility in reading and writing data; however, higher-level query abstractions are typically an exercise left to the user.</description></item><item><title>Apache Hive : AdminManual</title><link>https://hive.apache.org/docs/latest/adminmanual_27362071/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/adminmanual_27362071/</guid><description>Apache Hive : AdminManual Hive Administrator&amp;rsquo;s Manual Installing Hive Configuring Hive Setting up Metastore Setting up Hive Server (JDBC, ODBC, Thrift, etc) Hive on Amazon Web Services</description></item><item><title>Apache Hive : AdminManual Configuration</title><link>https://hive.apache.org/docs/latest/adminmanual-configuration_27362070/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/adminmanual-configuration_27362070/</guid><description>Apache Hive : AdminManual Configuration Configuring Hive hive-site.xml and hive-default.xml.template Temporary Folders Log Files Derby Server Mode Configuration Variables Removing Hive Metastore Password from Hive Configuration Configuring HCatalog and WebHCat HCatalog WebHCat Configuring Hive A number of configuration variables in Hive can be used by the administrator to change the behavior for their installations and user sessions. These variables can be configured in any of the following ways, shown in the order of preference:</description></item><item><title>Apache Hive : AdminManual Installation</title><link>https://hive.apache.org/docs/latest/adminmanual-installation_27362077/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/adminmanual-installation_27362077/</guid><description>Apache Hive : AdminManual Installation Installing Hive Installing from a Tarball Installing from Source Code (Hive 1.2.0 and Later) Installing from Source Code (Hive 0.13.0 and Later) Installing from Source Code (Hive 0.12.0 and Earlier) Next Steps Hive CLI and Beeline CLI Hive Metastore HCatalog and WebHCat HCatalog WebHCat (Templeton) Installing Hive You can install a stable release of Hive by downloading and unpacking a tarball, or you can download the source code and build Hive using Maven (release 0.</description></item><item><title>Apache Hive : AdminManual Metastore 3.0 Administration</title><link>https://hive.apache.org/docs/latest/adminmanual-metastore-3-0-administration_75978150/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/adminmanual-metastore-3-0-administration_75978150/</guid><description>Apache Hive : AdminManual Metastore 3.0 Administration Metastore 3.0 Administration
Version Note Introduction Changes From Hive 2 to Hive 3 General Configuration RDBMS Option 1: Embedding Derby Option 2: External RDBMS Supported RDBMSs Installing and Upgrading the Metastore Schema Running the Metastore Embedded Mode Metastore Server High Availability Securing the Service Running the Metastore Without Hive Performance Optimizations CachedStore Less Commonly Changed Configuration Parameters Version Note This document applies only to the Metastore in Hive 3.</description></item><item><title>Apache Hive : AdminManual Metastore Administration</title><link>https://hive.apache.org/docs/latest/adminmanual-metastore-administration_27362076/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/adminmanual-metastore-administration_27362076/</guid><description>Apache Hive : AdminManual Metastore Administration Hive Metastore Administration Hive Metastore Administration Introduction Basic Configuration Parameters Additional Configuration Parameters Data Nucleus Auto Start Default Configuration Local/Embedded Metastore Database (Derby) Remote Metastore Database Local/Embedded Metastore Server Remote Metastore Server Client Configuration Parameters Supported Backend Databases for Metastore Metastore Schema Consistency and Upgrades This page only documents the MetaStore in Hive 2.</description></item><item><title>Apache Hive : AdminManual SettingUpHiveServer</title><link>https://hive.apache.org/docs/latest/adminmanual-settinguphiveserver_27362079/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/adminmanual-settinguphiveserver_27362079/</guid><description>Apache Hive : AdminManual SettingUpHiveServer Setting Up Hive Server Setting Up HiveServer2 Setting Up Thrift Hive Server Setting Up Hive JDBC Server Setting Up Hive ODBC Server</description></item><item><title>Apache Hive : Apache Hive 4.0.X</title><link>https://hive.apache.org/docs/latest/apache-hive-4-0-x_282102245/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/apache-hive-4-0-x_282102245/</guid><description>Apache Hive : Apache Hive 4.0.X Overview of Major Changes ChangeLog Introduction to Apache Hive Building from Source Installing Hive From Docker Manual Installation HiveServer2 Overview HiveServer2 Clients AdminManual Metastore 3.0+ Administration SchemaTool Supported Features: Apache Hive 3.1+ Hive Metrics HiveCounters Hive APIs Overview UDFs Operators Hive-Iceberg Integration Accumulo Integration Druid Integration Kudu Integration Hive Transactions (HIVE ACID) JDBC Storage Handler Materialized Views Hive Replication Streaming Data Ingest V2 Configuration Defaults HiveDeveloperFAQ Books, Blogs &amp;amp; Talks</description></item><item><title>Apache Hive : Apache Hive SQL Conformance</title><link>https://hive.apache.org/docs/latest/apache-hive-sql-conformance_67641449/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/apache-hive-sql-conformance_67641449/</guid><description>Apache Hive : Apache Hive SQL Conformance This page documents which parts of the SQL standard are supported by Apache Hive. The information here is not a full statement of conformance but provides users detail sufficient to generally understand Hive&amp;rsquo;s SQL conformance.
This information is versioned by Hive release version, allowing a user to quickly identify features available to them.
The formal name of the current SQL standard is ISO/IEC 9075 &amp;ldquo;Database Language SQL&amp;rdquo;.</description></item><item><title>Apache Hive : AuthDev</title><link>https://hive.apache.org/docs/latest/authdev_27362078/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/authdev_27362078/</guid><description>Apache Hive : AuthDev Index
1. Privilege 1.1 Access Privilege 2. Hive Operations 3. Metadata 3.1 user, group, and roles 3.1.1 Role management 3.1.2 role metadata 3.1.3 hive role user membership table 3.2 Privileges to be supported by Hive 3.2.1 metadata 4. grant/revoke access privilege 4.1 Privilege names/types: 4.2 show grant 4.3 grant/revoke statement 5.</description></item><item><title>Apache Hive : AvroSerDe</title><link>https://hive.apache.org/docs/latest/avroserde_27850707/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/avroserde_27850707/</guid><description>Apache Hive : AvroSerDe Availability
Overview – Working with Avro from Hive
Requirements
Avro to Hive type conversion
Creating Avro-backed Hive tables
All Hive versions Hive 0.14 and later versions Writing tables to Avro files
- [Example](#example)+ [All Hive versions](#all-hive-versions) Hive 0.14 and later Avro file extension Specifying the Avro schema for a table</description></item><item><title>Apache Hive : Binary DataType Proposal</title><link>https://hive.apache.org/docs/latest/binary-datatype-proposal_27826614/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/binary-datatype-proposal_27826614/</guid><description>Apache Hive : Binary DataType Proposal Binary Type in Hive Motivation: Hive is designed to work with big data. Often in such cases, a row in a data might be very wide with hundreds of columns. Sometimes, user is just interested in few of those columns and doesn&amp;rsquo;t want to bother about exact type information for rest of columns. In such cases, he may just declare the types of those columns as binary and Hive will not try to interpret those columns.</description></item><item><title>Apache Hive : Books about Hive</title><link>https://hive.apache.org/docs/latest/books-about-hive_61322063/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/books-about-hive_61322063/</guid><description>Apache Hive : Books about Hive These books describe Apache Hive and explain how to use its features. If you know of others that should be listed here, or newer editions, please send a message to the Hive user mailing list or add the information yourself if you have wiki edit privileges. Most links go to the publishers although you can also buy most of these books from bookstores, either online or brick-and-mortar.</description></item><item><title>Apache Hive : Books, Blogs &amp; Talks</title><link>https://hive.apache.org/docs/latest/282102318/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/282102318/</guid><description>Apache Hive : Books, Blogs &amp;amp; Talks Books: Programming Hive by Edward Capriolo, Dean Wampler, and Jason Rutherglen – O&amp;rsquo;Reilly Media, 2012 Apache Hive Essentials by Dayong Du – Packt Publishing, 2015 and 2018 (second edition) Apache Hive Cookbook by Hanish Bansal, Saurabh Chauhan, and Shrey Mehrotra – Packt Publishing, 2016 Instant Apache Hive Essentials How-to by Darren Lee – Packt Publishing, 2013 Practical Hive by Scott Shaw, Andreas François Vermeulen, Ankur Gupta, and David Kjerrumgaard – Apress, 2016 The Ultimate Guide to Programming Apache Hive by Fru Nde – NextGen Publishing, 2015 Learn Hive in 1 Day by Krishna Rungta – independently published, 2017 Books primarily about Hadoop, with some coverage of Hive:</description></item><item><title>Apache Hive : Building Hive from Source</title><link>https://hive.apache.org/docs/latest/building-hive-from-source_282102252/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/building-hive-from-source_282102252/</guid><description>Apache Hive : Building Hive from Source Fetching the source code Using the source tar: Download the source tar from [TODO: Put link post release] and untar From Git tag: Checkout the release tag using git clone &amp;ndash;branch rel/release-4.0.0 https://github.com/apache/hive.git Building Distribution Run: mvn clean install -DskipTests -Pdist -Piceberg -Pitests Find the built tar under packaging/target/apache-hive-* Running Unit Tests Run: mvn clean install -Piceberg Running Integration Tests GoTo itests directory Run: mvn clean test -pl itest -Piceberg</description></item><item><title>Apache Hive : CAST...FORMAT with SQL:2016 datetime formats</title><link>https://hive.apache.org/docs/latest/122917025/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/122917025/</guid><description>Apache Hive : CAST&amp;hellip;FORMAT with SQL:2016 datetime formats Usage CAST(&amp;lt;timestamp/date&amp;gt; AS &amp;lt;varchar/char/string&amp;gt; [FORMAT &amp;lt;template&amp;gt;]) CAST(&amp;lt;varchar/char/string&amp;gt; AS &amp;lt;timestamp/date&amp;gt; [FORMAT &amp;lt;template&amp;gt;]) Example select cast(dt as string format 'DD-MM-YYYY') select cast('01-05-2017' as date format 'DD-MM-YYYY') Template elements, a.k.a. Tokens, a.k.a Patterns a.k.a SQL:2016 Datetime Formats Notes For all tokens:
Patterns are case-insensitive, except AM/PM and T/Z. See these sections for more details. For string to datetime conversion, no duplicate format tokens are allowed, including tokens</description></item><item><title>Apache Hive : ChangeLog</title><link>https://hive.apache.org/docs/latest/changelog_283118275/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/changelog_283118275/</guid><description>Apache Hive : ChangeLog Release 4.0.0 - 2024-03-29 NEW FEATURES: JIRA Summary Priority Component Reporter Contributor HIVE-27850 Iceberg: Major QB Compaction Major Iceberg integration Dmitriy Fingerman Dmitriy Fingerman HIVE-26222 Native GeoSpatial Support in Hive Major Hive, HiveServer2 mahesh kumar behera Ayush Saxena HIVE-27980 Hive Iceberg Compaction: add support for OPTIMIZE TABLE syntax Major . Dmitriy Fingerman Dmitriy Fingerman HIVE-26435 Add method for collecting HMS meta summary Major .</description></item><item><title>Apache Hive : Column Statistics in Hive</title><link>https://hive.apache.org/docs/latest/column-statistics-in-hive_29131019/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/column-statistics-in-hive_29131019/</guid><description>Apache Hive : Column Statistics in Hive *** Introduction
HiveQL changes Metastore Schema Metastore Thrift API** Introduction This document describes changes to a) HiveQL, b) metastore schema, and c) metastore Thrift API to support column level statistics in Hive. Please note that the document doesn’t describe the changes needed to persist histograms in the metastore yet.
Version information
Column statistics are introduced in Hive 0.10.0 by HIVE-1362. This is the design document.</description></item><item><title>Apache Hive : Common Table Expression</title><link>https://hive.apache.org/docs/latest/common-table-expression_38572242/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/common-table-expression_38572242/</guid><description>Apache Hive : Common Table Expression A Common Table Expression (CTE) is a temporary result set derived from a simple query specified in a WITH clause, which immediately precedes a SELECT or INSERT keyword. The CTE is defined only within the execution scope of a single statement. One or more CTEs can be used in a Hive SELECT, INSERT, CREATE TABLE AS SELECT, or CREATE VIEW AS SELECT statement.
Version</description></item><item><title>Apache Hive : Compaction pooling</title><link>https://hive.apache.org/docs/latest/compaction-pooling_240884493/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/compaction-pooling_240884493/</guid><description>Apache Hive : Compaction pooling Concept: Compaction requests and workers can be assigned to pools. A worker assigned to a specific pool will only process compaction requests in that pool. Workers and compaction requests without pool assignment are implicitly belong to the default pool. The pooling concept allows fine tuning of processing compaction requests. For example it is possible to create a pool name &amp;lsquo;high priority compaction&amp;rsquo;, assign some frequently modified tables to it, and dedicate a set of workers to this pool.</description></item><item><title>Apache Hive : CompressedStorage</title><link>https://hive.apache.org/docs/latest/compressedstorage_27362073/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/compressedstorage_27362073/</guid><description>Apache Hive : CompressedStorage Compressed Data Storage Keeping data compressed in Hive tables has, in some cases, been known to give better performance than uncompressed storage; both in terms of disk usage and query performance.
You can import text files compressed with Gzip or Bzip2 directly into a table stored as TextFile. The compression will be detected automatically and the file will be decompressed on-the-fly during query execution. For example:</description></item><item><title>Apache Hive : Configuration Properties</title><link>https://hive.apache.org/docs/latest/configuration-properties_27842758/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/configuration-properties_27842758/</guid><description>Apache Hive : Configuration Properties Hive Configuration Properties Hive Configuration Properties Query and DDL Execution Datetime SerDes and I/O SerDes I/O File Formats RCFile Format ORC File Format Parquet Avro Vectorization MetaStore Hive Metastore Connection Pooling Configuration Hive Metastore HBase HiveServer2 HiveServer2 Web UI Spark Remote Spark Driver Tez LLAP LLAP Client LLAP Web Services LLAP Cache LLAP I/O LLAP CBO LLAP Metrics LLAP UDF Security LLAP Security Transactions and Compactor Transactions Compactor Compaction History Indexing Statistics Runtime Filtering Authentication and Authorization Restricted/Hidden/Internal List and Whitelist Whitelist for SQL Standard Based Hive Authorization Hive Client Security Hive Metastore Security SQL Standard Based Authorization Archiving Locking Metrics Clustering Regions Command Line Interface HBase StorageHandler Hive Web Interface (HWI) (component removed as of Hive 2.</description></item><item><title>Apache Hive : ContributorDay2011</title><link>https://hive.apache.org/docs/latest/contributorday2011_27820725/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/contributorday2011_27820725/</guid><description>Apache Hive : ContributorDay2011 Apache Hive Contributor Day is a special event hosted as part of Yahoo&amp;rsquo;s Hadoop Summit.
Resources for mini-hackathon:
PluginDeveloperKit has info on the new pdk; download this snapshot build of Hive which includes it you&amp;rsquo;ll need a Mac or Linux development environment with Hive+Hadoop already installed on it per these instructions; for Hive, use the snapshot you&amp;rsquo;ll also need Apache ant installed. HIVE-1545 has the UDF libraries we&amp;rsquo;d like to get cleaned up for inclusion in Hive or extension libraries (download core.</description></item><item><title>Apache Hive : ContributorMinutes20110907</title><link>https://hive.apache.org/docs/latest/contributorminutes20110907_27826430/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/contributorminutes20110907_27826430/</guid><description>Apache Hive : ContributorMinutes20110907 Notes from the Hive Meetup at Hortonworks, 9/7/11
Attendees: http://www.meetup.com/Hive-Contributors-Group/events/30620561/
The Binary type proposed by Ashutosh Chauhan, HIVE-2380 was discussed. There was agreement that a design document is needed to explain the proposed changes for this feature. The design document should cover:
Can columns of binary type be used as a key in group by or join? What native functions exist to manipulate binary types? How does casting between binary and other types work?</description></item><item><title>Apache Hive : ContributorMinutes20111205</title><link>https://hive.apache.org/docs/latest/contributorminutes20111205_27833038/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/contributorminutes20111205_27833038/</guid><description>Apache Hive : ContributorMinutes20111205 Notes from the Hive Meetup at Facebook, 12/5/11
Attendees: http://www.meetup.com/Hive-Contributors-Group/events/41150912/
John gave a demo of the Phabricator instance at http://reviews.facebook.net, and proposed that we push through moving all code review over from Review Board to Phabricator (https://cwiki.apache.org/confluence/display/Hive/PhabricatorCodeReview). There were no objections.
Marek gave an overview of the new parallel test framework (https://issues.apache.org/jira/browse/HIVE-1487); he&amp;rsquo;ll publish a wiki page explaining how to use it once it gets committed.</description></item><item><title>Apache Hive : ContributorMinutes20120418</title><link>https://hive.apache.org/docs/latest/contributorminutes20120418_27844528/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/contributorminutes20120418_27844528/</guid><description>Apache Hive : ContributorMinutes20120418 Notes from the Hive Contributors Meetup at Cloudera, 4/18/12
Attendees: http://www.meetup.com/Hive-Contributors-Group/events/59148562/
Ashutosh gave a status update on the Hive 0.9.0 release work. RC0 was put up for a vote last week, but it turned out there were several problems. Ashutosh is in the process of fixing those issues, and is also trying to get several other patches resolved and backported before cutting RC1.
Carl asked for more details about the impact of HIVE-2795 on the upgrade process for 0.</description></item><item><title>Apache Hive : ContributorsMinutes110726</title><link>https://hive.apache.org/docs/latest/contributorsminutes110726_27822784/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/contributorsminutes110726_27822784/</guid><description>Apache Hive : ContributorsMinutes110726 Meeting date: July 26, 2011
Location: Cloudera (Palo Alto)
Attendees: http://www.meetup.com/Hive-Contributors-Group/events/26345541/
Carl proposed end of August as target for 0.8 release, with branch cut in a couple of weeks. Work is still underway for publishing release artifacts in Maven for 0.7.1 and 0.8 (development snapshots are already being published).
Ashutosh gave an update on HCatalog development status; no blocking issues from Hive for the 0.2 release; some ideas are being discussed for the 0.</description></item><item><title>Apache Hive : Copy of Hive Schema Tool - [TODO: move it under a 4.0 admin manual page, find a proper name]</title><link>https://hive.apache.org/docs/latest/284790216/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/284790216/</guid><description>Apache Hive : Copy of Hive Schema Tool - [TODO: move it under a 4.0 admin manual page, find a proper name] About Metastore Schema Verification The Hive Schema Tool The schematool Command Usage Examples About Schema tool helps to initialise and upgrade metastore database and hive sys schema.
Metastore Schema Verification Hive records the schema version in the metastore database and verifies that the metastore schema version is compatible with Hive binaries that are going to access the metastore.</description></item><item><title>Apache Hive : Correlation Optimizer</title><link>https://hive.apache.org/docs/latest/correlation-optimizer_34019487/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/correlation-optimizer_34019487/</guid><description>Apache Hive : Correlation Optimizer This page documents Correlation Optimizer. It was originally introduced by HIVE-2206 and based on the idea of YSmart [1]. To turn on this optimizer, you can use &amp;hellip;
set hive.optimize.correlation=true; 1. Overview In Hadoop environments, an SQL query submitted to Hive will be evaluated in distributed systems. Thus, after generating a query operator tree representing the submitted SQL query, Hive needs to determine what operations can be executed in a task which will be evalauted in a single node.</description></item><item><title>Apache Hive : Cost-based optimization in Hive</title><link>https://hive.apache.org/docs/latest/cost-based-optimization-in-hive_42566775/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/cost-based-optimization-in-hive_42566775/</guid><description>Apache Hive : Cost-based optimization in Hive Abstract 1. INTRODUCTION 2. RELATED WORK 3. BACKGROUND 4. Implementation details 5. Phase 1 – Work Items Open Issues Reference Abstract Apache Hadoop is a framework for the distributed processing of large data sets using clusters of computers typically composed of commodity hardware. Over last few years Apache Hadoop has become the de facto platform for distributed data processing using commodity hardware.</description></item><item><title>Apache Hive : CSV Serde</title><link>https://hive.apache.org/docs/latest/csv-serde_48202659/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/csv-serde_48202659/</guid><description>Apache Hive : CSV Serde Availability Background Usage Versions Availability Earliest version CSVSerde is available
The CSVSerde is available in Hive 0.14 and greater.
Background The CSV SerDe is based on https://github.com/ogrodnek/csv-serde, and was added to the Hive distribution in HIVE-7777.
 Limitation
This SerDe treats all columns to be of type String. Even if you create a table with non-string column types using this SerDe, the DESCRIBE TABLE output would show string column type.</description></item><item><title>Apache Hive : Data Connector for Hive and Hive-like engines</title><link>https://hive.apache.org/docs/latest/data-connector-for-hive-and-hive-like-engines_288885794/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/data-connector-for-hive-and-hive-like-engines_288885794/</guid><description>Apache Hive : Data Connector for Hive and Hive-like engines What is a Data connector? Data connectors (referred to as &amp;ldquo;connector&amp;rdquo; in Hive Query Language) are top level objects in Hive where users can define a set of properties required to be able to connect to an external datasource from hive. This document illustrates example of the data connector framework can be used to do SQL query federation between two distinct &amp;ldquo;hive&amp;rdquo; clusters/installations or between Hive and another hive-like compute engines (eg: EMR).</description></item><item><title>Apache Hive : Data Connectors in Hive</title><link>https://hive.apache.org/docs/latest/data-connectors-in-hive_177049669/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/data-connectors-in-hive_177049669/</guid><description>Apache Hive : Data Connectors in Hive What is a Data connector? Data connectors (referred to as &amp;ldquo;connector&amp;rdquo; in Hive Query Language) are top level objects in Hive where users can define a set of properties required to be able to connect to a datasource from hive. So a connector has a type (closed enumerated set) that allows Hive to determine the driver class (for JDBC) and other URL params, a URL and a set of properties that could include the default credentials for the remote datasource.</description></item><item><title>Apache Hive : Datasketches Integration</title><link>https://hive.apache.org/docs/latest/datasketches-integration_177050456/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/datasketches-integration_177050456/</guid><description>Apache Hive : Datasketches Integration Sketch functions Naming convention List declared sketch functions Integration with materialized views BI mode Rewrite COUNT(DISTINCT(X)) Rewrite percentile_disc(p) withing group(order by x) Rewrite cume_dist() over (order by id) Rewrite NTILE Rewrite RANK Examples Simple distinct counting examples using HLL Apache DataSketches (https://datasketches.apache.org/) is integrated into Hive via HIVE-22939.
This enables various kind of sketch operations thru regular sql statement.</description></item><item><title>Apache Hive : Default Constraint (HIVE-18726)</title><link>https://hive.apache.org/docs/latest/75969407/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/75969407/</guid><description>Apache Hive : Default Constraint (HIVE-18726) Introduction This document proposes the addition of DEFAULT clause to Hive. DEFAULT clause is a domain constraint which lets user specify a value for domain i.e. column to be used in absence of user specified value i.e. in absence of column reference. Note that this does not propose to implement DEFAULT ON NULL like ORACLE which lets user specify DEFAULT value for explicit NULLs.</description></item><item><title>Apache Hive : DEFAULT Keyword (HIVE-19059)</title><link>https://hive.apache.org/docs/latest/75977362/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/75977362/</guid><description>Apache Hive : DEFAULT Keyword (HIVE-19059) Goal We propose to add DEFAULT keyword in INSERT INTO, UPDATE and MERGE statements to let user add DEFAULT values without specifying column schema.
Background With the addition of DEFAULT constraint (HIVE-18726) user can define columns to have default value which will be used in case user doesn’t explicitly specify it while INSERTING data. For DEFAULT constraint to kick in user has to explicitly specify column schema leaving out the column name for which user would like the sytem to use DEFAULT value.</description></item><item><title>Apache Hive : Dependent Tables</title><link>https://hive.apache.org/docs/latest/dependent-tables_30151205/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/dependent-tables_30151205/</guid><description>Apache Hive : Dependent Tables Hive supports both partitioned and unpartitioned external tables. In both cases, when a new table/partition is being added, the location is also specified for the new table/partition. Let us consider a specific example:
create table T (key string, value string) partitioned by (ds string, hr string);
insert overwrite table T partition (ds=&amp;lsquo;1&amp;rsquo;, hr=&amp;lsquo;1&amp;rsquo;) &amp;hellip;;
..
insert overwrite table T partition (ds=&amp;lsquo;1&amp;rsquo;, hr=&amp;lsquo;24&amp;rsquo;) &amp;hellip;;
T is a partitioned table by date and hour, and Tsignal is an external table which conceptually denotes the creation of the signal table.</description></item><item><title>Apache Hive : Design</title><link>https://hive.apache.org/docs/latest/design_27362072/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/design_27362072/</guid><description>Apache Hive : Design This page contains details about the Hive design and architecture. A brief technical report about Hive is available at hive.pdf.
Hive Architecture Hive Data Model Metastore Motivation Metadata Objects Metastore Architecture Metastore Interface Hive Query Language Compiler Optimizer Hive APIs Figure 1
Hive Architecture Figure 1 shows the major components of Hive and its interactions with Hadoop. As shown in that figure, the main components of Hive are:</description></item><item><title>Apache Hive : DesignDocs</title><link>https://hive.apache.org/docs/latest/designdocs_27362075/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/designdocs_27362075/</guid><description>Apache Hive : DesignDocs Hive Design Documents Proposals that appear in the &amp;ldquo;Completed&amp;rdquo; and &amp;ldquo;In Progress&amp;rdquo; sections should include a link to a JIRA ticket
Completed Views (HIVE-1143) Partitioned Views (HIVE-1941) Storage Handlers (HIVE-705) HBase Integration HBase Bulk Load Locking (HIVE-1293) Indexes (HIVE-417) Bitmap Indexes (HIVE-1803) Filter Pushdown (HIVE-279) Table-level Statistics (HIVE-1361) Dynamic Partitions Binary Data Type (HIVE-2380) Decimal Precision and Scale Support HCatalog (formerly Howl) HiveServer2 (HIVE-2935) Column Statistics in Hive (HIVE-1362) List Bucketing (HIVE-3026) Group By With Rollup (HIVE-2397) Enhanced Aggregation, Cube, Grouping and Rollup (HIVE-3433) Optimizing Skewed Joins (HIVE-3086) Correlation Optimizer (HIVE-2206) Hive on Tez (HIVE-4660) Hive-Tez Compatibility Vectorized Query Execution (HIVE-4160) Cost Based Optimizer in Hive (HIVE-5775) Atomic Insert/Update/Delete (HIVE-5317) Transaction Manager (HIVE-5843) SQL Standard based secure authorization (HIVE-5837) Hybrid Hybrid Grace Hash Join (HIVE-9277) LLAP Daemons (HIVE-7926) Support for Hive Replication (HIVE-7973) In Progress Column Level Top K Statistics (HIVE-3421) Hive on Spark (HIVE-7292) Hive on Spark: Join Design (HIVE-7613) Improve ACID Performance – download docx file (HIVE-14035, HIVE-14199, HIVE-14233) Query Results Caching (HIVE-18513) Default Constraint (HIVE-18726) Different TIMESTAMP types (HIVE-21348) Support SAML 2.</description></item><item><title>Apache Hive : DeveloperDocs</title><link>https://hive.apache.org/docs/latest/developerdocs_42568263/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/developerdocs_42568263/</guid><description>Apache Hive : DeveloperDocs Hive Developer Documentation Information for Hive developers is available in these documents:
Hive Developer Guide Code organization and architecture Compiling and running Hive Unit tests Debugging Hive code Pluggable interfaces Hive Developer FAQ Moving files Building Hive Testing Hive Plugin Developer Kit Writing UDTFs Hive on Spark: Getting Started</description></item><item><title>Apache Hive : DeveloperGuide</title><link>https://hive.apache.org/docs/latest/developerguide_27362074/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/developerguide_27362074/</guid><description>Apache Hive : DeveloperGuide Code Organization and a Brief Architecture Introduction Hive SerDe MetaStore Query Processor Compiling and Running Hive Default Mode Advanced Mode Running Hive Without a Hadoop Cluster Unit tests and debugging Layout of the unit tests Debugging Hive Code Pluggable interfaces File Formats SerDe - how to add a new SerDe Map-Reduce Scripts UDFs and UDAFs - how to add new UDFs and UDAFs Code Organization and a Brief Architecture Introduction Hive has 3 main components:</description></item><item><title>Apache Hive : DeveloperGuide UDTF</title><link>https://hive.apache.org/docs/latest/developerguide-udtf_27362086/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/developerguide-udtf_27362086/</guid><description>Apache Hive : DeveloperGuide UDTF Writing UDTF&amp;rsquo;s Writing UDTF&amp;rsquo;s GenericUDTF Interface GenericUDTF Interface A custom UDTF can be created by extending the GenericUDTF abstract class and then implementing the initialize, process, and possibly close methods. The initialize method is called by Hive to notify the UDTF the argument types to expect. The UDTF must then return an object inspector corresponding to the row objects that the UDTF will generate.</description></item><item><title>Apache Hive : Development ContributorsMeetings</title><link>https://hive.apache.org/docs/latest/development-contributorsmeetings_27362087/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/development-contributorsmeetings_27362087/</guid><description>Apache Hive : Development ContributorsMeetings Hive Contributors Meetings Active contributors to the Hive project are invited to attend the monthly Hive Contributors Meeting. Meetings are announced on the Hive Contributors meetup group.
Meeting Minutes April 18, 2012 December 5, 2011 September 7, 2011 July 26, 2011 June 30, 2011 April 25, 2011 January 11, 2011 (forgot to take notes) October 25, 2010 September 13, 2010 August 8, 2010 July 6, 2010 June 1, 2010</description></item><item><title>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100601</title><link>https://hive.apache.org/docs/latest/development-contributorsmeetings-hivecontributorsminutes100601_27362084/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/development-contributorsmeetings-hivecontributorsminutes100601_27362084/</guid><description>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100601 Notes provided by Namit Jain.
The following people were present:
Facebook (Paul Yang; Ning Zhang; Yongqiang He; Ahmed Aly; John Sichi; Ashish Thusoo; Namit Jain) Netflix (Eva Tse; Jerome Boulon) Cloudera (Arvind Prabhakar; Vinithra Varadharajan; Carl Steinbach) Yahoo (Alan Gates) The following were the main meeting minutes:
We should have these meetings more often, say every month. Cloudera will host the next meeting.</description></item><item><title>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100706</title><link>https://hive.apache.org/docs/latest/development-contributorsmeetings-hivecontributorsminutes100706_27362085/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/development-contributorsmeetings-hivecontributorsminutes100706_27362085/</guid><description>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100706 Attendees: Amr Awadallah, John Sichi, Paul Yang, Olga Natkovich, Ajay Kidave, Yongqiang He, Basab Malik, Vinithra Varadharajan, bc Wong, Arvind Prabhakar, Carl Steinbach
bc Wong gave a live demo of Cloudera&amp;rsquo;s Hue framework and the Beeswax Hive web interface. Slides from this talk are available here: http://www.slideshare.net/cwsteinbach/cloudera-huebeeswax Hue was recently released as open source. The code is available on Github here: http://github.com/cloudera/hue Olga Natkovich gave a whiteboard talk on HOwl.</description></item><item><title>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100808</title><link>https://hive.apache.org/docs/latest/development-contributorsmeetings-hivecontributorsminutes100808_27362082/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/development-contributorsmeetings-hivecontributorsminutes100808_27362082/</guid><description>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100808 August 8th, 2010
Yongqiang He gave a presentation about his work on index support in Hive. Slides are available here: http://files.meetup.com/1658206/Hive%20Index.pptx John Sichi talked about his work on filter-pushdown optimizations. This is applicable to the HBase storage handler and the new index infrastructure. Pradeep Kamath gave an update on progress with Howl. The Howl source code is available on GitHub here: http://github.</description></item><item><title>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100913</title><link>https://hive.apache.org/docs/latest/development-contributorsmeetings-hivecontributorsminutes100913_27362083/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/development-contributorsmeetings-hivecontributorsminutes100913_27362083/</guid><description>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100913 Meeting date: Sept 13, 2010
Location: Cloudera Palo Alto office
Attendees: http://www.meetup.com/Hive-Contributors-Group/calendar/14689507/
Carl Steinbach gave a status update on the 0.6 release. Since plans for documentation migration have been deferred to the next release, the only remaining issues are completion of the CREATE DATABASE feature (HIVE-675), metastore VARCHAR precision widening (HIVE-1364), and metastore upgrade scripts (HIVE-1427). HIVE-675 has already been committed to trunk and the backport for 0.</description></item><item><title>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes101025</title><link>https://hive.apache.org/docs/latest/development-contributorsmeetings-hivecontributorsminutes101025_27362080/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/development-contributorsmeetings-hivecontributorsminutes101025_27362080/</guid><description>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes101025 Meeting date: October 25, 2010
Location: Facebook Palo Alto
Attendees: http://www.meetup.com/Hive-Contributors-Group/calendar/14875663 plus Paul, Ning, Yongqiang, Liyin, Basab
The TLP and bylaws votes passed, so Hive is now officially an Apache top level project! We are going ahead with moving the following resources:
website (now at hive.apache.org) svn (new trunk location is http://svn.apache.org/repos/asf/hive/trunk); git will follow soon irc: we are making #hive the official channel on freenode.</description></item><item><title>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes110425</title><link>https://hive.apache.org/docs/latest/development-contributorsmeetings-hivecontributorsminutes110425_27362081/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/development-contributorsmeetings-hivecontributorsminutes110425_27362081/</guid><description>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes110425 Meeting date: April 25, 2011
Location: Facebook Palo Alto
Attendees: http://www.meetup.com/Hive-Contributors-Group/events/17272914/
The 0.7 release is out, and Carl proposed an 0.7.1 release for items such as PostgreSQL metastore upgrade scripts and Maven artifact publication. Rules for a point release were discussed: no metastore changes, and no changes to API&amp;rsquo;s such as Thrift and extension interfaces. Everyone was fine with this; Carl will manage the release.</description></item><item><title>Apache Hive : Different TIMESTAMP types</title><link>https://hive.apache.org/docs/latest/different-timestamp-types_103091503/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/different-timestamp-types_103091503/</guid><description>Apache Hive : Different TIMESTAMP types Overview The following overview depicts the desired timestamp semantics in comparison to the SQL standard and selected database vendors:
TIMESTAMP and TIMESTAMP WITHOUT TIME ZONE The TIMESTAMP and TIMESTAMP WITHOUT TIME ZONE types shall behave like the LocalDateTime class of Java, i.e., each value is a recording of what can be seen on a calendar and a clock hanging on the wall, for example &amp;ldquo;1969-07-20 16:17:39&amp;rdquo;.</description></item><item><title>Apache Hive : Druid Integration</title><link>https://hive.apache.org/docs/latest/druid-integration_65866491/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/druid-integration_65866491/</guid><description>Apache Hive : Druid Integration Introduction Objectives Preliminaries Druid Storage Handlers Usage Discovery and management of Druid datasources from Hive Create tables linked to existing Druid datasources Create Druid datasources from Hive Druid kafka ingestion from Hive Start/Stop/Reset Druid Kafka ingestion INSERT, INSERT OVERWRITE and DROP statements Queries completely executed in Druid Select queries Timeseries queries GroupBy queries Queries across Druid and Hive Open Issues (JIRA)  Version information</description></item><item><title>Apache Hive : DynamicPartitions</title><link>https://hive.apache.org/docs/latest/dynamicpartitions_27823715/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/dynamicpartitions_27823715/</guid><description>Apache Hive : DynamicPartitions Dynamic Partitions Dynamic Partitions Documentation Terminology Syntax Design Design issues Documentation This is the design document for dynamic partitions in Hive. Usage information is also available:
Tutorial: Dynamic-Partition Insert Hive DML: Dynamic Partition Inserts HCatalog Dynamic Partitioning Usage with Pig Usage from MapReduce References:
Original design doc HIVE-936 Terminology Static Partition (SP) columns: in DML/DDL involving multiple partitioning columns, the columns whose values are known at COMPILE TIME (given by user).</description></item><item><title>Apache Hive : Enabling gRPC in Hive/Hive Metastore (Proposal)</title><link>https://hive.apache.org/docs/latest/158869886/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/158869886/</guid><description>Apache Hive : Enabling gRPC in Hive/Hive Metastore (Proposal) Contacts: Cameron Moberg (Google), Zhou Fang (Google), Feng Lu (Google), Thejas Nair (Cloudera), Vihang Karajgaonkar (Cloudera), Naveen Gangam (Cloudera)
Last upated: 7/31/2020
Objective Background Design Overview Implementation Pluggable gRPC Support Hive Metastore Server Class Change Config Changes Hive Metastore Client Class Change Configuration Changes Summary Future Work Objective To modernize Hive Metastore’s interface with a state-of-the-art serving layer based on gRPC while also keeping it backwards compatible with Thrift for minimal upgrade toil; To achieve this the proposed design is to add support for a proxy-layer between the Thrift interface and a new gRPC interface that allows for in-memory request/response translation in-between; To expand the Hive client to work with Hive Metastore server in both gRPC and Thrift mode.</description></item><item><title>Apache Hive : Enhanced Aggregation, Cube, Grouping and Rollup</title><link>https://hive.apache.org/docs/latest/30151323/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/30151323/</guid><description>Apache Hive : Enhanced Aggregation, Cube, Grouping and Rollup This document describes enhanced aggregation features for the GROUP BY clause of SELECT statements.
GROUPING SETS clause Grouping__ID function Grouping function Cubes and Rollups hive.new.job.grouping.set.cardinality Grouping__ID function (before Hive 2.3.0) Version
Grouping sets, CUBE and ROLLUP operators, and the GROUPING__ID function were added in Hive 0.10.0.
See HIVE-2397, HIVE-3433, HIVE-3471, and HIVE-3613.
Also see HIVE-3552 for an improvement added in Hive 0.</description></item><item><title>Apache Hive : Exchange Partition</title><link>https://hive.apache.org/docs/latest/exchange-partition_30755801/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/exchange-partition_30755801/</guid><description>Apache Hive : Exchange Partition The EXCHANGE PARTITION command will move a partition from a source table to target table and alter each table&amp;rsquo;s metadata. The Exchange Partition feature is implemented as part of HIVE-4095. Exchanging multiple partitions is supported in Hive versions 1.2.2, 1.3.0, and 2.0.0+ as part of HIVE-11745.
When the command is executed, the source table&amp;rsquo;s partition folder in HDFS will be renamed to move it to the destination table&amp;rsquo;s partition folder.</description></item><item><title>Apache Hive : FileFormats</title><link>https://hive.apache.org/docs/latest/fileformats_47384180/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/fileformats_47384180/</guid><description>Apache Hive : FileFormats File Formats and Compression File Formats Hive supports several file formats:
Text File SequenceFile RCFile Avro Files ORC Files Parquet Custom INPUTFORMAT and OUTPUTFORMAT The hive.default.fileformat configuration parameter determines the format to use if it is not specified in a CREATE TABLE or ALTER TABLE statement. Text file is the parameter&amp;rsquo;s default value.
For more information, see the sections Storage Formats and Row Formats &amp;amp; SerDe on the DDL page.</description></item><item><title>Apache Hive : FilterPushdownDev</title><link>https://hive.apache.org/docs/latest/filterpushdowndev_27362092/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/filterpushdowndev_27362092/</guid><description>Apache Hive : FilterPushdownDev Filter Pushdown Filter Pushdown Introduction Use Cases Components Involved Primary Filter Representation Other Filter Representations Filter Passing Filter Collection Filter Decomposition Introduction This document explains how we are planning to add support in Hive&amp;rsquo;s optimizer for pushing filters down into physical access methods. This is an important optimization for minimizing the amount of data scanned and processed by an access method (e.</description></item><item><title>Apache Hive : GenericUDAFCaseStudy</title><link>https://hive.apache.org/docs/latest/genericudafcasestudy_27362093/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/genericudafcasestudy_27362093/</guid><description>Apache Hive : GenericUDAFCaseStudy Writing GenericUDAFs: A Tutorial User-Defined Aggregation Functions (UDAFs) are an excellent way to integrate advanced data-processing into Hive. Hive allows two varieties of UDAFs: simple and generic. Simple UDAFs, as the name implies, are rather simple to write, but incur performance penalties because of the use of Java Reflection, and do not allow features such as variable-length argument lists. Generic UDAFs allow all these features, but are perhaps not quite as intuitive to write as Simple UDAFs.</description></item><item><title>Apache Hive : GettingStarted</title><link>https://hive.apache.org/docs/latest/gettingstarted_27362090/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/gettingstarted_27362090/</guid><description>Apache Hive : GettingStarted Table of Contents
Installation and Configuration
- [Running HiveServer2 and Beeline](#running-hiveserver2-and-beeline)+ [Requirements](#requirements) Installing Hive from a Stable Release Building Hive from Source Compile Hive on master Compile Hive on branch-1 Compile Hive Prior to 0.13 on Hadoop 0.20 Compile Hive Prior to 0.13 on Hadoop 0.23 Running Hive Running Hive CLI Running HiveServer2 and Beeline Running HCatalog Running WebHCat (Templeton) Configuration Management Overview Runtime Configuration Hive, Map-Reduce and Local-Mode Hive Logging HiveServer2 Logs Audit Logs Perf Logger DDL Operations</description></item><item><title>Apache Hive : GettingStarted EclipseSetup</title><link>https://hive.apache.org/docs/latest/gettingstarted-eclipsesetup_27362091/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/gettingstarted-eclipsesetup_27362091/</guid><description>Apache Hive : GettingStarted EclipseSetup Page does not apply to trunk
The following page only applies to branch-0.12 and earlier. For trunk see HiveDeveloperFAQ
After checking out the source code run the following command from the top-level directory:
$ ant clean package eclipse-files Now open up Eclipse and do the following:
File-&amp;gt;Import-&amp;gt;General-&amp;gt;Existing Projects Into Workspace-&amp;gt;Select root directory (point to ) Make sure that Eclipse Java Compiler is in 1.</description></item><item><title>Apache Hive : GroupByWithRollup</title><link>https://hive.apache.org/docs/latest/groupbywithrollup_27826238/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/groupbywithrollup_27826238/</guid><description>Apache Hive : GroupByWithRollup Group By With Rollup References:
Original design doc
HIVE-2397
Group By With Rollup Terminology Design Map Aggr &amp;amp; No Skew: Map Aggr &amp;amp; Skew No Map Aggr &amp;amp; No Skew &amp;amp; No Rollup No Map Aggr &amp;amp; No Skew &amp;amp; With Rollup No Map Aggr &amp;amp; Skew &amp;amp; (No Distinct or No Rollup) No Map Aggr &amp;amp; Skew &amp;amp; Distinct &amp;amp; Rollup Terminology (No) Map Aggr: Shorthand for whether the configuration variable hive.</description></item><item><title>Apache Hive : Hadoop-compatible Input-Output Format for Hive</title><link>https://hive.apache.org/docs/latest/hadoop-compatible-input-output-format-for-hive_30745805/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hadoop-compatible-input-output-format-for-hive_30745805/</guid><description>Apache Hive : Hadoop-compatible Input-Output Format for Hive Overview This is a proposal for adding API to Hive which allows reading and writing using a Hadoop compatible API. Specifically, the interfaces being implemented are:
InputFormat: http://hadoop.apache.org/docs/mapreduce/r0.21.0/api/org/apache/hadoop/mapreduce/InputFormat.html OutputFormat: http://hadoop.apache.org/docs/mapreduce/r0.21.0/api/org/apache/hadoop/mapreduce/OutputFormat.html The classes will be named HiveApiInputFormat and HiveApiOutputFormat.
See HIVE-3752 for discussion of this proposal.
InputFormat (reading from Hive) Usage:
Create a HiveInputDescription object. Fill it with information about the table to read from (with database, partition, columns).</description></item><item><title>Apache Hive : Hbase execution plans for RawStore partition filter condition</title><link>https://hive.apache.org/docs/latest/hbase-execution-plans-for-rawstore-partition-filter-condition_55151993/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hbase-execution-plans-for-rawstore-partition-filter-condition_55151993/</guid><description>Apache Hive : Hbase execution plans for RawStore partition filter condition (Apologies for this doc being organized properly, I thought something is better than nothing - Thejas)
This is part of metastore on hbase work - HIVE-9452 Use HBase to store Hive metadata Open
Functionality needed
RawStore functions that support partition filtering are the following -
getPartitionsByExpr getPartitionsByFilter (takes filter string as argument, used from hcatalog) We need to generate a query execution plan in terms of Hbase scan api calls for a given filter condition.</description></item><item><title>Apache Hive : HBaseBulkLoad</title><link>https://hive.apache.org/docs/latest/hbasebulkload_27362088/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hbasebulkload_27362088/</guid><description>Apache Hive : HBaseBulkLoad Hive HBase Bulk Load Hive HBase Bulk Load Overview Decide on Target HBase Schema Estimate Resources Needed Add necessary JARs Prepare Range Partitioning Prepare Staging Location Sort Data Run HBase Script Map New Table Back Into Hive Followups Needed This page explains how to use Hive to bulk load data into a new (empty) HBase table per HIVE-1295. (If you&amp;rsquo;re not using a build which contains this functionality yet, you&amp;rsquo;ll need to build from source and make sure this patch and HIVE-1321 are both applied.</description></item><item><title>Apache Hive : HBaseIntegration</title><link>https://hive.apache.org/docs/latest/hbaseintegration_27362089/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hbaseintegration_27362089/</guid><description>Apache Hive : HBaseIntegration Hive HBase Integration Hive HBase Integration
- [Avro Data Stored in HBase Columns](#avro-data-stored-in-hbase-columns)+ [Introduction](#introduction) Storage Handlers Usage Column Mapping Multiple Columns and Families Hive MAP to HBase Column Family Hive MAP to HBase Column Prefix Hiding Column Prefixes Illegal: Hive Primitive to HBase Column Family Example with Binary Columns Simple Composite Row Keys Complex Composite Row Keys and HBaseKeyFactory Avro Data Stored in HBase Columns Put Timestamps Key Uniqueness Overwrite Potential Followups Build Tests Links Acknowledgements Open Issues (JIRA) Version information</description></item><item><title>Apache Hive : HBaseMetastoreDevelopmentGuide</title><link>https://hive.apache.org/docs/latest/hbasemetastoredevelopmentguide_55151960/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hbasemetastoredevelopmentguide_55151960/</guid><description>Apache Hive : HBaseMetastoreDevelopmentGuide  Guide for contributors to the metastore on hbase development work. Umbrella JIRA - HIVE-9452
This work is discontinued and the code is removed in release 3.0.0 (HIVE-17234).
  Building Setup for running hive against hbase metastore - Importing metadata from rdbms to hbase Design Docs Building You will need to download the source for Tephra and build it from the develop branch. You need Tephra 0.</description></item><item><title>Apache Hive : HCatalog</title><link>https://hive.apache.org/docs/latest/hcatalog_33299065/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog_33299065/</guid><description>Apache Hive : HCatalog HCatalog is a table and storage management layer for Hadoop that enables users with different data processing tools — Pig, MapReduce — to more easily read and write data on the grid.
This is the HCatalog manual. Using HCatalog Installation from Tarball HCatalog Configuration Properties Load and Store Interfaces Input and Output Interfaces Reader and Writer Interfaces Command Line Interface Storage Formats Dynamic Partitioning Notification Storage Based Authorization The old HCatalog wiki page has many other documents including additional user documentation, further information on HBase integration, and resources for contributors.</description></item><item><title>Apache Hive : HCatalog Authorization</title><link>https://hive.apache.org/docs/latest/hcatalog-authorization_34014782/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog-authorization_34014782/</guid><description>Apache Hive : HCatalog Authorization Storage Based Authorization Storage Based Authorization Default Authorization Model of Hive Storage-System Based Authorization Model Minimum Permissions Unused DDL for Permissions Configuring Storage-System Based Authorization Creating New Tables or Databases Known Issues Default Authorization Model of Hive The default authorization model of Hive supports a traditional RDBMS style of authorization based on users, groups and roles and granting them permissions to do operations on database or table.</description></item><item><title>Apache Hive : HCatalog CLI</title><link>https://hive.apache.org/docs/latest/hcatalog-cli_34013932/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog-cli_34013932/</guid><description>Apache Hive : HCatalog CLI Command Line Interface Command Line Interface Set Up HCatalog CLI Owner Permissions Hive CLI HCatalog DDL Create/Drop/Alter Table Create/Drop/Alter View Show/Describe Create/Drop Index Create/Drop Function &amp;ldquo;dfs&amp;rdquo; Command and &amp;ldquo;set&amp;rdquo; Command Other Commands CLI Errors Authentication Error Log Set Up The HCatalog command line interface (CLI) can be invoked as HIVE_HOME=hive_home hcat_home/bin/hcat where hive_home is the directory where Hive has been installed and hcat_home is the directory where HCatalog has been installed.</description></item><item><title>Apache Hive : HCatalog Configuration Properties</title><link>https://hive.apache.org/docs/latest/hcatalog-configuration-properties_39622369/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog-configuration-properties_39622369/</guid><description>Apache Hive : HCatalog Configuration Properties Setup Storage Directives Cache Behaviour Directives Input Split Generation Behaviour Data Promotion Behaviour HCatRecordReader Error Tolerance Behaviour Apache HCatalog&amp;rsquo;s behaviour can be modified through the use of a few configuration parameters specified in jobs submitted to it. This document details all the various knobs that users have available to them, and what they accomplish. Setup The properties described in this page are meant to be job-level properties set on HCatalog through the jobConf passed into it.</description></item><item><title>Apache Hive : HCatalog DynamicPartitions</title><link>https://hive.apache.org/docs/latest/hcatalog-dynamicpartitions_34014006/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog-dynamicpartitions_34014006/</guid><description>Apache Hive : HCatalog DynamicPartitions Dynamic Partitioning Dynamic Partitioning Overview External Tables Hive Dynamic Partitions Usage with Pig Usage from MapReduce Overview When writing data in HCatalog it is possible to write all records to a single partition. In this case the partition column(s) need not be in the output data.
The following Pig script illustrates this:
A = load 'raw' using HCatLoader(); .</description></item><item><title>Apache Hive : HCatalog InputOutput</title><link>https://hive.apache.org/docs/latest/hcatalog-inputoutput_34013776/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog-inputoutput_34013776/</guid><description>Apache Hive : HCatalog InputOutput Input and Output Interfaces Input and Output Interfaces Set Up HCatInputFormat API HCatOutputFormat API HCatRecord Running MapReduce with HCatalog Authentication Read Example Filter Operators Scan Filter Write Filter Set Up No HCatalog-specific setup is required for the HCatInputFormat and HCatOutputFormat interfaces.
Note: HCatalog is not thread safe.
HCatInputFormat The HCatInputFormat is used with MapReduce jobs to read data from HCatalog-managed tables.</description></item><item><title>Apache Hive : HCatalog InstallHCat</title><link>https://hive.apache.org/docs/latest/hcatalog-installhcat_34013403/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog-installhcat_34013403/</guid><description>Apache Hive : HCatalog InstallHCat Installation from Tarball Installation from Tarball HCatalog Installed with Hive HCatalog Command Line HCatalog Client Jars HCatalog Server HCatalog Installed with Hive Version
HCatalog is installed with Hive, starting with Hive release 0.11.0.
Hive installation is documented here.
HCatalog Command Line If you install Hive from the binary tarball, the hcat command is available in the hcatalog/bin directory.
The hcat command line is similar to the hive command line; the main difference is that it restricts the queries that can be run to metadata-only operations such as DDL and DML queries used to read metadata (for example, &amp;ldquo;show tables&amp;rdquo;).</description></item><item><title>Apache Hive : HCatalog LoadStore</title><link>https://hive.apache.org/docs/latest/hcatalog-loadstore_34013511/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog-loadstore_34013511/</guid><description>Apache Hive : HCatalog LoadStore Load and Store Interfaces Load and Store Interfaces Set Up Running Pig HCatLoader Usage Assumptions HCatLoader Data Types Types in Hive 0.12.0 and Earlier Types in Hive 0.13.0 and Later Running Pig with HCatalog The -useHCatalog Flag Jars and Configuration Files Authentication Load Examples Filter Operators HCatStorer Usage Assumptions Store Examples HCatStorer Data Types Types in Hive 0.</description></item><item><title>Apache Hive : HCatalog Notification</title><link>https://hive.apache.org/docs/latest/hcatalog-notification_34014558/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog-notification_34014558/</guid><description>Apache Hive : HCatalog Notification Notification Notification Notification for a New Partition Notification for a Set of Partitions Server Configuration Enable JMS Notifications Topic Names Since version 0.2, HCatalog provides notifications for certain events happening in the system. This way applications such as Oozie can wait for those events and schedule the work that depends on them. The current version of HCatalog supports two kinds of events:</description></item><item><title>Apache Hive : HCatalog ReaderWriter</title><link>https://hive.apache.org/docs/latest/hcatalog-readerwriter_34013921/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog-readerwriter_34013921/</guid><description>Apache Hive : HCatalog ReaderWriter Reader and Writer Interfaces Reader and Writer Interfaces Overview HCatReader HCatWriter Complete Example Program Overview HCatalog provides a data transfer API for parallel input and output without using MapReduce. This API provides a way to read data from a Hadoop cluster or write data into a Hadoop cluster, using a basic storage abstraction of tables and rows.
The data transfer API has three essential classes:</description></item><item><title>Apache Hive : HCatalog StorageFormats</title><link>https://hive.apache.org/docs/latest/hcatalog-storageformats_34013997/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog-storageformats_34013997/</guid><description>Apache Hive : HCatalog StorageFormats Storage Formats Storage Formats SerDes and Storage Formats Usage from Hive CTAS Issue with JSON SerDe SerDes and Storage Formats HCatalog uses Hive&amp;rsquo;s SerDe class to serialize and deserialize data. SerDes are provided for RCFile, CSV text, JSON text, and SequenceFile formats. Check the SerDe documentation for additional SerDes that might be included in new versions. For example, the Avro SerDe was added in Hive 0.</description></item><item><title>Apache Hive : HCatalog Streaming Mutation API</title><link>https://hive.apache.org/docs/latest/hcatalog-streaming-mutation-api_61337025/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog-streaming-mutation-api_61337025/</guid><description>Apache Hive : HCatalog Streaming Mutation API A Java API focused on mutating (insert/update/delete) records into transactional tables using Hive’s ACID feature. It is introduced in Hive 2.0.0 (HIVE-10165).
Background Structure Data Requirements Streaming Requirements Record Layout Connection and Transaction Management Writing Data Dynamic Partition Creation Reading Data Example Background In certain data processing use cases it is necessary to modify existing data when new facts arrive.</description></item><item><title>Apache Hive : HCatalog Streaming Mutation API (Copy)</title><link>https://hive.apache.org/docs/latest/283118454/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/283118454/</guid><description>Apache Hive : HCatalog Streaming Mutation API (Copy) A Java API focused on mutating (insert/update/delete) records into transactional tables using Hive’s ACID feature. It is introduced in Hive 2.0.0 (HIVE-10165).
Background Structure Data Requirements Streaming Requirements Record Layout Connection and Transaction Management Writing Data Dynamic Partition Creation Reading Data Example Background In certain data processing use cases it is necessary to modify existing data when new facts arrive.</description></item><item><title>Apache Hive : HCatalog UsingHCat</title><link>https://hive.apache.org/docs/latest/hcatalog-usinghcat_34013260/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog-usinghcat_34013260/</guid><description>Apache Hive : HCatalog UsingHCat Using HCatalog Using HCatalog Overview HCatalog Architecture Interfaces Data Model Data Flow Example First: Copy Data to the Grid Second: Prepare the Data Third: Analyze the Data HCatalog Web API Version information
HCatalog graduated from the Apache incubator and merged with the Hive project on March 26, 2013.
Hive version 0.11.0 is the first release that includes HCatalog.</description></item><item><title>Apache Hive : Hive across Multiple Data Centers (Physical Clusters)</title><link>https://hive.apache.org/docs/latest/27837073/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/27837073/</guid><description>Apache Hive : Hive across Multiple Data Centers (Physical Clusters) This project has been abandoned. We&amp;rsquo;re leaving the design doc here in case someone decides to attempt this project in the future.
Use Cases Requirements Use Cases Inside facebook, we are running out of power inside a data center (physical cluster), and we have a need to have a bigger cluster.
We can divide the cluster into multiple clusters - multiple hive instances, multiple mr and multiple dfs.</description></item><item><title>Apache Hive : Hive APIs Overview</title><link>https://hive.apache.org/docs/latest/hive-apis-overview_61326349/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-apis-overview_61326349/</guid><description>Apache Hive : Hive APIs Overview This page aims to catalogue and describe the various public facing APIs exposed by Hive in order to inform developers wishing to integrate their applications and frameworks with the Hive ecosystem. To date the following APIs have been identified in the Hive project that are either considered public, or widely used in the public domain:
API categories Operation based APIs Query based APIs Available APIs HCatClient (Java) HCatalog Storage Handlers (Java) HCatalog CLI (Command Line) Metastore (Java) WebHCat (REST) Streaming Data Ingest (Java) Streaming Mutation (Java) hive-jdbc (JDBC) API categories The APIs can be segmented into two conceptual categories: operation based APIs and query based APIs.</description></item><item><title>Apache Hive : Hive Aws EMR</title><link>https://hive.apache.org/docs/latest/hive-aws-emr_27823791/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-aws-emr_27823791/</guid><description>Apache Hive : Hive Aws EMR Amazon Elastic MapReduce and Hive Amazon Elastic MapReduce is a web service that makes it easy to launch managed, resizable Hadoop clusters on the web-scale infrastructure of Amazon Web Services (AWS). Elastic Map Reduce makes it easy for you to launch a Hive and Hadoop cluster, provides you with flexibility to choose different cluster sizes, and allows you to tear them down automatically when processing has completed.</description></item><item><title>Apache Hive : Hive Configurations</title><link>https://hive.apache.org/docs/latest/hive-configurations_283118321/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-configurations_283118321/</guid><description>Apache Hive : Hive Configurations Hive has more than 1600 configs around the service. The hive-site.xml contains the default configurations for the service. In this config file, you can change the configs. Every config change needs to restart the service(s).
Here you can find the most important configurations and default values.
Config Name Default Value Description Config file hive.metastore.client.cache.v2.enabled true This property enabled a Caffaine Cache for Metastore client MetastoreConf More configs are in MetastoreConf.</description></item><item><title>Apache Hive : Hive deprecated authorization mode / Legacy Mode</title><link>https://hive.apache.org/docs/latest/45876173/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/45876173/</guid><description>Apache Hive : Hive deprecated authorization mode / Legacy Mode Disclaimer Prerequisites Users, Groups, and Roles Names of Users and Roles Creating/Dropping/Using Roles Create/Drop Role Grant/Revoke Roles Viewing Granted Roles Privileges Grant/Revoke Privileges Viewing Granted Privileges Hive Operations and Required Privileges This document describes Hive security using the basic authorization scheme, which regulates access to Hive metadata on the client side.</description></item><item><title>Apache Hive : Hive HPL/SQL</title><link>https://hive.apache.org/docs/latest/59690156/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/59690156/</guid><description>Apache Hive : Hive HPL/SQL Hive Hybrid Procedural SQL On Hadoop (HPL/SQL) is a tool that implements procedural SQL for Hive. It is available in Hive 2.0.0 (HIVE-11055).
HPL/SQL is an open source tool (Apache License 2.0) that implements procedural SQL language for Apache Hive, SparkSQL, Impala as well as any other SQL-on-Hadoop implementation, any NoSQL and any RDBMS.
HPL/SQL is a hybrid and heterogeneous language that understands syntaxes and semantics of almost any existing procedural SQL dialect, and you can use with any database, for example, running existing Oracle PL/SQL code on Apache Hive and Microsoft SQL Server, or running Transact-SQL on Oracle, Cloudera Impala or Amazon Redshift.</description></item><item><title>Apache Hive : Hive Metadata Caching Proposal</title><link>https://hive.apache.org/docs/latest/hive-metadata-caching-proposal_69407514/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-metadata-caching-proposal_69407514/</guid><description>Apache Hive : Hive Metadata Caching Proposal Why Metastore Cache During Hive 2 benchmark, we find Hive metastore operation take a lot of time and thus slow down Hive compilation. In some extreme case, it takes much longer than the actual query run time. Especially, we find the latency of cloud db is very high and 90% of total query runtime is waiting for metastore SQL database operations. Based on this observation, the metastore operation performance will be greatly enhanced if we have a memory structure which cache the database query result.</description></item><item><title>Apache Hive : Hive MetaTool</title><link>https://hive.apache.org/docs/latest/hive-metatool_55156221/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-metatool_55156221/</guid><description>Apache Hive : Hive MetaTool Hive MetaTool The metatool Command Usage Example Hive MetaTool Version 0.10.0 and later
Introduced in Hive 0.10.0. See HIVE-3056 and HIVE-3443.
The Hive MetaTool enables administrators to do bulk updates on the location fields in database, table, and partition records in the metastore. It provides the following functionality:
Ability to search and replace the HDFS NN (NameNode) location in metastore records that reference the NN.</description></item><item><title>Apache Hive : Hive Metrics</title><link>https://hive.apache.org/docs/latest/hive-metrics_65872987/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-metrics_65872987/</guid><description>Apache Hive : Hive Metrics The metrics that Hive collects can be viewed in the HiveServer2 Web UI by using the &amp;ldquo;Metrics Dump&amp;rdquo; tab.
The metrics dump will display any metric available over JMX encoded in JSON: Alternatively the metrics can be written directly into HDFS, a JSON file on the local file system where the HS2 instance is running or to the console by enabling the corresponding metric reporters. By default only the JMX and the JSON file reporter are enabled.</description></item><item><title>Apache Hive : Hive on Spark</title><link>https://hive.apache.org/docs/latest/hive-on-spark_42567714/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-on-spark_42567714/</guid><description>Apache Hive : Hive on Spark 1. Introduction 1.1 Motivation 1.2 Design Principle 1.3 Comparison with Shark and Spark SQL 1.4 Other Considerations 2. High-Level Functionality 2.1 A New Execution Engine 2.2 Spark Configuration 2.3 Miscellaneous Functionality 3. Hive-Level Design 3.1 Query Planning 3.2 Job Execution 3.3 Design Considerations Table as RDD SparkWork SparkTask Shuffle, Group, and Sort Join Number of Tasks Local MapReduce Tasks Semantic Analysis and Logical Optimizations Job Diagnostics Counters and Metrics Explain Statements Hive Variables Union Concurrency and Thread Safety Build Infrastructure Mini Spark Cluster Testing 3.</description></item><item><title>Apache Hive : Hive on Spark: Getting Started</title><link>https://hive.apache.org/docs/latest/44302539/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/44302539/</guid><description>Apache Hive : Hive on Spark: Getting Started Version Compatibility Spark Installation Configuring YARN Configuring Hive Configuration property details Configuring Spark Tuning Details Common Issues (Green are resolved, will be removed from this list) Recommended Configuration Design documents Hive on Spark provides Hive with the ability to utilize Apache Spark as its execution engine.
set hive.execution.engine=spark; Hive on Spark was added in HIVE-7292.</description></item><item><title>Apache Hive : Hive on Spark: Join Design Master</title><link>https://hive.apache.org/docs/latest/50858744/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/50858744/</guid><description>Apache Hive : Hive on Spark: Join Design Master Purpose and Prerequisites MapReduce Summary Figure 1. Join Processors for Hive on MapReduce Tez Comparison Spark MapJoin Spark Join Design Figure 2: Join Processors for Hive on Spark Purpose and Prerequisites The purpose of this document is to summarize the findings of all the research of different joins and describe a unified design to attack the problem in Spark.</description></item><item><title>Apache Hive : Hive on Tez</title><link>https://hive.apache.org/docs/latest/hive-on-tez_33296197/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-on-tez_33296197/</guid><description>Apache Hive : Hive on Tez Overview Multiple reduce stages Pipelining In memory versus disk writes Joins Fine-tuned algorithms Limit processing Scope Functional requirements of phase I Example Plan with TEZ Plan without TEZ Design Summary of changes Execution layer Job submission Job monitoring Job diagnostics Counters Job execution Query planning MapRedWork Semantic analysis and logical optimizations Physical Optimizations and Task generation Local Job Runner Number of tasks Explain statements Hive variables Build infrastructure Testing Mini Tez Cluster Installation and Configuration Hive-Tez Compatibility Overview Tez is a new application framework built on Hadoop Yarn that can execute complex directed acyclic graphs of general data processing tasks.</description></item><item><title>Apache Hive : Hive Operators</title><link>https://hive.apache.org/docs/latest/hive-operators_283118406/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-operators_283118406/</guid><description>Apache Hive : Hive Operators Operators Precedences Example Operators Description A[B] , A.identifier bracket_op([]), dot(.) element selector, dot -A unary(+), unary(-), unary(~) unary prefix operators A IS [NOT] (NULL TRUE FALSE) A ^ B bitwise xor(^) bitwise xor A * B star(*), divide(/), mod(%), div(DIV) multiplicative operators A + B plus(+), minus(-) additive operators A B A &amp;amp; B bitwise and(&amp;amp;) bitwise and A B bitwise or( Relational Operators The following operators compare the passed operands and generate a TRUE or FALSE value depending on whether the comparison between the operands holds.</description></item><item><title>Apache Hive : Hive remote databases/tables</title><link>https://hive.apache.org/docs/latest/80452092/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/80452092/</guid><description>Apache Hive : Hive remote databases/tables Abstract At the 2018 DataWorks conference in Berlin, Hotels.com presented Waggle Dance, a tool for federating multiple Hive clusters and providing the illusion of a unified data catalog from disparate instances. We’ve been running Waggle Dance in production for well over a year and it has formed a critical part of our data platform architecture and infrastructure.
We believe that this type of functionality will be of increasing importance as Hadoop and Hive workloads migrate to the cloud.</description></item><item><title>Apache Hive : Hive Schema Tool</title><link>https://hive.apache.org/docs/latest/hive-schema-tool_34835119/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-schema-tool_34835119/</guid><description>Apache Hive : Hive Schema Tool Metastore Schema Verification The Hive Schema Tool The schematool Command Usage Examples Metastore Schema Verification Version
Introduced in Hive 0.12.0. See HIVE-3764.
Hive now records the schema version in the metastore database and verifies that the metastore schema version is compatible with Hive binaries that are going to accesss the metastore. Note that the Hive properties to implicitly create or alter the existing schema are disabled by default.</description></item><item><title>Apache Hive : Hive Transactions</title><link>https://hive.apache.org/docs/latest/hive-transactions_40509723/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-transactions_40509723/</guid><description>Apache Hive : Hive Transactions ACID and Transactions in Hive ACID and Transactions in Hive What is ACID and why should you use it? Limitations Streaming APIs Grammar Changes Basic Design Base and Delta Directories Compactor Delta File Compaction Initiator Worker Cleaner AcidHouseKeeperService SHOW COMPACTIONS Transaction/Lock Manager Configuration New Configuration Parameters for Transactions Configuration Values to Set for INSERT, UPDATE, DELETE Configuration Values to Set for Compaction Compaction pooling Table Properties Talks and Presentations Hive 3 Warning</description></item><item><title>Apache Hive : Hive Transactions (Hive ACID)</title><link>https://hive.apache.org/docs/latest/283118453/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/283118453/</guid><description>Apache Hive : Hive Transactions (Hive ACID) ACID and Transactions in Hive ACID and Transactions in Hive What is ACID and why should you use it? Limitations Streaming APIs Grammar Changes Basic Design Base and Delta Directories Compactor Delta File Compaction Initiator Worker Cleaner AcidHouseKeeperService SHOW COMPACTIONS Transaction/Lock Manager Configuration New Configuration Parameters for Transactions Configuration Values to Set for Hive ACID (INSERT, UPDATE, DELETE) Configuration Values to Set for Compaction Compaction pooling Table Properties Talks and Presentations What is ACID and why should you use it?</description></item><item><title>Apache Hive : Hive UDFs</title><link>https://hive.apache.org/docs/latest/hive-udfs_282102277/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-udfs_282102277/</guid><description>Apache Hive : Hive UDFs Built-in Aggregate Functions (UDAF) Built-in Table-Generating Functions (UDTF) String Functions Date Functions Mathematical Functions Collection Functions Type Conversion Functions Conditional Functions Data Masking Functions Miscellaneous Functions Geospatial Creating Custom UDF&amp;rsquo;s Hive User-Defined Functions (UDFs) are custom functions developed in Java and seamlessly integrated with Apache Hive. UDFs are routines designed to accept parameters, execute a specific action, and return the resulting value. The return value can either be a single scalar row or a complete result set, depending on the UDF&amp;rsquo;s code and the implemented interface.</description></item><item><title>Apache Hive : HIVE-24543: Support SAML 2.0 authentication mode</title><link>https://hive.apache.org/docs/latest/170266662/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/170266662/</guid><description>Apache Hive : HIVE-24543: Support SAML 2.0 authentication mode Description In cloud based deployments, it is common that the user identity is federated and managed externally by an identity provider (e.g Okta, PingIndentity, Azure AD). Integrating with such external identity providers (IDP) would help adoption and unlock use-cases where Hive is deployed in a cloud based environment and doesn&amp;rsquo;t need user managed authentication mechanisms (e.g Ldap, Kerberos). There are primarily two authentication protocols which are standardized with such external identity providers namely (SAML 2.</description></item><item><title>Apache Hive : Hive-Iceberg Integration</title><link>https://hive.apache.org/docs/latest/hive-iceberg-integration_282102247/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-iceberg-integration_282102247/</guid><description>Apache Hive : Hive-Iceberg Integration Apache Hive starting from 4.0 out of the box supports the Iceberg table format, the iceberg tables can be created like regular hive external or ACID tables, without adding any extra jars.
Creating an Iceberg Table
An iceberg table can be created using STORED BY ICEBERG keywords while creating a table.
Creating an Iceberg table using normal create command CREATE TABLE TBL_ICE (ID INT) STORED BY ICEBERG; The above creates an iceberg table named &amp;lsquo;TBL_ICE&amp;rsquo;</description></item><item><title>Apache Hive : Hive-Tez Compatibility</title><link>https://hive.apache.org/docs/latest/hive-tez-compatibility_59689974/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hive-tez-compatibility_59689974/</guid><description>Apache Hive : Hive-Tez Compatibility This is derived from the pom files of the respective releases. Other releases with compatibility are listed in parenthesis.
Hive (Works with) Tez 0.13 0.4.0-incubating 0.14 0.5.2+, (through 0.7.0) 1.0 0.5.2, (through 0.7.0) 1.1 0.5.2, (through 0.7.0) 1.2* 0.5.3, (through 0.7.0) 2.0 0.8.2 *Hive-1.2 is the latest release of Hive as of 07/2015.</description></item><item><title>Apache Hive : HiveAmazonElasticMapReduce</title><link>https://hive.apache.org/docs/latest/hiveamazonelasticmapreduce_27825646/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hiveamazonelasticmapreduce_27825646/</guid><description>Apache Hive : HiveAmazonElasticMapReduce Amazon Elastic MapReduce and Hive Amazon Elastic MapReduce is a web service that makes it easy to launch managed, resizable Hadoop clusters on the web-scale infrastructure of Amazon Web Services (AWS). Elastic Map Reduce makes it easy for you to launch a Hive and Hadoop cluster, provides you with flexibility to choose different cluster sizes, and allows you to tear them down automatically when processing has completed.</description></item><item><title>Apache Hive : HiveAws</title><link>https://hive.apache.org/docs/latest/hiveaws_27362103/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hiveaws_27362103/</guid><description>Apache Hive : HiveAws = Hive and Amazon Web Services =
Background This document explores the different ways of leveraging Hive on Amazon Web Services - namely S3, EC2 and Elastic Map-Reduce.
Hadoop already has a long tradition of being run on EC2 and S3. These are well documented in the links below which are a must read:
Hadoop and S3 Amazon and EC2 The second document also has pointers on how to get started using EC2 and S3.</description></item><item><title>Apache Hive : HiveAws HivingS3nRemotely</title><link>https://hive.apache.org/docs/latest/hiveaws-hivings3nremotely_27362102/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hiveaws-hivings3nremotely_27362102/</guid><description>Apache Hive : HiveAws HivingS3nRemotely = Querying S3 files from your PC (using EC2, Hive and Hadoop) =
Usage Scenario The scenario being covered here goes as follows:
A user has data stored in S3 - for example Apache log files archived in the cloud, or databases backed up into S3. The user would like to declare tables over the data sets here and issue SQL queries against them These SQL queries should be executed using computed resources provisioned from EC2.</description></item><item><title>Apache Hive : HiveClient</title><link>https://hive.apache.org/docs/latest/hiveclient_27362101/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hiveclient_27362101/</guid><description>Apache Hive : HiveClient Command Line JDBC JDBC Client Sample Code Running the JDBC Sample Code JDBC Client Setup for a Secure Cluster Python PHP ODBC Thrift Thrift Java Client Thrift C++ Client Thrift Node Clients Thrift Ruby Client This page describes the different clients supported by Hive. The command line client currently only supports an embedded server. The JDBC and Thrift-Java clients support both embedded and standalone servers.</description></item><item><title>Apache Hive : HiveContributorsMinutes100601</title><link>https://hive.apache.org/docs/latest/hivecontributorsminutes100601_27362064/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hivecontributorsminutes100601_27362064/</guid><description>Apache Hive : HiveContributorsMinutes100601 Notes provided by Namit Jain.
The following people were present:
Facebook (Paul Yang; Ning Zhang; Yongqiang He; Ahmed Aly; John Sichi; Ashish Thusoo; Namit Jain) Netflix (Eva Tse; Jerome Boulon) Cloudera (Arvind Prabhakar; Vinithra Varadharajan; Carl Steinbach) Yahoo (Alan Gates) The following were the main meeting minutes:
We should have these meetings more often, say every month. Cloudera will host the next meeting.</description></item><item><title>Apache Hive : HiveContributorsMinutes100706</title><link>https://hive.apache.org/docs/latest/hivecontributorsminutes100706_27362065/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hivecontributorsminutes100706_27362065/</guid><description>Apache Hive : HiveContributorsMinutes100706 Attendees: Amr Awadallah, John Sichi, Paul Yang, Olga Natkovich, Ajay Kidave, Yongqiang He, Basab Malik, Vinithra Varadharajan, bc Wong, Arvind Prabhakar, Carl Steinbach
bc Wong gave a live demo of Cloudera&amp;rsquo;s Hue framework and the Beeswax Hive web interface. Slides from this talk are available here: http://www.slideshare.net/cwsteinbach/cloudera-huebeeswax Hue was recently released as open source. The code is available on Github here: http://github.com/cloudera/hue Olga Natkovich gave a whiteboard talk on HOwl.</description></item><item><title>Apache Hive : HiveCounters</title><link>https://hive.apache.org/docs/latest/hivecounters_67636835/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hivecounters_67636835/</guid><description>Apache Hive : HiveCounters Task counters created by Hive during query execution
 For Tez execution, %context is set to the mapper/reducer name. For other execution engines it is not included in the counter name.
Counter Name Description RECORDS_IN[_%context] Input records read RECORDS_OUT[_%context] Output records written RECORDS_OUT_INTERMEDIATE[_%context] Records written as intermediate records to ReduceSink (which become input records to other tasks) CREATED_FILES Number of files created DESERIALIZE_ERRORS Deserialization errors encountered while reading data</description></item><item><title>Apache Hive : HiveDerbyServerMode</title><link>https://hive.apache.org/docs/latest/hivederbyservermode_27362068/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hivederbyservermode_27362068/</guid><description>Apache Hive : HiveDerbyServerMode Hive Using Derby in Server Mode Hive Using Derby in Server Mode Download Derby Set Environment Starting Derby Configure Hive to Use Network Derby Copy Derby Jar Files Start Up Hive The Result Hive in embedded mode has a limitation of one active user at a time. You may want to run Derby as a Network Server, this way multiple users can access it simultaneously from different systems.</description></item><item><title>Apache Hive : HiveDeveloperFAQ</title><link>https://hive.apache.org/docs/latest/hivedeveloperfaq_27823747/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hivedeveloperfaq_27823747/</guid><description>Apache Hive : HiveDeveloperFAQ Developing How do I move some files? Building Maven settings How to build all source? How do I import into Eclipse? How to generate tarball? How to generate protobuf code? How to generate Thrift code? HIVE-26769 How to compile ODBC? How do I publish Hive artifacts to my local Maven repository? Testing How do I run precommit tests on a patch?</description></item><item><title>Apache Hive : HiveJDBCInterface</title><link>https://hive.apache.org/docs/latest/hivejdbcinterface_27362100/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hivejdbcinterface_27362100/</guid><description>Apache Hive : HiveJDBCInterface Hive JDBC Driver Hive JDBC Driver Integration with Pentaho Integration with SQuirrel SQL Client The current JDBC interface for Hive only supports running queries and fetching results. Only a small subset of the metadata calls are supported.
To see how the JDBC interface can be used, see sample code.
Integration with Pentaho Download pentaho report designer from the pentaho website. Overwrite report-designer.</description></item><item><title>Apache Hive : HiveODBC</title><link>https://hive.apache.org/docs/latest/hiveodbc_27362099/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hiveodbc_27362099/</guid><description>Apache Hive : HiveODBC Hive ODBC Driver Hive ODBC Driver Introduction Suggested Reading Software Requirements Driver Architecture Building and Setting Up ODBC Components Hive Client Build/Setup unixODBC API Wrapper Build/Setup Connecting the Driver to a Driver Manager Testing with ISQL Build libodbchive.so for 3rd Party Driver Manager Troubleshooting Current Status These instructions are for the Hive ODBC driver available in Hive for HiveServer1.</description></item><item><title>Apache Hive : HivePlugins</title><link>https://hive.apache.org/docs/latest/hiveplugins_27362098/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hiveplugins_27362098/</guid><description>Apache Hive : HivePlugins Creating Custom UDFs Deploying Jars for User Defined Functions and User Defined SerDes Creating Custom UDFs First, you need to create a new class that extends UDF, with one or more methods named evaluate.
package com.example.hive.udf; import org.apache.hadoop.hive.ql.exec.UDF; import org.apache.hadoop.io.Text; public final class Lower extends UDF { public Text evaluate(final Text s) { if (s == null) { return null; } return new Text(s.toString().toLowerCase()); } } (Note that there&amp;rsquo;s already a built-in function for this, it&amp;rsquo;s just an easy example).</description></item><item><title>Apache Hive : HiveQL</title><link>https://hive.apache.org/docs/latest/hiveql_27362097/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hiveql_27362097/</guid><description>Apache Hive : HiveQL This page is deprecated
Please see the HiveQL Language Manual</description></item><item><title>Apache Hive : HiveReplicationDevelopment</title><link>https://hive.apache.org/docs/latest/hivereplicationdevelopment_55155632/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hivereplicationdevelopment_55155632/</guid><description>Apache Hive : HiveReplicationDevelopment Introduction Purposes of Replication Disaster Recovery Load Balancing Replication Taxonomy Transaction Source Primary-Copy Update-Anywhere Synchronization Strategy Eager Lazy Design Taxonomy Design Choices Primary-Copy vs Update-Anywhere Eager vs Lazy Other Design Choices Basic Approach Implementation Events Event IDs, State IDs, and Sequencing of Exports/Imports Handling of Events Future Features References Introduction Replication in the context of databases and warehouses is the process of duplication of entities from one warehouse to another.</description></item><item><title>Apache Hive : HiveReplicationv2Development</title><link>https://hive.apache.org/docs/latest/hivereplicationv2development_66850051/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hivereplicationv2development_66850051/</guid><description>Apache Hive : HiveReplicationv2Development Issues with the Current Replication System Slowness Requiring Staging Directories with Full Copies (4xcopy Problem) Unsuitable for Load-Balancing Use Cases Incompatibility with ACID Dependency on External Tools To Do a Lot Support for a Hub-Spoke Model Rubberbanding Change Management _files Solution for Rubber Banding _metadata A Need for Bootstrap New Commands REPL DUMP Syntax: Return values: Note: REPL LOAD Return values: REPL STATUS Return values: Bootstrap, Revisited Metastore notification API security Setup/Configuration This document describes the second version of Hive Replication.</description></item><item><title>Apache Hive : HiveServer</title><link>https://hive.apache.org/docs/latest/hiveserver_27362111/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hiveserver_27362111/</guid><description>Apache Hive : HiveServer Thrift Hive Server HiveServer is an optional service that allows a remote client to submit requests to Hive, using a variety of programming languages, and retrieve results. HiveServer is built on Apache ThriftTM (http://thrift.apache.org/), therefore it is sometimes called the Thrift server although this can lead to confusion because a newer service named HiveServer2 is also built on Thrift. Since the introduction of HiveServer2, HiveServer has also been called HiveServer1.</description></item><item><title>Apache Hive : HiveServer2 Clients</title><link>https://hive.apache.org/docs/latest/hiveserver2-clients_30758725/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hiveserver2-clients_30758725/</guid><description>Apache Hive : HiveServer2 Clients Beeline – Command Line Shell Beeline Example Beeline Commands Beeline Properties Beeline Hive Commands Beeline Command Options Output Formats table vertical xmlattr xmlelements json jsonfile Separated-Value Output Formats csv2, tsv2, dsv Quoting in csv2, tsv2 and dsv Formats csv, tsv HiveServer2 Logging Cancelling the Query Background Query in Terminal Script JDBC Connection URLs Connection URL Format Connection URL for Remote or Embedded Mode Connection URL When HiveServer2 Is Running in HTTP Mode Connection URL When SSL Is Enabled in HiveServer2 Connection URL When ZooKeeper Service Discovery Is Enabled Named Connection URLs Reconnecting Using hive-site.</description></item><item><title>Apache Hive : HiveServer2 Overview</title><link>https://hive.apache.org/docs/latest/hiveserver2-overview_65147648/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hiveserver2-overview_65147648/</guid><description>Apache Hive : HiveServer2 Overview Introduction HS2 Architecture Server Transport Protocol Processor Dependencies of HS2 JDBC Client Source Code Description Server Side Client Side Interaction between Client and Server Resources Introduction HiveServer2 (HS2) is a service that enables clients to execute queries against Hive. HiveServer2 is the successor to HiveServer1 which has been deprecated. HS2 supports multi-client concurrency and authentication. It is designed to provide better support for open API clients like JDBC and ODBC.</description></item><item><title>Apache Hive : HiveServer2 Thrift API</title><link>https://hive.apache.org/docs/latest/hiveserver2-thrift-api_27843687/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hiveserver2-thrift-api_27843687/</guid><description>Apache Hive : HiveServer2 Thrift API Introduction This document is a proposal for a new HiveServer2 Thrift API.
Motivations Concurrency Many users have reported that the current HiveServer implementation has concurrency bugs (for example, see HIVE-80). In fact, it&amp;rsquo;s impossible for HiveServer to support concurrent connections using the current Thrift API, a result of the fact that Thrift doesn&amp;rsquo;t provide server-side access to connection handles. Since the current API does not provide explicit support for sessions or connections, HiveServer has no way of mapping incoming requests to client sessions, which makes it impossible for HiveServer to maintain session state in between calls.</description></item><item><title>Apache Hive : Home</title><link>https://hive.apache.org/docs/latest/home_27362069/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/home_27362069/</guid><description>Apache Hive : Home Apache Hive Hive Documentation General Information about Hive User Documentation Administrator Documentation HCatalog and WebHCat Documentation Resources for Contributors Hive Versions and Branches Apache Hive The Apache Hive™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage and queried using SQL syntax.
Built on top of Apache Hadoop™, Hive provides the following features:
Tools to enable easy access to data via SQL, thus enabling data warehousing tasks such as extract/transform/load (ETL), reporting, and data analysis.</description></item><item><title>Apache Hive : Howl</title><link>https://hive.apache.org/docs/latest/howl_27362109/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/howl_27362109/</guid><description>Apache Hive : Howl This page collects some pointers to resources about Howl (an effort to create a metastore for all of Hadoop) and how its first incarnation is being built by reusing and extending Hive&amp;rsquo;s metastore and CLI.
Howl wiki Yahoo group for Howl developers (including mailing list archive) Howl source code at github Howl CLI functional spec Original plans for Owl (predecessor to Howl)</description></item><item><title>Apache Hive : HowToCommit</title><link>https://hive.apache.org/docs/latest/howtocommit_27362108/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/howtocommit_27362108/</guid><description>Apache Hive : HowToCommit Guide for Hive Committers Guide for Hive Committers New committers Review Reject PreCommit runs, and committing patches Commit Committing Documentation Backporting commits to previous branches Dialog This page contains guidelines for committers of the Apache Hive project. (If you&amp;rsquo;re currently a contributor, and are interested in how we add new committers, read BecomingACommitter)
New committers New committers are encouraged to first read Apache&amp;rsquo;s generic committer documentation:</description></item><item><title>Apache Hive : HowToContribute</title><link>https://hive.apache.org/docs/latest/howtocontribute_27362107/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/howtocontribute_27362107/</guid><description>Apache Hive : HowToContribute How to Contribute to Apache Hive This page describes the mechanics of how to contribute software to Apache Hive. For ideas about what you might contribute, please see open tickets in Jira.
Getting the Source Code Becoming a Contributor Making Changes Coding Conventions Understanding Maven Understanding Hive Branches Hadoop Dependencies Unit Tests Add a Unit Test Submitting a PR Fetching a PR from Github Contributing Your Work JIRA Guidelines Generating Thrift Code See Also Getting the Source Code First of all, you need the Hive source code.</description></item><item><title>Apache Hive : HowToRelease</title><link>https://hive.apache.org/docs/latest/howtorelease_27362106/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/howtorelease_27362106/</guid><description>Apache Hive : HowToRelease This page is prepared for Hive committers. You need committer rights to create a new Hive release.
Storage API Release Storage API Prepare Master Branch Storage API Branching Making Storage API Release Artifacts Publishing the Storage API Artifacts Preparing Branch for further development Cleaning Up Storage API Artifacts Hive Release Preparation Branching Updating Release Branch Building Voting Verifying the Release Candidate Publishing Archive old releases Preparing Branch for Future Maintenance Release See Also Hadoop Version Warning</description></item><item><title>Apache Hive : Hybrid Hybrid Grace Hash Join, v1.0</title><link>https://hive.apache.org/docs/latest/50860526/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/50860526/</guid><description>Apache Hive : Hybrid Hybrid Grace Hash Join, v1.0 Overview Scope Notation and Assumptions Brief Review on Hash Join Algorithms Simple Hash Join GRACE Hash Join Hybrid GRACE Hash Join Hash Join in Hive Motivation for “Hybrid Hybrid GRACE Hash Join” Algorithm Recursive Hashing and Spilling Skewed Data Distribution Bloom Filter References Overview We are proposing an enhanced hash join algorithm called “hybrid hybrid grace hash join”.</description></item><item><title>Apache Hive : IndexDev</title><link>https://hive.apache.org/docs/latest/indexdev_27362104/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/indexdev_27362104/</guid><description>Apache Hive : IndexDev Indexes Indexes Indexing Is Removed since 3.0 Introduction Scope CREATE INDEX Metastore Model Metastore Upgrades REBUILD DROP INDEX Plugin Interface Reference Implementation TBD Current Status (JIRA) Indexing Is Removed since 3.0 There are alternate options which might work similarily to indexing:
Materialized views with automatic rewriting can result in very similar results. Hive 2.3.0 adds support for materialzed views. Using columnar file formats (Parquet, ORC) – they can do selective scanning; they may even skip entire files/blocks.</description></item><item><title>Apache Hive : IndexDev Bitmap</title><link>https://hive.apache.org/docs/latest/indexdev-bitmap_27362028/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/indexdev-bitmap_27362028/</guid><description>Apache Hive : IndexDev Bitmap = Bitmap Indexing =
Introduction Approach Proposal First implementation Second iteration Example Introduction This document explains the proposed design for adding a bitmap index handler (https://issues.apache.org/jira/browse/HIVE-1803).
Bitmap indexing (http://en.wikipedia.org/wiki/Bitmap_index) is a standard technique for indexing columns with few distinct
values, such as gender.
Approach We want to develop a bitmap index that can reuse as much of the existing Compact Index code as possible.</description></item><item><title>Apache Hive : Introduction to Apache Hive</title><link>https://hive.apache.org/docs/latest/introduction-to-apache-hive_283118337/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/introduction-to-apache-hive_283118337/</guid><description>Apache Hive : Introduction to Apache Hive The Apache Hive™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage and queried using SQL syntax.
Built on top of Apache Hadoop™, Hive provides the following features:
Tools to enable easy access to data via SQL, thus enabling data warehousing tasks such as extract/transform/load (ETL), reporting, and data analysis. A mechanism to impose structure on a variety of data formats Access to files stored either directly in Apache HDFS™ or in other data storage systems such as Apache HBase™ Query execution via Apache Tez™ or MapReduce Procedural language with HPL-SQL Sub-second query retrieval via Hive LLAP, Apache YARN and Apache Slider.</description></item><item><title>Apache Hive : JDBC Storage Handler</title><link>https://hive.apache.org/docs/latest/jdbc-storage-handler_95651916/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/jdbc-storage-handler_95651916/</guid><description>Apache Hive : JDBC Storage Handler Syntax Table Properties Supported Data Type Column/Type Mapping Auto Shipping Securing Password Partitioning Computation Pushdown Using a Non-default Schema MariaDB MS SQL Oracle PostgreSQL Syntax JdbcStorageHandler supports reading from jdbc data source in Hive. Currently writing to a jdbc data source is not supported. To use JdbcStorageHandler, you need to create an external table using JdbcStorageHandler.</description></item><item><title>Apache Hive : Kudu Integration</title><link>https://hive.apache.org/docs/latest/kudu-integration_133631955/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/kudu-integration_133631955/</guid><description>Apache Hive : Kudu Integration Hive Kudu Integration Hive Kudu Integration Overview Implementation Hive Configuration Table Creation Impala Tables Data Ingest Examples Overview Apache Kudu is a an Open Source data storage engine that makes fast analytics on fast and changing data easy. Implementation The initial implementation was added to Hive 4.0 in HIVE-12971 and is designed to work with Kudu 1.2+.</description></item><item><title>Apache Hive : LanguageManual</title><link>https://hive.apache.org/docs/latest/languagemanual_27362030/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual_27362030/</guid><description>Apache Hive : LanguageManual This is the Hive Language Manual. For other Hive documentation, see the Hive wiki&amp;rsquo;s Home page.
Commands and CLIs
Commands Hive CLI (old) Beeline CLI (new) Variable Substitution HCatalog CLI File Formats
Avro Files ORC Files Parquet Compressed Data Storage LZO Compression Data Types
Data Definition Statements
DDL Statements Bucketed Tables Statistics (Analyze and Describe) Indexes Archiving Data Manipulation Statements</description></item><item><title>Apache Hive : LanguageManual Archiving</title><link>https://hive.apache.org/docs/latest/languagemanual-archiving_27362031/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-archiving_27362031/</guid><description>Apache Hive : LanguageManual Archiving Archiving for File Count Reduction Note: Archiving should be considered an advanced command due to the caveats involved.
Archiving for File Count Reduction Overview Settings Usage Archive Unarchive Cautions and Limitations Under the Hood Overview Due to the design of HDFS, the number of files in the filesystem directly affects the memory consumption in the namenode. While normally not a problem for small clusters, memory usage may hit the limits of accessible memory on a single machine when there are &amp;gt;50-100 million files.</description></item><item><title>Apache Hive : LanguageManual Authorization</title><link>https://hive.apache.org/docs/latest/languagemanual-authorization_27362032/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-authorization_27362032/</guid><description>Apache Hive : LanguageManual Authorization Hive Authorization
Introduction Hive Authorization Options Use Cases Overview of Authorization Modes 1 Storage Based Authorization in the Metastore Server Fall Back Authorizer 2 SQL Standards Based Authorization in HiveServer2 3 Authorization using Apache Ranger &amp;amp; Sentry 4 Old default Hive Authorization (Legacy Mode) Addressing Authorization Needs of Multiple Use Cases Explain Authorization More Information Introduction Note that this documentation is referring to Authorization which is verifying if a user has permission to perform a certain action, and not about Authentication (verifying the identity of the user).</description></item><item><title>Apache Hive : LanguageManual Cli</title><link>https://hive.apache.org/docs/latest/languagemanual-cli_27362033/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-cli_27362033/</guid><description>Apache Hive : LanguageManual Cli Hive CLI Hive CLI Deprecation in favor of Beeline CLI Hive Command Line Options Examples The hiverc File Logging Tool to Clear Dangling Scratch Directories Hive Batch Mode Commands Hive Interactive Shell Commands Hive Resources HCatalog CLI $HIVE_HOME/bin/hive is a shell utility which can be used to run Hive queries in either interactive or batch mode.</description></item><item><title>Apache Hive : LanguageManual Commands</title><link>https://hive.apache.org/docs/latest/languagemanual-commands_34838882/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-commands_34838882/</guid><description>Apache Hive : LanguageManual Commands Commands are non-SQL statements such as setting a property or adding a resource. They can be used in HiveQL scripts or directly in the CLI or Beeline.
Command Description quit exit Use quit or exit to leave the interactive shell. reset Resets the configuration to the default values (as of Hive 0.10: see HIVE-3202). Any configuration parameters that were set using the set command or -hiveconf parameter in hive commandline will get reset to default value.</description></item><item><title>Apache Hive : LanguageManual DDL</title><link>https://hive.apache.org/docs/latest/languagemanual-ddl_27362034/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-ddl_27362034/</guid><description>Apache Hive : LanguageManual DDL Hive Data Definition Language
Overview Keywords, Non-reserved Keywords and Reserved Keywords Create/Drop/Alter/Use Database Create/Drop/Alter Connector Create/Drop/Truncate Table Alter Table/Partition/Column Create/Drop/Alter View Create/Drop/Alter Materialized View Create/Drop/Alter Index Create/Drop Macro Create/Drop/Reload Function Create/Drop/Grant/Revoke Roles and Privileges Show Describe Abort Scheduled queries
Datasketches integration
HCatalog and WebHCat DDL
Overview HiveQL DDL statements are documented here, including:
CREATE DATABASE/SCHEMA, TABLE, VIEW, FUNCTION, INDEX DROP DATABASE/SCHEMA, TABLE, VIEW, INDEX TRUNCATE TABLE ALTER DATABASE/SCHEMA, TABLE, VIEW MSCK REPAIR TABLE (or ALTER TABLE RECOVER PARTITIONS) SHOW DATABASES/SCHEMAS, TABLES, TBLPROPERTIES, VIEWS, PARTITIONS, FUNCTIONS, INDEX[ES], COLUMNS, CREATE TABLE DESCRIBE DATABASE/SCHEMA, table_name, view_name, materialized_view_name PARTITION statements are usually options of TABLE statements, except for SHOW PARTITIONS.</description></item><item><title>Apache Hive : LanguageManual DDL BucketedTables</title><link>https://hive.apache.org/docs/latest/languagemanual-ddl-bucketedtables_27362035/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-ddl-bucketedtables_27362035/</guid><description>Apache Hive : LanguageManual DDL BucketedTables This is a brief example on creating and populating bucketed tables. (For another example, see Bucketed Sorted Tables.)
Bucketed tables are fantastic in that they allow much more efficient sampling than do non-bucketed tables, and they may later allow for time saving operations such as mapside joins. However, the bucketing specified at table creation is not enforced when the table is written to, and so it is possible for the table&amp;rsquo;s metadata to advertise properties which are not upheld by the table&amp;rsquo;s actual layout.</description></item><item><title>Apache Hive : LanguageManual DML</title><link>https://hive.apache.org/docs/latest/languagemanual-dml_27362036/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-dml_27362036/</guid><description>Apache Hive : LanguageManual DML Hive Data Manipulation Language Hive Data Manipulation Language Loading files into tables Syntax Synopsis Notes Inserting data into Hive Tables from queries Syntax Synopsis Notes Dynamic Partition Inserts Example Additional Documentation Writing data into the filesystem from queries Syntax Synopsis Notes Inserting values into tables from SQL Syntax Synopsis Examples Update Syntax Synopsis Notes Delete Syntax Synopsis Notes Merge Syntax Synopsis Performance Note Notes Examples There are multiple ways to modify data in Hive:</description></item><item><title>Apache Hive : LanguageManual Explain</title><link>https://hive.apache.org/docs/latest/languagemanual-explain_27362037/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-explain_27362037/</guid><description>Apache Hive : LanguageManual Explain EXPLAIN Syntax Example The CBO Clause The AST Clause The DEPENDENCY Clause The AUTHORIZATION Clause The LOCKS Clause The VECTORIZATION Clause The ANALYZE Clause User-level Explain Output EXPLAIN Syntax Hive provides an EXPLAIN command that shows the execution plan for a query. The syntax for this statement is as follows:
EXPLAIN [EXTENDED|CBO|AST|DEPENDENCY|AUTHORIZATION|LOCKS|VECTORIZATION|ANALYZE] query AUTHORIZATION is supported from HIVE 0.14.0 via HIVE-5961.</description></item><item><title>Apache Hive : LanguageManual GroupBy</title><link>https://hive.apache.org/docs/latest/languagemanual-groupby_27362038/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-groupby_27362038/</guid><description>Apache Hive : LanguageManual GroupBy Group By Syntax Simple Examples Select statement and group by clause Advanced Features Multi-Group-By Inserts Map-side Aggregation for Group By Grouping Sets, Cubes, Rollups, and the GROUPING__ID Function Group By Syntax groupByClause: GROUP BY groupByExpression (, groupByExpression)* groupByExpression: expression groupByQuery: SELECT expression (, expression)* FROM src groupByClause? In groupByExpression columns are specified by name, not by position number.</description></item><item><title>Apache Hive : LanguageManual ImportExport</title><link>https://hive.apache.org/docs/latest/languagemanual-importexport_27837968/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-importexport_27837968/</guid><description>Apache Hive : LanguageManual ImportExport Import/Export Import/Export Overview Export Syntax Import Syntax Replication usage Examples Version
The EXPORT and IMPORT commands were added in Hive 0.8.0 (see HIVE-1918).
Replication extensions to the EXPORT and IMPORT commands were added in Hive 1.2.0 (see HIVE-7973 and Hive Replication Development).
Overview The EXPORT command exports the data of a table or partition, along with the metadata, into a specified output location.</description></item><item><title>Apache Hive : LanguageManual Indexing</title><link>https://hive.apache.org/docs/latest/languagemanual-indexing_31822176/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-indexing_31822176/</guid><description>Apache Hive : LanguageManual Indexing Indexing Is Removed since 3.0 Overview of Hive Indexes Indexing Resources Configuration Parameters for Hive Indexes Simple Examples Indexing Is Removed since 3.0 There are alternate options which might work similarily to indexing:
Materialized views with automatic rewriting can result in very similar results. Hive 2.3.0 adds support for materialzed views. Using columnar file formats (Parquet, ORC) – they can do selective scanning; they may even skip entire files/blocks.</description></item><item><title>Apache Hive : LanguageManual JoinOptimization</title><link>https://hive.apache.org/docs/latest/languagemanual-joinoptimization_33293167/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-joinoptimization_33293167/</guid><description>Apache Hive : LanguageManual JoinOptimization Join Optimization Join Optimization Improvements to the Hive Optimizer Star Join Optimization Star Schema Example Prior Support for MAPJOIN Limitations of Prior Implementation Enhancements for Star Joins Optimize Chains of Map Joins
Current and Future Optimizations Optimize Auto Join Conversion
- [Current Optimization](#current-optimization)+ [Auto Conversion to SMB Map Join](#auto-conversion-to-smb-map-join) - [SMB Join across Tables with Different Keys](#smb-join-across-tables-with-different-keys) Generate Hash Tables on the Task Side</description></item><item><title>Apache Hive : LanguageManual Joins</title><link>https://hive.apache.org/docs/latest/languagemanual-joins_27362039/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-joins_27362039/</guid><description>Apache Hive : LanguageManual Joins Hive Joins Hive Joins Join Syntax Examples MapJoin Restrictions Join Optimization Predicate Pushdown in Outer Joins Enhancements in Hive Version 0.11 Join Syntax Hive supports the following syntax for joining tables:
join_table: table_reference [INNER] JOIN table_factor [join_condition] | table_reference {LEFT|RIGHT|FULL} [OUTER] JOIN table_reference join_condition | table_reference LEFT SEMI JOIN table_reference join_condition | table_reference CROSS JOIN table_reference [join_condition] (as of Hive 0.</description></item><item><title>Apache Hive : LanguageManual LateralView</title><link>https://hive.apache.org/docs/latest/languagemanual-lateralview_27362040/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-lateralview_27362040/</guid><description>Apache Hive : LanguageManual LateralView Lateral View Syntax Description Example Multiple Lateral Views Outer Lateral Views Lateral View Syntax lateralView: LATERAL VIEW udtf(expression) tableAlias AS columnAlias (',' columnAlias)* fromClause: FROM baseTable (lateralView)* Description Lateral view is used in conjunction with user-defined table generating functions such as explode(). As mentioned in Built-in Table-Generating Functions, a UDTF generates zero or more output rows for each input row. A lateral view first applies the UDTF to each row of base table and then joins resulting output rows to the input rows to form a virtual table having the supplied table alias.</description></item><item><title>Apache Hive : LanguageManual LZO</title><link>https://hive.apache.org/docs/latest/languagemanual-lzo_33298193/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-lzo_33298193/</guid><description>Apache Hive : LanguageManual LZO LZO Compression LZO Compression General LZO Concepts Prerequisites Lzo/Lzop Installations core-site.xml Table Definition Hive Queries Option 1: Directly Create LZO Files Option 2: Write Custom Java to Create LZO Files General LZO Concepts LZO is a lossless data compression library that favors speed over compression ratio. See http://www.oberhumer.com/opensource/lzo and http://www.lzop.org for general information about LZO and see Compressed Data Storage for information about compression in Hive.</description></item><item><title>Apache Hive : LanguageManual ORC</title><link>https://hive.apache.org/docs/latest/languagemanual-orc_31818911/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-orc_31818911/</guid><description>Apache Hive : LanguageManual ORC ORC Files ORC Files ORC File Format File Structure Stripe Structure HiveQL Syntax Serialization and Compression Integer Column Serialization String Column Serialization Compression ORC File Dump Utility ORC Configuration Parameters ORC Format Specification ORC File Format Version
Introduced in Hive version 0.11.0.
The Optimized Row Columnar (ORC) file format provides a highly efficient way to store Hive data.</description></item><item><title>Apache Hive : LanguageManual Sampling</title><link>https://hive.apache.org/docs/latest/languagemanual-sampling_27362042/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-sampling_27362042/</guid><description>Apache Hive : LanguageManual Sampling Sampling Syntax Sampling Bucketized Table Block Sampling Sampling Syntax Sampling Bucketized Table table_sample: TABLESAMPLE (BUCKET x OUT OF y [ON colname]) The TABLESAMPLE clause allows the users to write queries for samples of the data instead of the whole table. The TABLESAMPLE clause can be added to any table in the FROM clause. The buckets are numbered starting from 1.</description></item><item><title>Apache Hive : LanguageManual Select</title><link>https://hive.apache.org/docs/latest/languagemanual-select_27362043/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-select_27362043/</guid><description>Apache Hive : LanguageManual Select Select Syntax WHERE Clause ALL and DISTINCT Clauses Partition Based Queries HAVING Clause LIMIT Clause REGEX Column Specification More Select Syntax GROUP BY; SORT/ORDER/CLUSTER/DISTRIBUTE BY; JOIN (Hive Joins, Join Optimization, Outer Join Behavior); UNION; TABLESAMPLE; Subqueries; Virtual Columns; Operators and UDFs; LATERAL VIEW; Windowing, OVER, and Analytics; Common Table Expressions
Select Syntax [WITH CommonTableExpression (, CommonTableExpression)*] (Note: Only available starting with Hive 0.</description></item><item><title>Apache Hive : LanguageManual SortBy</title><link>https://hive.apache.org/docs/latest/languagemanual-sortby_27362045/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-sortby_27362045/</guid><description>Apache Hive : LanguageManual SortBy Order, Sort, Cluster, and Distribute By Syntax of Order By Syntax of Sort By Difference between Sort By and Order By Setting Types for Sort By Syntax of Cluster By and Distribute By Order, Sort, Cluster, and Distribute By This describes the syntax of SELECT clauses ORDER BY, SORT BY, CLUSTER BY, and DISTRIBUTE BY. See Select Syntax for general information.</description></item><item><title>Apache Hive : LanguageManual SubQueries</title><link>https://hive.apache.org/docs/latest/languagemanual-subqueries_27362044/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-subqueries_27362044/</guid><description>Apache Hive : LanguageManual SubQueries Subqueries in the FROM Clause Subqueries in the WHERE Clause Subqueries in the FROM Clause SELECT ... FROM (subquery) name ... SELECT ... FROM (subquery) AS name ... (Note: Only valid starting with Hive 0.13.0) Hive supports subqueries only in the FROM clause (through Hive 0.12). The subquery has to be given a name because every table in a FROM clause must have a name.</description></item><item><title>Apache Hive : LanguageManual Transform</title><link>https://hive.apache.org/docs/latest/languagemanual-transform_27362047/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-transform_27362047/</guid><description>Apache Hive : LanguageManual Transform Transform/Map-Reduce Syntax SQL Standard Based Authorization Disallows TRANSFORM TRANSFORM Examples Schema-less Map-reduce Scripts Typing the output of TRANSFORM Transform/Map-Reduce Syntax Users can also plug in their own custom mappers and reducers in the data stream by using features natively supported in the Hive language. e.g. in order to run a custom mapper script - map_script - and a custom reducer script - reduce_script - the user can issue the following command which uses the TRANSFORM clause to embed the mapper and the reducer scripts.</description></item><item><title>Apache Hive : LanguageManual Types</title><link>https://hive.apache.org/docs/latest/languagemanual-types_27838462/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-types_27838462/</guid><description>Apache Hive : LanguageManual Types Hive Data Types Hive Data Types Overview Numeric Types Date/Time Types String Types Misc Types Complex Types Column Types Integral Types (TINYINT, SMALLINT, INT/INTEGER, BIGINT) Strings Varchar Char Timestamps Casting Dates Intervals Decimals Decimal Literals Decimal Type Incompatibilities between Hive 0.12.0 and 0.13.0 Upgrading Pre-Hive 0.13.0 Decimal Columns Union Types Literals Floating Point Types Decimal Types Using Decimal Types Mathematical UDFs Casting Decimal Values Testing Decimal Types Handling of NULL Values Change Types Allowed Implicit Conversions Overview This lists all supported data types in Hive.</description></item><item><title>Apache Hive : LanguageManual UDF</title><link>https://hive.apache.org/docs/latest/languagemanual-udf_27362046/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-udf_27362046/</guid><description>Apache Hive : LanguageManual UDF Hive Operators and User-Defined Functions (UDFs) Hive Operators and User-Defined Functions (UDFs) Built-in Operators Operators Precedences Relational Operators Arithmetic Operators Logical Operators String Operators Complex Type Constructors Operators on Complex Types Built-in Functions Mathematical Functions Mathematical Functions and Operators for Decimal Datatypes Collection Functions Type Conversion Functions Date Functions Conditional Functions String Functions Data Masking Functions Misc.</description></item><item><title>Apache Hive : LanguageManual Union</title><link>https://hive.apache.org/docs/latest/languagemanual-union_27362049/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-union_27362049/</guid><description>Apache Hive : LanguageManual Union Union Syntax UNION within a FROM Clause Unions in DDL and Insert Statements Applying Subclauses Column Aliases for Schema Matching Column Type Conversion Version Information Union Syntax select_statement UNION [ALL | DISTINCT] select_statement UNION [ALL | DISTINCT] select_statement ... UNION is used to combine the result from multiple SELECT statements into a single result set.
Hive versions prior to 1.</description></item><item><title>Apache Hive : LanguageManual VariableSubstitution</title><link>https://hive.apache.org/docs/latest/languagemanual-variablesubstitution_30754722/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-variablesubstitution_30754722/</guid><description>Apache Hive : LanguageManual VariableSubstitution Introduction Using Variables Substitution During Query Construction Disabling Variable Substitution Introduction Hive is used for batch and interactive queries. Variable Substitution allows for tasks such as separating environment-specific configuration variables from code.
The Hive variable substitution mechanism was designed to avoid some of the code that was getting baked into the scripting language on top of Hive.
Examples such as the following shell commands may (inefficiently) be used to set variables within a script:</description></item><item><title>Apache Hive : LanguageManual VirtualColumns</title><link>https://hive.apache.org/docs/latest/languagemanual-virtualcolumns_27362048/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-virtualcolumns_27362048/</guid><description>Apache Hive : LanguageManual VirtualColumns Virtual Columns Simple Examples Virtual Columns Hive 0.8.0 provides support for two virtual columns:
One is INPUT__FILE__NAME, which is the input file&amp;rsquo;s name for a mapper task.
the other is BLOCK__OFFSET__INSIDE__FILE, which is the current global file position.
For block compressed file, it is the current block&amp;rsquo;s file offset, which is the current block&amp;rsquo;s first byte&amp;rsquo;s file offset.
Since Hive 0.</description></item><item><title>Apache Hive : LanguageManual WindowingAndAnalytics</title><link>https://hive.apache.org/docs/latest/languagemanual-windowingandanalytics_31819589/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-windowingandanalytics_31819589/</guid><description>Apache Hive : LanguageManual WindowingAndAnalytics Windowing and Analytics Functions Windowing and Analytics Functions Enhancements to Hive QL Examples PARTITION BY with one partitioning column, no ORDER BY or window specification PARTITION BY with two partitioning columns, no ORDER BY or window specification PARTITION BY with one partitioning column, one ORDER BY column, and no window specification PARTITION BY with two partitioning columns, two ORDER BY columns, and no window specification PARTITION BY with partitioning, ORDER BY, and window specification WINDOW clause LEAD using default 1 row lead and not specifying default value LAG specifying a lag of 3 rows and default value of 0 Distinct counting for each partition Enhancements to Hive QL Version</description></item><item><title>Apache Hive : LanguageManual XPathUDF</title><link>https://hive.apache.org/docs/latest/languagemanual-xpathudf_27362051/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/languagemanual-xpathudf_27362051/</guid><description>Apache Hive : LanguageManual XPathUDF Documentation for Built-In User-Defined Functions Related To XPath
UDFs xpath, xpath_short, xpath_int, xpath_long, xpath_float, xpath_double, xpath_number, xpath_string Functions for parsing XML data using XPath expressions. Since version: 0.6.0 Overview The xpath family of UDFs are wrappers around the Java XPath library javax.xml.xpath provided by the JDK. The library is based on the XPath 1.0 specification. Please refer to http://java.sun.com/javase/6/docs/api/javax/xml/xpath/package-summary.html for detailed information on the Java XPath library.</description></item><item><title>Apache Hive : Links</title><link>https://hive.apache.org/docs/latest/links_27847416/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/links_27847416/</guid><description>Apache Hive : Links Motivation Today, the infrastructure provided by Hive allows for the setup of a single shared warehouse and the authorization model allows for access control within this warehouse if needed. Growth beyond a single warehouse (when datacenter capacity limits are reached) OR separation of capacity usage and allocation requires the creation of multiple warehouses with each warehouse mapping to it&amp;rsquo;s own Hive metastore. Let&amp;rsquo;s define the term physical warehouse to map to a single Hive metastore, the Hadoop cluster it maps to and the data in it.</description></item><item><title>Apache Hive : ListBucketing</title><link>https://hive.apache.org/docs/latest/listbucketing_27846854/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/listbucketing_27846854/</guid><description>Apache Hive : ListBucketing Goal Basic Partitioning List Bucketing Skewed Table vs. List Bucketing Table List Bucketing Validation DDL DML Alter Table Concatenate Hive Enhancements Create Table Alter Table Alter Table Skewed Alter Table Not Skewed Alter Table Not Stored as Directories Alter Table Set Skewed Location Design Implementation Goal The top level problem is as follows:</description></item><item><title>Apache Hive : Literals</title><link>https://hive.apache.org/docs/latest/literals_27829682/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/literals_27829682/</guid><description>Apache Hive : Literals Literals Integral types Integral literals are assumed to be INT by default, unless the number exceeds the range of INT in which case it is interpreted as a BIGINT, or if one of the following postfixes is present on the number.
Type Postfix Example TINYINT Y 100Y SMALLINT S 100S BIGINT L 100L String types String literals can be expressed with either single quotes (') or double quotes (&amp;quot;).</description></item><item><title>Apache Hive : LLAP</title><link>https://hive.apache.org/docs/latest/llap_62689557/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/llap_62689557/</guid><description>Apache Hive : LLAP Overview Persistent Daemon Execution Engine Query Fragment Execution I/O Caching Workload Management ACID Support Security Monitoring Web Services SLIDER on YARN Deployment LLAP Status Resources Live Long And Process (LLAP) functionality was added in Hive 2.0 (HIVE-7926 and associated tasks). HIVE-9850 links documentation, features, and issues for this enhancement.
For configuration of LLAP, see the LLAP Section of Configuration Properties.
Overview Hive has become significantly faster thanks to various features and improvements that were built by the community in recent years, including Tez and Cost-based-optimization.</description></item><item><title>Apache Hive : Locking</title><link>https://hive.apache.org/docs/latest/locking_27362050/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/locking_27362050/</guid><description>Apache Hive : Locking Hive Concurrency Model Hive Concurrency Model Use Cases Turn Off Concurrency Debugging Configuration Locking in Hive Transactions Use Cases Concurrency support (http://issues.apache.org/jira/browse/HIVE-1293) is a must in databases and their use cases are well understood. At a minimum, we want to support concurrent readers and writers whenever possible. It would be useful to add a mechanism to discover the current locks which have been acquired.</description></item><item><title>Apache Hive : Managed vs. External Tables</title><link>https://hive.apache.org/docs/latest/managed-vs-external-tables_95654003/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/managed-vs-external-tables_95654003/</guid><description>Apache Hive : Managed vs. External Tables Hive fundamentally knows two different types of tables:
Managed (Internal) External Introduction This document lists some of the differences between the two but the fundamental difference is that Hive assumes that it owns the data for managed tables. That means that the data, its properties and data layout will and can only be changed via Hive command. The data still lives in a normal file system and nothing is stopping you from changing it without telling Hive about it.</description></item><item><title>Apache Hive : Manual Installation</title><link>https://hive.apache.org/docs/latest/manual-installation_283118363/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/manual-installation_283118363/</guid><description>Apache Hive : Manual Installation Installing, configuring and running Hive Prerequisites Install the prerequisites Java 8 Maven: Protobuf Hadoop Tez Extra hadoop configurations to make everything working Installing Hive from a Tarball Installing from Source Code Installing with old version hadoop(greater than or equal 3.1.0) Next Steps Beeline CLI Hive Metastore HCatalog and WebHCat HCatalog WebHCat (Templeton) Installing, configuring and running Hive You can install a stable release of Hive by downloading and unpacking a tarball, or you can download the source code and build Hive using Maven (release 3.</description></item><item><title>Apache Hive : MapJoin and Partition Pruning</title><link>https://hive.apache.org/docs/latest/mapjoin-and-partition-pruning_34015666/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/mapjoin-and-partition-pruning_34015666/</guid><description>Apache Hive : MapJoin and Partition Pruning Overview Problem Proposed Solution Possible Extensions Optimization Details Compile Time Runtime Pseudo Code Overview In Hive, Map-Join is a technique that materializes data for all tables involved in the join except for the largest table and then large table is streamed over the materialized data from small tables. Map-Join is often a good join approach for star-schema joins where the fact table will be streamed over materialized dimension tables.</description></item><item><title>Apache Hive : MapJoinOptimization</title><link>https://hive.apache.org/docs/latest/mapjoinoptimization_27362029/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/mapjoinoptimization_27362029/</guid><description>Apache Hive : MapJoinOptimization Index
1. Map Join Optimization 1.1 Using Distributed Cache to Propagate Hashtable File 1.2 Removing JDBM 1.3 Performance Evaluation 2. Converting Join into Map Join Automatically 2.1 New Join Execution Flow 2.2 Resolving the Join Operation at Run Time 2.3 Backup Task 2.4 Performance Evaluation 1. Map Join Optimization 1.1 Using Distributed Cache to Propagate Hashtable File Previously, when 2 large data tables need to do a join, there will be 2 different Mappers to sort these tables based on the join key and emit an intermediate file, and the Reducer will take the intermediate file as input file and do the real join work.</description></item><item><title>Apache Hive : Materialized views</title><link>https://hive.apache.org/docs/latest/materialized-views_80447331/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/materialized-views_80447331/</guid><description>Apache Hive : Materialized views Introduction Objectives Management of materialized views in Hive Materialized views creation Other operations for materialized view management Materialized view-based query rewriting Example 1 Example 2 Example 3 Materialized view maintenance Materialized view lifecycle Open issues (JIRA) Version information
Materialized views support is introduced in Hive 3.0.0.
Introduction This page documents the work done for the supporting materialized views in Apache Hive.</description></item><item><title>Apache Hive : Materialized views in Hive</title><link>https://hive.apache.org/docs/latest/materialized-views-in-hive_283118346/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/materialized-views-in-hive_283118346/</guid><description>Apache Hive : Materialized views in Hive Objectives Traditionally, one of the most powerful techniques used to accelerate query processing in data warehouses is the pre-computation of relevant summaries or materialized views.
The initial implementation focuses on introducing materialized views and automatic query rewriting based on those materializations in the project. In particular, materialized views can be stored natively in Hive or in other systems such as Druid using custom storage handlers, and they can seamlessly exploit new exciting Hive features such as LLAP acceleration.</description></item><item><title>Apache Hive : MetaStore API Tests</title><link>https://hive.apache.org/docs/latest/metastore-api-tests_75958143/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/metastore-api-tests_75958143/</guid><description>Apache Hive : MetaStore API Tests IMetaStoreClient Tests IMetaStoreClient Tests One option for Java clients to access the MetaStore is to connect through the IMetaStoreClient interface implementations.
To ensure that the IMetaStoreClient implementations provide the same API we created a set of tests to validate their workings.
Currently the following implementations are tested:
EmbeddedMetaStore – when the MetaStore is running in the same thread, and in process communication is used.</description></item><item><title>Apache Hive : Metastore TLP Proposal</title><link>https://hive.apache.org/docs/latest/metastore-tlp-proposal_71013238/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/metastore-tlp-proposal_71013238/</guid><description>Apache Hive : Metastore TLP Proposal Summary of the Proposal from the Email Hive’s metastore has long been used by other projects in the Hadoop ecosystem to store and access metadata. Apache Impala, Apache Spark, Apache Drill, Presto, and other systems all use Hive’s metastore. Some, like Impala and Presto, can use it as their own metadata system with the rest of Hive not present.
This sharing is excellent for the ecosystem.</description></item><item><title>Apache Hive : MultiDelimitSerDe</title><link>https://hive.apache.org/docs/latest/multidelimitserde_46631999/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/multidelimitserde_46631999/</guid><description>Apache Hive : MultiDelimitSerDe Introduction Introduced in HIVE-5871, MultiDelimitSerDe allows user to specify multiple-character string as the field delimiter when creating a table.
Version Hive 0.14.0 and later.
Hive QL Syntax You can use MultiDelimitSerDe in a create table statement like this:
CREATE TABLE test ( id string, hivearray array&amp;lt;binary&amp;gt;, hivemap map&amp;lt;string,int&amp;gt;) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.MultiDelimitSerDe' WITH SERDEPROPERTIES (&amp;quot;field.delim&amp;quot;=&amp;quot;[,]&amp;quot;,&amp;quot;collection.delim&amp;quot;=&amp;quot;:&amp;quot;,&amp;quot;mapkey.delim&amp;quot;=&amp;quot;@&amp;quot;); where field.delim is the field delimiter, collection.delim and mapkey.delim is the delimiter for collection items and key value pairs, respectively.</description></item><item><title>Apache Hive : OperatorsAndFunctions</title><link>https://hive.apache.org/docs/latest/operatorsandfunctions_30754909/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/operatorsandfunctions_30754909/</guid><description>Apache Hive : OperatorsAndFunctions Hive Operators and Functions Hive Plug-in Interfaces - User-Defined Functions and SerDes
Guide to Hive Operators and Functions
Reflect UDF Generic UDAF Case Study Functions for Statistics and Data Mining</description></item><item><title>Apache Hive : OuterJoinBehavior</title><link>https://hive.apache.org/docs/latest/outerjoinbehavior_35749927/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/outerjoinbehavior_35749927/</guid><description>Apache Hive : OuterJoinBehavior Hive Outer Join Behavior Hive Outer Join Behavior Definitions Predicate Pushdown Rules Hive Implementation Examples Case J1: Join Predicate on Preserved Row Table Case J2: Join Predicate on Null Supplying Table Case W1: Where Predicate on Preserved Row Table Case W2: Where Predicate on Null Supplying Table This document is based on a writeup of DB2 Outer Join Behavior.</description></item><item><title>Apache Hive : Overview of Major Changes</title><link>https://hive.apache.org/docs/latest/overview-of-major-changes_283118379/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/overview-of-major-changes_283118379/</guid><description>Apache Hive : Overview of Major Changes Iceberg Integration Advanced Snapshot management Branches &amp;amp; Tags support DML (insert/update/delete/merge) COW &amp;amp; MOR modes Vectorised Reads &amp;amp; Writes Table migration command LOAD DATA statements support Partition-level operations support Improved statistics (column stats support) Hive ACID Use sequences for TXN_ID generation (performance) Read-only transactions optimization Zero-wait readers Optimistic and Pessimistic concurrency control Lockless reads Compaction Rebalance compaction (Hive ACID) Compaction requests prioritization (compaction pooling) Iceberg compaction (Major) Hive Metastore API optimization (performance) Dynamic leader election External data sources support HMS support for Thrift over HTTP JWT authentication for Thrift over HTTP HMS metadata summary Use Zookeeper for service discovery HiveServer2 Support SAML 2.</description></item><item><title>Apache Hive : Parquet</title><link>https://hive.apache.org/docs/latest/parquet_38570914/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/parquet_38570914/</guid><description>Apache Hive : Parquet Version
Parquet is supported by a plugin in Hive 0.10, 0.11, and 0.12 and natively in Hive 0.13 and later.
  Introduction Native Parquet Support Hive 0.10, 0.11, and 0.12 Hive 0.13 HiveQL Syntax Hive 0.10 - 0.12 Hive 0.13 and later Versions and Limitations Hive 0.13.0 Hive 0.14.0 Hive 1.1.0 Hive 1.2.0 Resources Introduction Parquet (http://parquet.</description></item><item><title>Apache Hive : Partition Filter Syntax</title><link>https://hive.apache.org/docs/latest/partition-filter-syntax_103092177/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/partition-filter-syntax_103092177/</guid><description>Apache Hive : Partition Filter Syntax Example: for a table having partition keys country and state, one could construct the following filter:
country = &amp;quot;USA&amp;quot; AND (state = &amp;quot;CA&amp;quot; OR state = &amp;quot;AZ&amp;quot;)
In particular notice that it is possible to nest sub-expressions within parentheses.
The following operators are supported when constructing filters for partition columns (derived from HIVE-1862):
= &amp;lt; &amp;lt;= &amp;gt; &amp;gt;= &amp;lt;&amp;gt; AND OR LIKE (on keys of type string only, supports literal string template with &amp;lsquo;.</description></item><item><title>Apache Hive : PartitionedViews</title><link>https://hive.apache.org/docs/latest/partitionedviews_27362053/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/partitionedviews_27362053/</guid><description>Apache Hive : PartitionedViews Use Cases Approaches Syntax Metastore Strict Mode View Definition Changes Hook Information This is a followup to ViewDev for adding partition-awareness to views.
Use Cases An administrator wants to create a set of views as a table/column renaming layer on top of an existing set of base tables, without breaking any existing dependencies on those tables. To read-only users, the views should behave exactly the same as the underlying tables in every way.</description></item><item><title>Apache Hive : Performance</title><link>https://hive.apache.org/docs/latest/performance_27362052/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/performance_27362052/</guid><description>Apache Hive : Performance YourKit Java Profiler Collaboration To measure Hive&amp;rsquo;s internal performance, we use the YourKit Java Profiler. YourKit LLC is kindly supporting open source projects with its full-featured Java Profiler. The Hive project has been granted YourKit open source licenses to be used by its developers. For more information on this collaboration, ask on the developers mailing list.
 Benchmarks Here are some JIRA issues about benchmarks for Hive:</description></item><item><title>Apache Hive : Permission Inheritance in Hive</title><link>https://hive.apache.org/docs/latest/permission-inheritance-in-hive_48203008/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/permission-inheritance-in-hive_48203008/</guid><description>Apache Hive : Permission Inheritance in Hive This document describes how attributes (permission, group, extended ACL&amp;rsquo;s) of files representing Hive data are determined.
HDFS Background When a file or directory is created, its owner is the user identity of the client process, and its group is inherited from parent (the BSD rule). Permissions are taken from default umask. Extended Acl&amp;rsquo;s are taken from parent unless they are set explicitly. Goals To reduce need to set fine-grain file security props after every operation, users may want the following Hive warehouse file/dir to auto-inherit security properties from their directory parents:</description></item><item><title>Apache Hive : PluginDeveloperKit</title><link>https://hive.apache.org/docs/latest/plugindeveloperkit_27820324/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/plugindeveloperkit_27820324/</guid><description>Apache Hive : PluginDeveloperKit Hive Plugin Developer Kit This page explains Apache Hive&amp;rsquo;s Plugin Developer Kit, or PDK. This allows developers to build and test Hive plugins without having to set up a Hive source build; only a Hive binary release is needed.
The PDK is planned for inclusion in the Hive 0.8.0 release; until that is available, please download a recent snapshot build from Jenkins; make sure it includes HIVE-2244.</description></item><item><title>Apache Hive : PoweredBy</title><link>https://hive.apache.org/docs/latest/poweredby_27362055/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/poweredby_27362055/</guid><description>Apache Hive : PoweredBy Applications and organizations using Hive include (alphabetically):
Bizo We use Hive for reporting and ad hoc queries.
Chitika We use Hive for data mining and analysis on our 435M monthly global users.
CNET We use Hive for data mining, internal log analysis and ad hoc queries.
Digg We use Hive for data mining, internal log analysis, R&amp;amp;D, and reporting/analytics.
eHarmony We use Hadoop to store copies of internal log and dimension data sources and use it as a source for reporting/analytics and machine learning.</description></item><item><title>Apache Hive : Presentations</title><link>https://hive.apache.org/docs/latest/presentations_27362054/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/presentations_27362054/</guid><description>Apache Hive : Presentations   Hive Meetups January 2016 Hive User Group Meetup November 2015 Hive Contributor Meetup April 2015 Hive Contributor Meetup Presentations February 2015 Hive User Meetup Presentation November 2013 Hive Contributors Meetup Presentations June 2013 Hadoop Summit Hive Meetup Presentations February 2013 Hive User Group Meetup June 2012 Hadoop Summit Hive Meetup Presentations November 2011 NYC Hive Meetup Presentations Older Hive Presentations Related Work Hive Meetups January 2016 Hive User Group Meetup attachments/27362054/61337098-pptx attachments/27362054/61337312-ppsx attachments/27362054/61337398-ppsx Hive on Spark: now and future - Xuefu Zhang November 2015 Hive Contributor Meetup attachments/27362054/61329032-pptx attachments/27362054/61329033-pptx attachments/27362054/61329034-pptx attachments/27362054/61329036-pptx attachments/27362054/61329038-pptx attachments/27362054/61329039.</description></item><item><title>Apache Hive : Query ReExecution</title><link>https://hive.apache.org/docs/latest/query-reexecution_87298873/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/query-reexecution_87298873/</guid><description>Apache Hive : Query ReExecution Query reexecution provides a facility to re-run the query multiple times in case of an unfortunate event happens.
ReExecition strategies Overlay Reoptimize Operator Matching Configuration Introduced in Hive 3.0 (HIVE-17626)
ReExecition strategies Overlay Enables to change the hive settings for all reexecutions which will be happening. It works by adding a configuration subtree as an overlay to the actual hive settings(reexec.</description></item><item><title>Apache Hive : Query Results Caching (HIVE-18513)</title><link>https://hive.apache.org/docs/latest/75963441/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/75963441/</guid><description>Apache Hive : Query Results Caching (HIVE-18513) Introduction This document proposes the addition of a query results cache to Hive. Caching query results allows a previously computed query result to be re-used in the event that the same query is processed by Hive. This can save both time and resources spent running the cluster tasks required for the query.
Background Existing behavior for Hive query processing (very simplified):
Hive query compilation takes the query string and produces a QueryPlan.</description></item><item><title>Apache Hive : RCFile</title><link>https://hive.apache.org/docs/latest/rcfile_58851803/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/rcfile_58851803/</guid><description>Apache Hive : RCFile RCFile (Record Columnar File) is a data placement structure designed for MapReduce-based data warehouse systems. Hive added the RCFile format in version 0.6.0.
RCFile stores table data in a flat file consisting of binary key/value pairs. It first partitions rows horizontally into row splits, and then it vertically partitions each row split in a columnar way. RCFile stores the metadata of a row split as the key part of a record, and all the data of a row split as the value part.</description></item><item><title>Apache Hive : RCFileCat</title><link>https://hive.apache.org/docs/latest/rcfilecat_30748712/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/rcfilecat_30748712/</guid><description>Apache Hive : RCFileCat RCFileCat RCFileCat Data Metadata $HIVE_HOME/bin/hive &amp;ndash;rcfilecat is a shell utility which can be used to print data or metadata from RC files.
Data Prints out the rows stored in an RCFile, columns are tab separated and rows are newline separated.
Usage:
hive --rcfilecat [--start=start_offset] [--length=len] [--verbose] fileName --start=start_offset Start offset to begin reading in the file --length=len Length of data to read from the file --verbose Prints periodic stats about the data read, how many records, how many bytes, scan rate Metadata New in 0.</description></item><item><title>Apache Hive : Rebalance compaction</title><link>https://hive.apache.org/docs/latest/rebalance-compaction_240884502/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/rebalance-compaction_240884502/</guid><description>Apache Hive : Rebalance compaction In order to improve performance, Hive under the hood creates bucket files even for non-explicitly bucketed tables. Depending on the usage, the data loaded into these non-explicitly bucketed full-acid ORC tables may lead to unbalanced distribution, where some of the buckets are much larger (&amp;gt; 100 times) than the others. Unbalanced tables has performance penalty, as larger buckets takes more time to read. Rebalance compaction addresses this issue by equally redistributing the data among the implicit bucket files.</description></item><item><title>Apache Hive : ReflectUDF</title><link>https://hive.apache.org/docs/latest/reflectudf_30754716/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/reflectudf_30754716/</guid><description>Apache Hive : ReflectUDF Reflect (Generic) UDF A Java class and method often exists to handle the exact function a user would like to use in Hive. Rather than having to write a wrapper UDF to call this method, the majority of these methods can be called using reflect UDF. Reflect uses Java reflection to instantiate and call methods of objects; it can also call static functions. The method must return a primitive type or a type that Hive knows how to serialize.</description></item><item><title>Apache Hive : RelatedProjects</title><link>https://hive.apache.org/docs/latest/relatedprojects_34836686/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/relatedprojects_34836686/</guid><description>Apache Hive : RelatedProjects Shark Shark is a fork of Apache Hive that uses Spark in place of MapReduce.
Apache Hivemall (incubating) Apache Hivemall is a scalable machine learning library for Apache Hive, Apache Spark, and Apache Pig.
Apache Sentry (incubating) Sentry is a role-based authorization system for Apache Hive.</description></item><item><title>Apache Hive : Replacing the Implementation of Hive CLI Using Beeline</title><link>https://hive.apache.org/docs/latest/replacing-the-implementation-of-hive-cli-using-beeline_61311909/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/replacing-the-implementation-of-hive-cli-using-beeline_61311909/</guid><description>Apache Hive : Replacing the Implementation of Hive CLI Using Beeline Why Replace the Existing Hive CLI? Hive CLI Functionality Support Hive CLI Options Support Examples Hive CLI Interactive Shell Commands Support Hive CLI Configuration Support Performance Impacts Why Replace the Existing Hive CLI? Hive CLI is a legacy tool which had two main use cases. The first is that it served as a thick client for SQL on Hadoop and the second is that it served as a command line tool for Hive Server (the original Hive server, now often referred to as &amp;ldquo;HiveServer1&amp;rdquo;).</description></item><item><title>Apache Hive : Replication</title><link>https://hive.apache.org/docs/latest/replication_61336919/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/replication_61336919/</guid><description>Apache Hive : Replication Overview Potential Uses Prerequisites Limitations Configuration Typical Mode of Operation Replication to AWS/EMR/S3 Overview Hive Replication builds on the metastore event and ExIm features to provide a framework for replicating Hive metadata and data changes between clusters. There is no requirement for the source cluster and replica to run the same Hadoop distribution, Hive version, or metastore RDBMS. The replication system has a fairly &amp;lsquo;light touch&amp;rsquo;, exhibiting a low degree of coupling and using the Hive-metastore Thrift service as an integration point.</description></item><item><title>Apache Hive : Roadmap</title><link>https://hive.apache.org/docs/latest/roadmap_27362057/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/roadmap_27362057/</guid><description>Apache Hive : Roadmap Before adding to the list below, please check JIRA to see if a ticket has already been opened for the feature. If not, please open a ticket on the Hive JIRA and also update the following list.
Features to be added Major Recent Changes Table Statistics Archiving Indexing First Cut Concurrency Conversion to Map-Join at Runtime Support for Multiple Distincts Remove Partition Filtering Conditions INSERT INTO statement Block-level merge HAVING clause support Cross-database queries Bitmap Index Use Filter Pushdown for Automatically Accessing Indexes Remove Duplicate Filters Authentication Authorization Current Projects Bloom Filters TIMESTAMP data type Up For Grabs Priorities are denoted as P0 &amp;gt; P1 &amp;gt; &amp;hellip;</description></item><item><title>Apache Hive : Running Yetus</title><link>https://hive.apache.org/docs/latest/running-yetus_71012969/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/running-yetus_71012969/</guid><description>Apache Hive : Running Yetus Overview Yetus is added to Hive in release 3.0.0 to run checks on the new patches. See HIVE-15051.
There are several rules already defined by the community, but most of them are not enforced.
Yetus helps us by checking these rules for newly introduced errors. Note that Yetus checks only the changed part of the code. If any unchanged code contains errors, then Yetus will not report them, but all of the new code should conform to the rules.</description></item><item><title>Apache Hive : Scheduled Queries</title><link>https://hive.apache.org/docs/latest/scheduled-queries_145724128/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/scheduled-queries_145724128/</guid><description>Apache Hive : Scheduled Queries Maintaining scheduled queries Create Scheduled query syntax Alter Scheduled query syntax Drop syntax scheduleSpecification syntax CRON based schedule syntax EVERY based schedule syntax ExecutedAs syntax enableSpecification syntax Defined AS syntax executeSpec syntax System tables/views information_schema.scheduled_queries information_schema.scheduled_executions Execution states Configuration Hive metastore related configuration HiveServer2 related configuration Examples Example 1 – basic example of using schedules Example 2 – analyze external table periodically Example 3 – materialized view rebuild Example 4 – Ingestion Intro</description></item><item><title>Apache Hive : Security</title><link>https://hive.apache.org/docs/latest/security_27362056/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/security_27362056/</guid><description>Apache Hive : Security This page collects some resources and pointers for various efforts underway to add security features to Hive and related projects.
Authorization modes
The links below refer to the original Hive authorization mode. See Authorization for an overview of authorization modes, which include storage based authorization and SQL standards based authorization.
Thoughts on security from Venkatesh Howl&amp;rsquo;s approach for persisting and validating DDL authorization via HDFS permissions HIVE-1264: Hadoop security integration THRIFT-889: allow Kerberos authentication over Thrift HTTP THRIFT-876: SASL integration Howl Authorization Proposal Hive Authorization Proposal Note that Howl was the precursor to HCatalog.</description></item><item><title>Apache Hive : SerDe</title><link>https://hive.apache.org/docs/latest/serde_27362059/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/serde_27362059/</guid><description>Apache Hive : SerDe SerDe Overview Built-in and Custom SerDes Built-in SerDes Custom SerDes HiveQL for SerDes Input Processing Output Processing Additional Notes SerDe Overview SerDe is short for Serializer/Deserializer. Hive uses the SerDe interface for IO. The interface handles both serialization and deserialization and also interpreting the results of serialization as individual fields for processing.
A SerDe allows Hive to read in data from a table, and write it back out to HDFS in any custom format.</description></item><item><title>Apache Hive : Setting Up Hive with Docker</title><link>https://hive.apache.org/docs/latest/setting-up-hive-with-docker_282102281/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/setting-up-hive-with-docker_282102281/</guid><description>Apache Hive : Setting Up Hive with Docker Introduction Run Apache Hive inside docker container in pseudo-distributed mode
STEP 1: Pull the image Pull the 4.0.0 image from Hive DockerHub docker pull apache/hive:4.0.0 STEP 2: Export the Hive version export HIVE_VERSION=4.0.0 STEP 3: Launch the HiveServer2 with an embedded Metastore. This is lightweight and for a quick setup, it uses Derby as metastore db.
docker run -d -p 10000:10000 -p 10002:10002 --env SERVICE_NAME=hiveserver2 --name hive4 apache/hive:${HIVE_VERSION} STEP 4: Connect to beeline docker exec -it hiveserver2 beeline -u 'jdbc:hive2://hiveserver2:10000/' Note: Launch Standalone Metastore To use standalone Metastore with Derby,</description></item><item><title>Apache Hive : Setting Up HiveServer2</title><link>https://hive.apache.org/docs/latest/setting-up-hiveserver2_30758712/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/setting-up-hiveserver2_30758712/</guid><description>Apache Hive : Setting Up HiveServer2 HiveServer2 HiveServer2 How to Configure Configuration Properties in the hive-site.xml File Running in HTTP Mode Cookie Based Authentication Optional Global Init File Logging Configuration How to Start Usage Message Authentication/Security Configuration Configuration Impersonation Integrity/Confidentiality Protection SSL Encryption Setting up SSL with self-signed certificates Selectively disabling SSL protocol versions Pluggable Authentication Modules (PAM) Setting up HiveServer2 job credential provider Scratch Directory Management Configuration Properties ClearDanglingScratchDir Tool Web UI for HiveServer2 Python Client Driver Ruby Client Driver HiveServer2 (HS2) is a server interface that enables remote clients to execute queries against Hive and retrieve the results (a more detailed intro here).</description></item><item><title>Apache Hive : Skewed Join Optimization</title><link>https://hive.apache.org/docs/latest/skewed-join-optimization_27847852/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/skewed-join-optimization_27847852/</guid><description>Apache Hive : Skewed Join Optimization Optimizing Skewed Joins The Problem A join of 2 large data tables is done by a set of MapReduce jobs which first sorts the tables based on the join key and then joins them. The Mapper gives all rows with a particular key to the same Reducer.
e.g., Suppose we have table A with a key column, &amp;ldquo;id&amp;rdquo; which has values 1, 2, 3 and 4, and table B with a similar column, which has values 1, 2 and 3.</description></item><item><title>Apache Hive : Spatial queries</title><link>https://hive.apache.org/docs/latest/spatial-queries_34022710/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/spatial-queries_34022710/</guid><description>Apache Hive : Spatial queries Overview Hadoop-GIS is a scalable and high performance spatial data warehousing system for running large-scale spatial queries on Hadoop. Hadoop-GIS relies on RESQUE for spatial query processing. RESQUE is a internally developed tile based spatial query engine which is written in C++ and deployed as shared library.
Hive****SP: we integrate Hadoop-GIS with Hive, to support both structured queries and spatial queries with a unified query language (HQL) and interface (Hive Shell).</description></item><item><title>Apache Hive : SQL Standard Based Hive Authorization</title><link>https://hive.apache.org/docs/latest/sql-standard-based-hive-authorization_40509928/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/sql-standard-based-hive-authorization_40509928/</guid><description>Apache Hive : SQL Standard Based Hive Authorization Status of Hive Authorization before Hive 0.13 SQL Standards Based Hive Authorization (New in Hive 0.13) Restrictions on Hive Commands and Statements Privileges Objects Object Ownership Users and Roles Names of Users and Roles Role Management Commands Managing Object Privileges Object Privilege Commands Examples of Managing Object Privileges Privileges Required for Hive Operations Configuration For Hive 0.</description></item><item><title>Apache Hive : StarRocks Integration</title><link>https://hive.apache.org/docs/latest/starrocks-integration_272927528/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/starrocks-integration_272927528/</guid><description>Apache Hive : StarRocks Integration StarRocks has the ability to setup a Hive catalog which enables you to query data from Hive without loading data into StarRocks or creating external tables. See here for more information. </description></item><item><title>Apache Hive : StatisticsAndDataMining</title><link>https://hive.apache.org/docs/latest/statisticsanddatamining_27362058/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/statisticsanddatamining_27362058/</guid><description>Apache Hive : StatisticsAndDataMining Statistics and Data Mining in Hive This page is the secondary documentation for the slightly more advanced statistical and data mining functions that are being integrated into Hive, and especially the functions that warrant more than one-line descriptions.
Statistics and Data Mining in Hive ngrams() and context_ngrams(): N-gram frequency estimation Use Cases Usage Example histogram_numeric(): Estimating frequency distributions Use Cases Usage Example ngrams() and context_ngrams(): N-gram frequency estimation N-grams are subsequences of length N drawn from a longer sequence.</description></item><item><title>Apache Hive : StatsDev</title><link>https://hive.apache.org/docs/latest/statsdev_27362062/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/statsdev_27362062/</guid><description>Apache Hive : StatsDev Statistics in Hive Statistics in Hive Motivation Scope Table and Partition Statistics Column Statistics Top K Statistics Quick overview Implementation Usage Configuration Variables Newly Created Tables Existing Tables – ANALYZE Examples ANALYZE TABLE CACHE METADATA Current Status (JIRA) This document describes the support of statistics for Hive tables (see HIVE-33).
Motivation Statistics such as the number of rows of a table or partition and the histograms of a particular interesting column are important in many ways.</description></item><item><title>Apache Hive : Storage API Release Proposal</title><link>https://hive.apache.org/docs/latest/storage-api-release-proposal_67635447/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/storage-api-release-proposal_67635447/</guid><description>Apache Hive : Storage API Release Proposal To enable faster and more direct integration of file formats like ORC and Parquet, Hive has separated out the Storage API as a distinct subproject and will release it independently of the rest of Hive. The storage-api source code will remain in the Hive git repository. The initial work on the pom files was done in HIVE-15419. The plan is to start the Storage API releases at 2.</description></item><item><title>Apache Hive : Storage Based Authorization in the Metastore Server</title><link>https://hive.apache.org/docs/latest/storage-based-authorization-in-the-metastore-server_45876440/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/storage-based-authorization-in-the-metastore-server_45876440/</guid><description>Apache Hive : Storage Based Authorization in the Metastore Server Storage Based Authorization in the Metastore Server The Need for Metastore Server Security Storage Based Authorization Configuration Parameters for Metastore Security Sample hive-site.xml: Default Settings Storage Based Authorization in the Metastore Server The metastore server security feature with storage based authorization was added to Hive in release 0.10. This feature was introduced previously in HCatalog.</description></item><item><title>Apache Hive : StorageHandlers</title><link>https://hive.apache.org/docs/latest/storagehandlers_27362063/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/storagehandlers_27362063/</guid><description>Apache Hive : StorageHandlers Hive Storage Handlers Hive Storage Handlers Introduction Terminology DDL Storage Handler Interface HiveMetaHook Interface Open Issues Introduction This page documents the storage handler support being added to Hive as part of work on HBaseIntegration. The motivation is to make it possible to allow Hive to access data stored and managed by other systems in a modular, extensible fashion.
Besides HBase, a storage handler implementation is also available for Hypertable, and others are being developed for Cassandra, Azure Table, JDBC (MySQL and others), MongoDB, ElasticSearch, Phoenix HBase, VoltDB and Google Spreadsheets.</description></item><item><title>Apache Hive : Streaming Data Ingest</title><link>https://hive.apache.org/docs/latest/streaming-data-ingest_40509746/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/streaming-data-ingest_40509746/</guid><description>Apache Hive : Streaming Data Ingest Hive 3 Streaming API Hive HCatalog Streaming API Streaming Mutation API Streaming Requirements Limitations API Usage Transaction and Connection Management HiveEndPoint StreamingConnection TransactionBatch Usage Guidelines Notes about the HiveConf Object I/O – Writing Data RecordWriter DelimitedInputWriter StrictJsonWriter StrictRegexWriter AbstractRecordWriter Error Handling Example – Non-secure Mode Example – Secure Streaming Knowledge Base Hive 3 Streaming API Hive 3 Streaming API Documentation - new API available in Hive 3</description></item><item><title>Apache Hive : Streaming Data Ingest V2</title><link>https://hive.apache.org/docs/latest/streaming-data-ingest-v2_85477610/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/streaming-data-ingest-v2_85477610/</guid><description>Apache Hive : Streaming Data Ingest V2 Starting in release Hive 3.0.0, Streaming Data Ingest is deprecated and is replaced by newer V2 API (HIVE-19205).  Hive Streaming API Streaming Mutation API Deprecation and Removal Streaming Requirements Limitations API Usage Transaction and Connection Management HiveStreamingConnection Usage Guidelines Notes about the HiveConf Object I/O – Writing Data RecordWriter StrictDelimitedInputWriter StrictJsonWriter StrictRegexWriter AbstractRecordWriter Error Handling Example Hive Streaming API Traditionally adding new data into Hive requires gathering a large amount of data onto HDFS and then periodically adding a new partition.</description></item><item><title>Apache Hive : Subqueries in SELECT</title><link>https://hive.apache.org/docs/latest/subqueries-in-select_68717850/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/subqueries-in-select_68717850/</guid><description>Apache Hive : Subqueries in SELECT Problem Currently Hive doesn&amp;rsquo;t support subqueries in a SELECT statement, for example, the following query will not run on Hive:
SELECT customer.customer_num, (SELECT SUM(ship_charge) FROM orders WHERE customer.customer_num = orders.customer_num ) AS total_ship_chg FROM customer Recently a lot of work has been done to extend support for subqueries (HIVE-15456). But this work primarily targeted extending subquery support in WHERE and HAVING clauses. We plan to continue the work done in HIVE-15456 to support subqueries in a select list (see HIVE-16091).</description></item><item><title>Apache Hive : Suggestion for DDL Commands in HMS schema upgrade scripts</title><link>https://hive.apache.org/docs/latest/suggestion-for-ddl-commands-in-hms-schema-upgrade-scripts_138022168/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/suggestion-for-ddl-commands-in-hms-schema-upgrade-scripts_138022168/</guid><description>Apache Hive : Suggestion for DDL Commands in HMS schema upgrade scripts In this page, I would like to share the information I learned from Braintree&amp;rsquo;s Blog about how they handle DB schema migration while application is up and serving requests. I think this should benefits to developer who is working on HMS&amp;rsquo;s schema upgrade scripts. As for some DDL commands, they can lock out updates to a table for a long time and database operation that locks for more than a few seconds is indistinguishable from an outage for customers.</description></item><item><title>Apache Hive : Supported Features: Apache Hive 3.1</title><link>https://hive.apache.org/docs/latest/97551656/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/97551656/</guid><description>Apache Hive : Supported Features: Apache Hive 3.1 This table covers all mandatory features from SQL:2016 as well as optional features that Hive implements.
Feature ID Feature Name Implemented Mandatory Comments E011 Numeric data types Yes Mandatory E011-01 INTEGER and SMALLINT data types (including all spellings) Yes Mandatory E011-02 REAL, DOUBLE PRECISON, and FLOAT data types Yes Mandatory E011-03 DECIMAL and NUMERIC data types Yes Mandatory E011-04 Arithmetic operators Yes Mandatory E011-05 Numeric comparison Yes Mandatory E011-06 Implicit casting among the numeric data types Yes Mandatory E021 Character string types Yes Mandatory E021-01 CHARACTER data type (including all its spellings) Partial Mandatory Only support CHAR, not CHARACTER E021-02 CHARACTER VARYING data type (including all its spellings) Partial Mandatory Only support VARCHAR, not CHARACTER VARYING or CHAR VARYING E021-03 Character literals Yes Mandatory E021-04 CHARACTER_LENGTH function Yes Mandatory E021-05 OCTET_LENGTH function Yes Mandatory E021-06 SUBSTRING function Partial Mandatory Standard: SUBSTRING(val FROM startpos [FOR len]).</description></item><item><title>Apache Hive : Supported Features: Apache Hive 2.1</title><link>https://hive.apache.org/docs/latest/67641451/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/67641451/</guid><description>Apache Hive : Supported Features: Apache Hive 2.1 Identifier Description Hive 2.1 Comment E011 Numeric data types Yes E011-01 INTEGER and SMALLINT data types (including all spellings) Yes Int instead of Integer E011-02 REAL, DOUBLE PRECISON,and FLOAT data types Yes Double instead of Double Precision E011-03 DECIMAL and NUMERIC data types Yes E011-04 Arithmetic operators Yes E011-05 Numeric comparison Yes E011-06 Implicit casting among the numeric data types Yes E021 Character data types Yes E021-01 CHARACTER data type Yes Char instead of Character E021-02 CHARACTER VARYING data type Yes Varchar instead of Character Varying E021-03 Character literals Yes E021-04 CHARACTER_LENGTH function Partial length UDF provided E021-06 SUBSTRING function Yes E021-07 Character concatenation Yes concat UDF instead of standard E021-08 UPPER and LOWER functions Yes E021-09 TRIM function Partial leading / trailing / both from not supported E021-10 Implicit casting among the fixed-length and variablelength character string types Yes E021-12 Character comparison Yes E031 Identifiers Yes E031-01 Delimited identifiers Partial Backtick (`) used instead of (&amp;quot;).</description></item><item><title>Apache Hive : Supported Features: Apache Hive 2.3</title><link>https://hive.apache.org/docs/latest/73632935/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/73632935/</guid><description>Apache Hive : Supported Features: Apache Hive 2.3 Identifier Description Hive 2.3 Comment E011 Numeric data types Yes E011-01 INTEGER and SMALLINT data types (including all spellings) Yes E011-02 REAL, DOUBLE PRECISON,and FLOAT data types Yes E011-03 DECIMAL and NUMERIC data types Yes E011-04 Arithmetic operators Yes E011-05 Numeric comparison Yes E011-06 Implicit casting among the numeric data types Yes E021 Character data types Yes E021-01 CHARACTER data type Yes Char instead of Character E021-02 CHARACTER VARYING data type Yes Varchar instead of Character Varying E021-03 Character literals Yes E021-04 CHARACTER_LENGTH function Yes E021-05 OCTET_LENGTH function Yes E021-06 SUBSTRING function Yes E021-07 Character concatenation Yes E021-08 UPPER and LOWER functions Yes E021-09 TRIM function Partial leading / trailing / both from not supported E021-10 Implicit casting among the fixed-length and variablelength character string types Yes E021-12 Character comparison Yes E031 Identifiers Yes E031-01 Delimited identifiers Yes E031-03 Trailing underscore Yes E051 Basic query specification Yes E051-01 SELECT DISTINCT Yes E051-02 GROUP BY clause Partial Empty grouping sets not supported E051-04 GROUP BY can contain columns not in Yes E051-05 Select list items can be renamed Yes E051-06 HAVING clause Yes E051-07 Qualified * in select list Yes E051-08 Correlation names in the FROM clause Yes E061 Basic predicates and search conditions Yes E061-01 Comparison predicate Yes E061-02 BETWEEN predicate Yes E061-03 IN predicate with list of values Yes E061-04 LIKE predicate Yes E061-06 NULL predicate Yes E061-08 EXISTS predicate Yes E061-09 Subqueries in comparison predicate Yes E061-11 Subqueries in IN predicate Yes E061-13 Correlated subqueries Yes E071 Basic query expressions Yes E071-01 UNION DISTINCT table operator Yes E071-02 UNION ALL table operator Yes E071-03 EXCEPT DISTINCT table operator Yes E071-05 Columns combined via table operators need not have exactly the same data type.</description></item><item><title>Apache Hive : Synchronized Metastore Cache</title><link>https://hive.apache.org/docs/latest/synchronized-metastore-cache_110692851/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/synchronized-metastore-cache_110692851/</guid><description>Apache Hive : Synchronized Metastore Cache Overview This work is to solve the consistency problem if we use HMS HA with metadata cache. Note it does not aim to address any existing consistency issues already exist in non-cached HMS. For example, it won’t fix the transaction semantic between metadata and data. If the problem exists today in non-cached HMS, it stays a problem after this work.
The problem we try to solve here is the cache consistency issue.</description></item><item><title>Apache Hive : TeradataBinarySerde</title><link>https://hive.apache.org/docs/latest/teradatabinaryserde_89068127/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/teradatabinaryserde_89068127/</guid><description>Apache Hive : TeradataBinarySerde Availability Overview How to export Using TPT FastExport Using BTEQ How to import Using BTEQ Using TPT FastLoad Usage Table Creating Table Properties Teradata to Hive Type Conversion Serde Restriction Availability Earliest version CSVSerde is available
The TeradataBinarySerDe is available in Hive 2.4 or greater.
Overview Teradata can use TPT(Teradata Parallel Transporter) or BTEQ(Basic Teradata Query) to export and import data files compressed by gzip in very high speed.</description></item><item><title>Apache Hive : TestingDocs</title><link>https://hive.apache.org/docs/latest/testingdocs_42567126/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/testingdocs_42567126/</guid><description>Apache Hive : TestingDocs Hive Testing Documents The following documents describe aspects of testing for Hive:
Hive Developer FAQ: Testing Developer Guide: Unit Tests Unit Testing Hive SQL Running Yetus MetaStore API Tests Query File Test(qtest)</description></item><item><title>Apache Hive : Theta Join</title><link>https://hive.apache.org/docs/latest/theta-join_33293991/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/theta-join_33293991/</guid><description>Apache Hive : Theta Join Preliminaries Overview Specific Use Cases Geo-Location Side-Table Similarity Requirements Goals Specific Non-Goals Literature Review Map-Reduce-Merge: Simplified Relational Data Processing on Large Clusters [1] Efficient Parallel Set-Similarity Joins Using MapReduce [2] Processing Theta-Joins using MapReduce [3] Efficient Multi-way Theta-Join Processing Using MapReduce [4] Design Map-side Reduce-side Mapper Reducer References Preliminaries Overview HIVE-556 requests that Hive support non-equality joins commonly called theta joins.</description></item><item><title>Apache Hive : Top K Stats</title><link>https://hive.apache.org/docs/latest/top-k-stats_30150275/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/top-k-stats_30150275/</guid><description>Apache Hive : Top K Stats Column Level Top K Statistics Column Level Top K Statistics Scope Implementation Usage Example Newly Created Tables Existing Tables Current Status (JIRA) This document is an addition to Statistics in Hive. It describes the support of collecting column level top K values for Hive tables (see HIVE-3421).
Scope In addition to the partition statistics, column level top K values can also be estimated for Hive tables.</description></item><item><title>Apache Hive : Transitivity on predicate pushdown</title><link>https://hive.apache.org/docs/latest/transitivity-on-predicate-pushdown_27823388/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/transitivity-on-predicate-pushdown_27823388/</guid><description>Apache Hive : Transitivity on predicate pushdown Before Hive 0.8.0, the query
set hive.mapred.mode=strict; create table invites (foo int, bar string) partitioned by (ds string); create table invites2 (foo int, bar string) partitioned by (ds string); select count(*) from invites join invites2 on invites.ds=invites2.ds where invites.ds='2011-01-01'; would give the error
Error in semantic analysis: No Partition Predicate Found for Alias &amp;quot;invites2&amp;quot; Table &amp;quot;invites2&amp;quot; Here, the filter is applied to the table invites as invites.</description></item><item><title>Apache Hive : Tutorial</title><link>https://hive.apache.org/docs/latest/tutorial_27362061/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/tutorial_27362061/</guid><description>Apache Hive : Tutorial Hive Tutorial Hive Tutorial Concepts What Is Hive What Hive Is NOT Getting Started Data Units Type System Built In Operators and Functions Language Capabilities Usage and Examples Concepts What Is Hive Hive is a data warehousing infrastructure based on Apache Hadoop. Hadoop provides massive scale out and fault tolerance capabilities for data storage and processing on commodity hardware.
Hive is designed to enable easy data summarization, ad-hoc querying and analysis of large volumes of data.</description></item><item><title>Apache Hive : Type Qualifiers in Hive</title><link>https://hive.apache.org/docs/latest/type-qualifiers-in-hive_33298524/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/type-qualifiers-in-hive_33298524/</guid><description>Apache Hive : Type Qualifiers in Hive Intro Hive will need to support some kind of type qualifiers/parameters in its type metadata to be able to enforce type features such as decimal precision/scale or char/varchar length and collation. This involves changes to the PrimitiveTypeEntry/TypeInfo/ObjectInspectors, possibly metastore changes,
My impression is that the actual enforcement of the type qualifiers should be done by the ObjectInspectors/Converters/casts operations. It should be ok to do col * col when col is a decimal(2) value of 99, it would fail if you try to cast the result to decimal(2) or try to insert it to a decimal(2) column.</description></item><item><title>Apache Hive : Union Optimization</title><link>https://hive.apache.org/docs/latest/union-optimization_29688910/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/union-optimization_29688910/</guid><description>Apache Hive : Union Optimization Consider the query
select * from
(subq1
UNION ALL
sub2) u;
If the parents to union were map reduce jobs, they will write the output to temporary files. The Union will then read the rows from these temporary files and write to a final directory. In effect, the results are read and written twice unnecessarily. We can avoid this by directly writing to the final directory.</description></item><item><title>Apache Hive : Unit Testing Hive SQL</title><link>https://hive.apache.org/docs/latest/unit-testing-hive-sql_61328063/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/unit-testing-hive-sql_61328063/</guid><description>Apache Hive : Unit Testing Hive SQL Motivations Challenges Modularisation Encapsulation of column level logic Encapsulation of set level logic Tools and frameworks Useful practices Relevant issues Other Hive unit testing concerns Motivations Hive is widely applied as a solution to numerous distinct problem types in the domain of big data. Quite clearly it is often used for the ad hoc querying of large datasets. However it is also used to implement ETL type processes.</description></item><item><title>Apache Hive : UpdatableViews</title><link>https://hive.apache.org/docs/latest/updatableviews_27824044/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/updatableviews_27824044/</guid><description>Apache Hive : UpdatableViews Proposal Hive will consider a view updatable if:
The view refers to exactly one base table or updatable view in the FROM clause without a WHERE clause. Each column in the view is a column in the underlying table/updatable view with no underlying columns duplicated. Views must have the same partition columns as the underlying table/updatable view. When inserting into a view:
If a view does not specify all underlying columns, NULL will be inserted for each column not specified.</description></item><item><title>Apache Hive : User and Group Filter Support with LDAP Atn Provider in HiveServer2</title><link>https://hive.apache.org/docs/latest/user-and-group-filter-support-with-ldap-atn-provider-in-hiveserver2_58852417/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user-and-group-filter-support-with-ldap-atn-provider-in-hiveserver2_58852417/</guid><description>Apache Hive : User and Group Filter Support with LDAP Atn Provider in HiveServer2 User and Group Filter Support with LDAP Group Membership hive.server2.authentication.ldap.groupDNPattern hive.server2.authentication.ldap.groupFilter hive.server2.authentication.ldap.groupMembershipKey hive.server2.authentication.ldap.groupClassKey User Search List hive.server2.authentication.ldap.userDNPattern hive.server2.authentication.ldap.userFilter Custom Query String hive.server2.authentication.ldap.customLDAPQuery Support for Groups in Custom LDAP Query Order of Precedence User and Group Filter Support with LDAP Starting in Hive 1.</description></item><item><title>Apache Hive : User FAQ</title><link>https://hive.apache.org/docs/latest/user-faq_27362095/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user-faq_27362095/</guid><description>Apache Hive : User FAQ Hive User FAQ Hive User FAQ General I see errors like: Server access Error: Connection timed out url=http://archive.apache.org/dist/hadoop/core/hadoop-0.20.1/hadoop-0.20.1.tar.gz How to change the warehouse.dir location for older tables? When running a JOIN query, I see out-of-memory errors. I am using MySQL as metastore and I see errors: &amp;ldquo;com.mysql.jdbc.exceptions.jdbc4.!CommunicationsException: Communications link failure&amp;rdquo; Does Hive support Unicode? Hive SQL Are Hive SQL identifiers (e.</description></item><item><title>Apache Hive : UserGuide</title><link>https://hive.apache.org/docs/latest/userguide_27362066/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/userguide_27362066/</guid><description>Apache Hive : UserGuide NOTE: This page is deprecated and merged into GettingStarted.
User Guide The query language specification is available at LanguageManual. Also see, GettingStarted for setup instructions.
Supported Features Usage Examples Creating tables MovieLens User Ratings CREATE TABLE u_data ( userid INT, movieid INT, rating INT, unixtime STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' STORED AS TEXTFILE; Apache Access Log Tables add jar ../build/contrib/hive_contrib.jar; CREATE TABLE apachelog ( host STRING, identity STRING, user STRING, time STRING, request STRING, status STRING, size STRING, referer STRING, agent STRING) ROW FORMAT SERDE 'org.</description></item><item><title>Apache Hive : Using TiDB as the Hive Metastore database</title><link>https://hive.apache.org/docs/latest/using-tidb-as-the-hive-metastore-database_158872426/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/using-tidb-as-the-hive-metastore-database_158872426/</guid><description>Apache Hive : Using TiDB as the Hive Metastore database Why use TiDB in Hive as the Metastore database? How to create a Hive cluster with TiDB Components required Install a Hive cluster Step 1: Deploy a TiDB cluster Step 2: Configure Hive Step 3: Initialize metadata Step 4: Launch Metastore and test Conclusion FAQ Why use TiDB in Hive as the Metastore database?</description></item><item><title>Apache Hive : Vectorized Query Execution</title><link>https://hive.apache.org/docs/latest/vectorized-query-execution_34838326/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/vectorized-query-execution_34838326/</guid><description>Apache Hive : Vectorized Query Execution Introduction Using Vectorized Query Execution Enabling vectorized execution Supported data types and operations Seeing whether vectorization is used for a query Limitations Version Information Introduction Vectorized query execution is a Hive feature that greatly reduces the CPU usage for typical query operations like scans, filters, aggregates, and joins. A standard query execution system processes one row at a time. This involves long code paths and significant metadata interpretation in the inner loop of execution.</description></item><item><title>Apache Hive : ViewDev</title><link>https://hive.apache.org/docs/latest/viewdev_27362067/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/viewdev_27362067/</guid><description>Apache Hive : ViewDev Hive Views Hive Views Use Cases Scope Syntax Implementation Sketch Issues Stored View Definition Metastore Modeling Dependency Tracking Dependency Invalidation View Modification Fast Path Execution ORDER BY and LIMIT in view definition Underlying Partition Dependencies Metastore Upgrades Automatic ALTER TABLE Explicit ALTER TABLE Existing Row UPDATE Use Cases Views (http://issues.apache.org/jira/browse/HIVE-972) are a standard DBMS feature and their uses are well understood.</description></item><item><title>Apache Hive : WebHCat</title><link>https://hive.apache.org/docs/latest/webhcat_33299069/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat_33299069/</guid><description>Apache Hive : WebHCat This is the manual for WebHCat, previously known as Templeton. WebHCat is the REST API for HCatalog, a table and storage management layer for Hadoop.  Using WebHCat Installation Configuration Reference See the HCatalog Manual for general HCatalog documentation.
Navigation Links Next: Using WebHCat
General: HCatalog Manual – Hive Wiki Home – Hive Project Site</description></item><item><title>Apache Hive : WebHCat Configure</title><link>https://hive.apache.org/docs/latest/webhcat-configure_34015738/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-configure_34015738/</guid><description>Apache Hive : WebHCat Configure WebHCat Configuration WebHCat Configuration Configuration Files Configuration Variables Default Values Configuration Files The configuration for WebHCat (Templeton) merges the normal Hadoop configuration with the WebHCat-specific variables. Because WebHCat is designed to connect services that are not normally connected, the configuration is more complex than might be desirable.
The WebHCat-specific configuration is split into two layers:
webhcat-default.xml – All the configuration variables that WebHCat needs.</description></item><item><title>Apache Hive : WebHCat InstallWebHCat</title><link>https://hive.apache.org/docs/latest/webhcat-installwebhcat_34015585/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-installwebhcat_34015585/</guid><description>Apache Hive : WebHCat InstallWebHCat WebHCat Installation WebHCat Installation WebHCat Installed with Hive WebHCat Installation Procedure Server Commands Requirements Hadoop Distributed Cache Permissions Secure Cluster Proxy User Support WebHCat Installed with Hive Version
WebHCat and HCatalog are installed with Hive, starting with Hive release 0.11.0.
If you install Hive from the binary tarball, the WebHCat server command webhcat_server.sh is in the hcatalog/sbin directory.
Hive installation is documented here.</description></item><item><title>Apache Hive : WebHCat Reference</title><link>https://hive.apache.org/docs/latest/webhcat-reference_34015762/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference_34015762/</guid><description>Apache Hive : WebHCat Reference Reference: WebHCat Resources This overview page lists all of the WebHCat resources. (DDL resources are listed here and on another overview page. For information about HCatalog DDL commands, see HCatalog DDL. For information about Hive DDL commands, see Hive Data Definition Language.)
  Category Resource (Type) Description General :version (GET) Return a list of supported response types.   status (GET) Return the WebHCat server status.</description></item><item><title>Apache Hive : WebHCat Reference AllDDL</title><link>https://hive.apache.org/docs/latest/webhcat-reference-allddl_34016001/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-allddl_34016001/</guid><description>Apache Hive : WebHCat Reference AllDDL WebHCat Reference: DDL Resources This is an overview page for the WebHCat DDL resources. The full list of WebHCat resources is on this overview page.
For information about HCatalog DDL commands, see HCatalog DDL. For information about Hive DDL commands, see Hive Data Definition Language. Object Resource (Type) Description DDL Command ddl (POST) Perform an HCatalog DDL command.</description></item><item><title>Apache Hive : WebHCat Reference DDL</title><link>https://hive.apache.org/docs/latest/webhcat-reference-ddl_34015990/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-ddl_34015990/</guid><description>Apache Hive : WebHCat Reference DDL DDL Command — POST ddl DDL Command — POST ddl Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description Performs an HCatalog DDL command. The command is executed immediately upon request. Responses are limited to 1 MB. For requests which may return longer results consider using the Hive resource as an alternative.</description></item><item><title>Apache Hive : WebHCat Reference DeleteDB</title><link>https://hive.apache.org/docs/latest/webhcat-reference-deletedb_34016281/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-deletedb_34016281/</guid><description>Apache Hive : WebHCat Reference DeleteDB Delete Database — DELETE ddl/database/:db Delete Database — DELETE ddl/database/:db Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description Delete a database.
URL http://www.myserver.com/templeton/v1/ddl/database/:db
Parameters Name Description Required? Default :db The database name Required None ifExists Hive returns an error if the database specified does not exist, unless ifExists is set to true.</description></item><item><title>Apache Hive : WebHCat Reference DeleteJob</title><link>https://hive.apache.org/docs/latest/webhcat-reference-deletejob_34017204/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-deletejob_34017204/</guid><description>Apache Hive : WebHCat Reference DeleteJob Delete Job — DELETE queue/:jobid Delete Job — DELETE queue/:jobid Description URL Parameters Results Example Curl Command JSON Output Description Kill a job given its job ID. Substitute &amp;ldquo;:jobid&amp;rdquo; with the job ID received when the job was created.
Version: Deprecated in 0.12.0
DELETE queue/:jobid is deprecated starting in Hive release 0.12.0. Users are encouraged to use DELETE jobs/:jobid instead.</description></item><item><title>Apache Hive : WebHCat Reference DeleteJobID</title><link>https://hive.apache.org/docs/latest/webhcat-reference-deletejobid_34835045/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-deletejobid_34835045/</guid><description>Apache Hive : WebHCat Reference DeleteJobID Delete Job — DELETE jobs/:jobid Delete Job — DELETE jobs/:jobid Description URL Parameters Results Example Curl Command JSON Output Description Kill a job given its job ID. Substitute &amp;ldquo;:jobid&amp;rdquo; with the job ID received when the job was created.
Version: Hive 0.12.0 and later
DELETE jobs/:jobid is introduced in Hive release 0.12.0. It is equivalent to [DELETE queue/:jobid](https://hive.</description></item><item><title>Apache Hive : WebHCat Reference DeletePartition</title><link>https://hive.apache.org/docs/latest/webhcat-reference-deletepartition_34016611/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-deletepartition_34016611/</guid><description>Apache Hive : WebHCat Reference DeletePartition Delete Partition — DELETE ddl/database/:db/table/:table/partition/:partition Delete Partition — DELETE ddl/database/:db/table/:table/partition/:partition Description URL Parameters Results Example Curl Command JSON Output Description Delete (drop) a partition in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/partition/:partition
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :partition The partition name, col_name=&amp;lsquo;value&amp;rsquo; list.</description></item><item><title>Apache Hive : WebHCat Reference DeleteTable</title><link>https://hive.apache.org/docs/latest/webhcat-reference-deletetable_34016561/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-deletetable_34016561/</guid><description>Apache Hive : WebHCat Reference DeleteTable Delete Table — DELETE ddl/database/:db/table/:table Delete Table — DELETE ddl/database/:db/table/:table Description URL Parameters Results Example Curl Command JSON Output Description Delete (drop) an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None ifExists Hive 0.</description></item><item><title>Apache Hive : WebHCat Reference GetColumn</title><link>https://hive.apache.org/docs/latest/webhcat-reference-getcolumn_34016979/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-getcolumn_34016979/</guid><description>Apache Hive : WebHCat Reference GetColumn Describe Column — GET ddl/database/:db/table/:table/column/:column Describe Column — GET ddl/database/:db/table/:table/column/:column Description URL Parameters Results Example Curl Command JSON Output Description Describe a single column in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/column/:column
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :column The column name Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetColumns</title><link>https://hive.apache.org/docs/latest/webhcat-reference-getcolumns_34016970/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-getcolumns_34016970/</guid><description>Apache Hive : WebHCat Reference GetColumns List Columns — GET ddl/database/:db/table/:table/column List Columns — GET ddl/database/:db/table/:table/column Description URL Parameters Results Example Curl Command JSON Output Description List the columns in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/column
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetDB</title><link>https://hive.apache.org/docs/latest/webhcat-reference-getdb_34016250/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-getdb_34016250/</guid><description>Apache Hive : WebHCat Reference GetDB Describe Database — GET ddl/database/:db Describe Database — GET ddl/database/:db Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description Describe a database. (Note: This resource has a &amp;ldquo;format=extended&amp;rdquo; parameter however the output structure does not change if it is used.)
URL http://www.myserver.com/templeton/v1/ddl/database/:db
Parameters Name Description Required? Default :db The database name Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetDBs</title><link>https://hive.apache.org/docs/latest/webhcat-reference-getdbs_34016238/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-getdbs_34016238/</guid><description>Apache Hive : WebHCat Reference GetDBs List Databases — GET ddl/database List Databases — GET ddl/database Description URL Parameters Results Example Curl Command JSON Output Description List the databases in HCatalog.
URL http://www.myserver.com/templeton/v1/ddl/database
Parameters Name Description Required? Default like List only databases whose names match the specified pattern. Optional &amp;ldquo;*&amp;rdquo; (List all) The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetPartition</title><link>https://hive.apache.org/docs/latest/webhcat-reference-getpartition_34016592/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-getpartition_34016592/</guid><description>Apache Hive : WebHCat Reference GetPartition Describe Partition — GET ddl/database/:db/table/:table/partition/:partition Describe Partition — GET ddl/database/:db/table/:table/partition/:partition Description URL Parameters Results Example Curl Command JSON Output Description Describe a single partition in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/partition/:partition
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :partition The partition name, col_name=&amp;lsquo;value&amp;rsquo; list.</description></item><item><title>Apache Hive : WebHCat Reference GetPartitions</title><link>https://hive.apache.org/docs/latest/webhcat-reference-getpartitions_34016583/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-getpartitions_34016583/</guid><description>Apache Hive : WebHCat Reference GetPartitions List Partitions — GET ddl/database/:db/table/:table/partition List Partitions — GET ddl/database/:db/table/:table/partition Description URL Parameters Results Example Curl Command JSON Output Description List all the partitions in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/partition
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetProperties</title><link>https://hive.apache.org/docs/latest/webhcat-reference-getproperties_34016995/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-getproperties_34016995/</guid><description>Apache Hive : WebHCat Reference GetProperties List Properties — GET ddl/database/:db/table/:table/property List Properties — GET ddl/database/:db/table/:table/property Description URL Parameters Results Example Curl Command JSON Output Description List all the properties of an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/property
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetProperty</title><link>https://hive.apache.org/docs/latest/webhcat-reference-getproperty_34017004/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-getproperty_34017004/</guid><description>Apache Hive : WebHCat Reference GetProperty Property Value — GET ddl/database/:db/table/:table/property/:property Property Value — GET ddl/database/:db/table/:table/property/:property Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description Return the value of a single table property.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/property/:property
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :property The property name Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetTable</title><link>https://hive.apache.org/docs/latest/webhcat-reference-gettable_34016519/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-gettable_34016519/</guid><description>Apache Hive : WebHCat Reference GetTable Describe Table — GET ddl/database/:db/table/:table Describe Table — GET ddl/database/:db/table/:table Description URL Parameters Results Example Curl Command (simple) JSON Output (simple) Curl Command (extended) JSON Output (extended) JSON Output (error) Description Describe an HCatalog table. Normally returns a simple list of columns (using &amp;ldquo;desc table&amp;rdquo;), but the extended format will show more information (using &amp;ldquo;show table extended like&amp;rdquo;).</description></item><item><title>Apache Hive : WebHCat Reference GetTables</title><link>https://hive.apache.org/docs/latest/webhcat-reference-gettables_34016290/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-gettables_34016290/</guid><description>Apache Hive : WebHCat Reference GetTables List Tables — GET ddl/database/:db/table List Tables — GET ddl/database/:db/table Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description List the tables in an HCatalog database.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table
Parameters Name Description Required? Default :db The database name Required None like List only tables whose names match the specified pattern Optional &amp;ldquo;*&amp;rdquo; (List all tables) The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference Hive</title><link>https://hive.apache.org/docs/latest/webhcat-reference-hive_34017180/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-hive_34017180/</guid><description>Apache Hive : WebHCat Reference Hive Hive Job — POST hive Hive Job — POST hive Description URL Parameters Results Example Curl Command JSON Output Example Results Description Runs a Hive query or set of commands.
Version: Hive 0.13.0 and later
As of Hive 0.13.0, GET version/hive displays the Hive version used for the query or commands.
URL http://www.myserver.com/templeton/v1/hive
Parameters Name Description Required?</description></item><item><title>Apache Hive : WebHCat Reference Job</title><link>https://hive.apache.org/docs/latest/webhcat-reference-job_34835065/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-job_34835065/</guid><description>Apache Hive : WebHCat Reference Job Job Information — GET jobs/:jobid Job Information — GET jobs/:jobid Description URL Parameters Results Example Curl Command JSON Output Description Check the status of a job and get related job information given its job ID. Substitute &amp;ldquo;:jobid&amp;rdquo; with the job ID received when the job was created.
Version: Hive 0.12.0 and later
GET jobs/:jobid is introduced in Hive release 0.</description></item><item><title>Apache Hive : WebHCat Reference JobIDs</title><link>https://hive.apache.org/docs/latest/webhcat-reference-jobids_34017187/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-jobids_34017187/</guid><description>Apache Hive : WebHCat Reference JobIDs List JobIDs — GET queue List JobIDs — GET queue Description URL Parameters Results Example Curl Command JSON Output Description Return a list of all job IDs.
Version: Deprecated in 0.12.0
GET queue is deprecated starting in Hive release 0.12.0. (See HIVE-4443.) Users are encouraged to use [GET jobs](https://hive.apache.org/docs/latest/webhcat-reference-jobs_34835057/) instead.
Version: Obsolete in 0.14.0
GET queue will be removed in Hive release 0.</description></item><item><title>Apache Hive : WebHCat Reference JobInfo</title><link>https://hive.apache.org/docs/latest/webhcat-reference-jobinfo_34017194/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-jobinfo_34017194/</guid><description>Apache Hive : WebHCat Reference JobInfo Job Information — GET queue/:jobid Job Information — GET queue/:jobid Description URL Parameters Results Example Curl Command JSON Output JSON Output (Hive 0.12.0 and later) Description Check the status of a job and get related job information given its job ID. Substitute &amp;ldquo;:jobid&amp;rdquo; with the job ID received when the job was created.
Version: Deprecated in 0.</description></item><item><title>Apache Hive : WebHCat Reference Jobs</title><link>https://hive.apache.org/docs/latest/webhcat-reference-jobs_34835057/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-jobs_34835057/</guid><description>Apache Hive : WebHCat Reference Jobs List JobIDs — GET jobs List JobIDs — GET jobs Description URL Parameters Results Examples Curl Command JSON Output Curl Command (showall) JSON Output (showall) Curl Command (fields) JSON Output (fields) Description Return a list of all job IDs.
Version: Hive 0.12.0 and later
GET jobs is introduced in Hive release 0.12.0. It is equivalent to [GET queue](https://hive.</description></item><item><title>Apache Hive : WebHCat Reference MapReduceJar</title><link>https://hive.apache.org/docs/latest/webhcat-reference-mapreducejar_34017030/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-mapreducejar_34017030/</guid><description>Apache Hive : WebHCat Reference MapReduceJar MapReduce Job — POST mapreduce/jar MapReduce Job — POST mapreduce/jar Description URL Parameters Results Example Code and Data Setup Curl Command JSON Output Description Creates and queues a standard Hadoop MapReduce job.
Version: Hive 0.13.0 and later
As of Hive 0.13.0, GET version/hadoop displays the Hadoop version used for the MapReduce job.
URL http://www.myserver.com/templeton/v1/mapreduce/jar
Parameters Name Description Required?</description></item><item><title>Apache Hive : WebHCat Reference MapReduceStream</title><link>https://hive.apache.org/docs/latest/webhcat-reference-mapreducestream_34017023/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-mapreducestream_34017023/</guid><description>Apache Hive : WebHCat Reference MapReduceStream MapReduce Streaming Job — POST mapreduce/streaming MapReduce Streaming Job — POST mapreduce/streaming Description URL Parameters Results Example Code and Data Setup Curl Command JSON Output Example Results Description Create and queue a Hadoop streaming MapReduce job.
Version: Hive 0.13.0 and later
As of Hive 0.13.0, GET version/hadoop displays the Hadoop version used for the MapReduce job.</description></item><item><title>Apache Hive : WebHCat Reference Pig</title><link>https://hive.apache.org/docs/latest/webhcat-reference-pig_34017169/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-pig_34017169/</guid><description>Apache Hive : WebHCat Reference Pig Pig Job — POST pig Pig Job — POST pig Description URL Parameters Results Example Code and Data Setup Curl Command JSON Output Description Create and queue a Pig job.
URL http://www.myserver.com/templeton/v1/pig
Parameters Name Description Required? Default execute String containing an entire, short Pig program to run. One of either &amp;ldquo;execute&amp;rdquo; or &amp;ldquo;file&amp;rdquo; is required.</description></item><item><title>Apache Hive : WebHCat Reference PostTable</title><link>https://hive.apache.org/docs/latest/webhcat-reference-posttable_34016548/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-posttable_34016548/</guid><description>Apache Hive : WebHCat Reference PostTable Rename Table — POST ddl/database/:db/table/:table Rename Table — POST ddl/database/:db/table/:table Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description Rename an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table
Parameters Name Description Required? Default :db The database name Required None :table The existing (old) table name Required None rename The new table name Required None group The user group to use Optional None permissions The permissions string to use.</description></item><item><title>Apache Hive : WebHCat Reference PutColumn</title><link>https://hive.apache.org/docs/latest/webhcat-reference-putcolumn_34016987/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-putcolumn_34016987/</guid><description>Apache Hive : WebHCat Reference PutColumn Create Column — PUT ddl/database/:db/table/:table/column/:column Create Column — PUT ddl/database/:db/table/:table/column/:column Description URL Parameters Results Example Curl Command JSON Output Description Create a column in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/column/:column
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :column The column name Required None group The user group to use Optional None permissions The permissions string to use Optional None type The type of column to add, like &amp;ldquo;string&amp;rdquo; or &amp;ldquo;int&amp;rdquo; Required None comment The column comment, like a description Optional None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference PutDB</title><link>https://hive.apache.org/docs/latest/webhcat-reference-putdb_34016273/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-putdb_34016273/</guid><description>Apache Hive : WebHCat Reference PutDB Create Database — PUT ddl/database/:db Create Database — PUT ddl/database/:db Description URL Parameters Results Example Curl Command JSON Output Description Create a database.
URL http://www.myserver.com/templeton/v1/ddl/database/:db
Parameters Name Description Required? Default :db The database name Required None group The user group to use Optional None permissions The permissions string to use Optional None location The database location Optional None comment A comment for the database, like a description Optional None properties The database properties Optional None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference PutPartition</title><link>https://hive.apache.org/docs/latest/webhcat-reference-putpartition_34016600/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-putpartition_34016600/</guid><description>Apache Hive : WebHCat Reference PutPartition Create Partition — PUT ddl/database/:db/table/:table/partition/:partition Create Partition — PUT ddl/database/:db/table/:table/partition/:partition Description URL Parameters Results Example Curl Command JSON Output Description Create a partition in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/partition/:partition
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :partition The partition name, col_name=&amp;lsquo;value&amp;rsquo; list.</description></item><item><title>Apache Hive : WebHCat Reference PutProperty</title><link>https://hive.apache.org/docs/latest/webhcat-reference-putproperty_34017012/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-putproperty_34017012/</guid><description>Apache Hive : WebHCat Reference PutProperty Set Property — PUT ddl/database/:db/table/:table/property/:property Set Property — PUT ddl/database/:db/table/:table/property/:property Description URL Parameters Results Example Curl Command JSON Output Description Add a single property on an HCatalog table. This will also reset an existing property.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/property/:property
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :property The property name Required None group The user group to use Optional None permissions The permissions string to use Optional None value The property value Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference PutTable</title><link>https://hive.apache.org/docs/latest/webhcat-reference-puttable_34016540/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-puttable_34016540/</guid><description>Apache Hive : WebHCat Reference PutTable Create Table — PUT ddl/database/:db/table/:table Create Table — PUT ddl/database/:db/table/:table Description URL Parameters Results Example Curl Command Curl Command (using clusteredBy) JSON Output JSON Output (error) Description Create a new HCatalog table. For more information, please refer to the Hive documentation for CREATE TABLE.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table
Parameters Name Description Required? Default :db The database name.</description></item><item><title>Apache Hive : WebHCat Reference PutTableLike</title><link>https://hive.apache.org/docs/latest/webhcat-reference-puttablelike_34016572/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-puttablelike_34016572/</guid><description>Apache Hive : WebHCat Reference PutTableLike Create Table Like — PUT ddl/database/:db/table/:existingtable/like/:newtable Create Table Like — PUT ddl/database/:db/table/:existingtable/like/:newtable Description URL Parameters Results Example Curl Command JSON Output Description Create a new HCatalog table like an existing one.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:existingtable/like/:newtable
Parameters Name Description Required? Default :db The database name Required None :existingtable The existing table name Required None :newtable The new table name Required None group The user group to use when creating a table Optional None permissions The permissions string to use when creating a table Optional None external Allows you to specify a location so that Hive does not use the default location for this table.</description></item><item><title>Apache Hive : WebHCat Reference ResponseTypes</title><link>https://hive.apache.org/docs/latest/webhcat-reference-responsetypes_34015937/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-responsetypes_34015937/</guid><description>Apache Hive : WebHCat Reference ResponseTypes Response Types — GET :version Response Types — GET :version Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description Returns a list of the response types supported by WebHCat (Templeton).
URL http://www.myserver.com/templeton/:version
Parameters Name Description Required? Default :version The WebHCat version number. (Currently this must be &amp;ldquo;v1&amp;rdquo;.</description></item><item><title>Apache Hive : WebHCat Reference Status</title><link>https://hive.apache.org/docs/latest/webhcat-reference-status_34015941/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-status_34015941/</guid><description>Apache Hive : WebHCat Reference Status Current Status — GET status Current Status — GET status Description URL Parameters Results Example Curl Command JSON Output Description Returns the current status of the WebHCat (Templeton) server. Useful for heartbeat monitoring.
URL http://www.myserver.com/templeton/v1/status
Parameters Only the standard parameters are accepted.
Results Name Description status &amp;ldquo;ok&amp;rdquo; if the WebHCat server was contacted.</description></item><item><title>Apache Hive : WebHCat Reference Version</title><link>https://hive.apache.org/docs/latest/webhcat-reference-version_34015986/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-version_34015986/</guid><description>Apache Hive : WebHCat Reference Version List Versions — GET version List Versions — GET version Description URL Parameters Results Example Curl Command JSON Output Description Returns a list of supported versions and the current version.
URL http://www.myserver.com/templeton/v1/version
Parameters Only the standard parameters are accepted.
Results Name Description supportedVersions A list of all supported versions. version The current version.</description></item><item><title>Apache Hive : WebHCat Reference VersionHadoop</title><link>https://hive.apache.org/docs/latest/webhcat-reference-versionhadoop_44303410/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-versionhadoop_44303410/</guid><description>Apache Hive : WebHCat Reference VersionHadoop Hadoop Version — GET version/hadoop Hadoop Version — GET version/hadoop Description URL Parameters Results Example Curl Command JSON Output Description Return the version of Hadoop being run when WebHCat creates a MapReduce job (POST mapreduce/jar or mapreduce/streaming).
Version: Hive 0.13.0 and later
GET version/hadoop is introduced in Hive release 0.13.0 (HIVE-6226).
URL http://www.myserver.com/templeton/v1/version/hadoop
Parameters Only the standard parameters are accepted.</description></item><item><title>Apache Hive : WebHCat Reference VersionHive</title><link>https://hive.apache.org/docs/latest/webhcat-reference-versionhive_44303406/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-reference-versionhive_44303406/</guid><description>Apache Hive : WebHCat Reference VersionHive Hive Version — GET version/hive Hive Version — GET version/hive Description URL Parameters Results Example Curl Command JSON Output Description Return the version of Hive being run when WebHCat issues Hive queries or commands (POST hive).
Version: Hive 0.13.0 and later
GET version/hive is introduced in Hive release 0.13.0 (HIVE-6226).
URL http://www.myserver.com/templeton/v1/version/hive
Parameters Only the standard parameters are accepted.</description></item><item><title>Apache Hive : WebHCat UsingWebHCat</title><link>https://hive.apache.org/docs/latest/webhcat-usingwebhcat_34015492/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat-usingwebhcat_34015492/</guid><description>Apache Hive : WebHCat UsingWebHCat Using the HCatalog REST API (WebHCat) Using the HCatalog REST API (WebHCat) Introduction to WebHCat URL Format Security Standard Parameters Specifying user.name Security Error Response WebHDFS and Code Push Error Codes and Responses Log Files Project Name Version information
The HCatalog project graduated from the Apache incubator and merged with the Hive project on March 26, 2013.</description></item><item><title/><link>https://hive.apache.org/docs/latest/capture-lineage-info/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/capture-lineage-info/</guid><description>Capture Lineage Information In Hive Hooks Background In Hive, lineage information is captured in the form of LineageInfo object. This object is created in the SemanticAnalyzer and is passed to the HookContext object. Users can use the following existing Hooks or implement their own custom hooks to capture this information and utilize it.
Existing Hooks org.apache.hadoop.hive.ql.hooks.PostExecutePrinter org.apache.hadoop.hive.ql.hooks.LineageLogger org.apache.atlas.hive.hook.HiveHook To facilitate the capture of lineage information in a custom hook or in a use case where the existing hooks are not set in hive.</description></item></channel></rss>