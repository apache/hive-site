<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Apache Hive on Hive Site</title><link>https://hive.apache.org/</link><description>Recent content in Apache Hive on Hive Site</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 27 Jan 2023 19:16:15 +0530</lastBuildDate><atom:link href="https://hive.apache.org/index.xml" rel="self" type="application/rss+xml"/><item><title>Apache Hive : Write Ordering</title><link>https://hive.apache.org/docs/latest/language/writeordering/</link><pubDate>Fri, 31 Oct 2025 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/writeordering/</guid><description>Apache Hive : Write Ordering Overview Write ordering controls the physical layout of data within table files. Unlike SORT BY which orders data during query execution, write ordering is applied at write time and persists in the stored files.
Write ordering is supported for Iceberg tables and can be specified during table creation.
Hive supports two write ordering strategies:
Type-Native Ordering: Sort by one or more columns in a specified order Z-Ordering: Multi-dimensional clustering using space-filling curves Type-Native Column Ordering Version Introduced in Hive version 4.</description></item><item><title>Hive 4.2.0 - REST Catalog Integration</title><link>https://hive.apache.org/docs/latest/quickstart-rest-catalog/</link><pubDate>Fri, 31 Oct 2025 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/quickstart-rest-catalog/</guid><description>REST Catalog Integration Table of Contents Hive + Gravitino + Keycloak Architecture Overview Prerequisites Quickstart Configuration Keyclock Gravitino Hive Networking Notes Hive + Polaris Architecture Overview Prerequisites Quickstart Configuration Polaris Hive Networking Notes Hive + Gravitino + Keycloak The code for this setup is located in the Hive repository in packaging/src/docker/thirdparties/gravitino folder. It contains a docker-compose-based setup integrating Apache Hive, Gravitino Iceberg REST server, and Keycloak for OAuth2 authentication.</description></item><item><title>Apache Hive : Hive Schema Tool</title><link>https://hive.apache.org/docs/latest/admin/hive-schema-tool/</link><pubDate>Tue, 14 Oct 2025 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/hive-schema-tool/</guid><description>Apache Hive : Hive Schema Tool Apache Hive : Hive Schema Tool About Metastore Schema Verification The Hive Schema Tool The schematool Command Usage Examples About Schema tool helps to initialise and upgrade metastore database and hive sys schema.
Metastore Schema Verification Introduced in Hive 0.12.0. See HIVE-3764.
Hive records the schema version in the metastore database and verifies that the metastore schema version is compatible with Hive binaries that are going to access the metastore.</description></item><item><title>Apache Hive : Setting Up OAuth 2 with Keycloak</title><link>https://hive.apache.org/docs/latest/admin/oauth2/keycloak/</link><pubDate>Tue, 30 Sep 2025 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/oauth2/keycloak/</guid><description>Apache Hive : Setting Up OAuth 2 with Keycloak Keycloak Settings 1. Register Hive Metastore as a Resource Server Browse Manage -&amp;gt; Clients -&amp;gt; Create client, and create a client for HMS, as an OAuth 2 resource server. This example useshive-metastore as a client ID. You can access the client secret in the Credentials tab.
2. Define the &amp;ldquo;catalog&amp;rdquo; scope Iceberg REST Catalog uses &amp;ldquo;catalog&amp;rdquo; as the default scope name.</description></item><item><title>Capture Lineage Information In Hive Hooks</title><link>https://hive.apache.org/docs/latest/user/capture-lineage-info/</link><pubDate>Tue, 29 Jul 2025 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/capture-lineage-info/</guid><description>Background In Hive, lineage information is captured in the form of LineageInfo object. This object is created in the SemanticAnalyzer and is passed to the HookContext object. Users can use the following existing Hooks or implement their own custom hooks to capture this information and utilize it.
Existing Hooks org.apache.hadoop.hive.ql.hooks.PostExecutePrinter org.apache.hadoop.hive.ql.hooks.LineageLogger org.apache.atlas.hive.hook.HiveHook To facilitate the capture of lineage information in a custom hook or in a use case where the existing hooks are not set in hive.</description></item><item><title>Query File Test(qtest)</title><link>https://hive.apache.org/development/qtest/</link><pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/qtest/</guid><description>Query File Test(qtest) Query File Test is a JUnit-based integration test suite for Apache Hive. Developers write any SQL; the testing framework runs it and verifies the result and output.
Query File Test(qtest) Tutorial: How to run a specific test case Preparation Run a test case Tutorial: How to add a new test case Add a QFile Generate a result file Verify the new result file Commandline options Test options Test Iceberg, Accumulo, or Kudu QTestOptionHandler: pre/post-processor Using test data Mask non-deterministic outputs Advanced Locations of log files Negative tests How to specify drivers How to use PostgreSQL/MySQL/Oracle as a backend database for Hive Metastore Remote debug Tips for Adding New Tests in Hive Tutorial: How to run a specific test case Preparation You have to compile Hive&amp;rsquo;s source codes ahead of time.</description></item><item><title>Apache Hive : AccessServer Design Proposal</title><link>https://hive.apache.org/development/desingdocs/accessserver-design-proposal/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/accessserver-design-proposal/</guid><description>Apache Hive : AccessServer Design Proposal AccessServer Proposal Author: Carl Steinbach Overview The technical approach described in the this document addresses the following high-level requirements:
Make Apache Hive’s data model and metadata services accessible to users of the Apache Pig dataflow programming language as well as other Hadoop language runtimes. Make it possible for Hive users and users of other Hadoop language runtimes to share data stored in Hive’s HDFS data warehouse.</description></item><item><title>Apache Hive : AccumuloIntegration</title><link>https://hive.apache.org/docs/latest/user/accumulointegration/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/accumulointegration/</guid><description>Apache Hive : Accumulo Integration Apache Hive : Accumulo Integration Overview Implementation Accumulo Configuration Usage Column Mapping Indexing Other options Examples Override the Accumulo table name Store a Hive map with binary serialization Register an external table Create an indexed table Acknowledgements Overview Apache Accumulo is a sorted, distributed key-value store based on the Google BigTable paper. The API methods that Accumulo provides are in terms of Keys and Values which present the highest level of flexibility in reading and writing data; however, higher-level query abstractions are typically an exercise left to the user.</description></item><item><title>Apache Hive : AdminManual</title><link>https://hive.apache.org/docs/latest/admin/adminmanual/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/adminmanual/</guid><description>Apache Hive : AdminManual Hive Administrator&amp;rsquo;s Manual Installing Hive Configuring Hive Setting up Metastore Setting up Hive Server (JDBC, ODBC, Thrift, etc) Hive on Amazon Web Services</description></item><item><title>Apache Hive : AdminManual Configuration</title><link>https://hive.apache.org/docs/latest/admin/adminmanual-configuration/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/adminmanual-configuration/</guid><description>Apache Hive : AdminManual Configuration Apache Hive : AdminManual Configuration Configuring Hive hive-site.xml and hive-default.xml.template Temporary Folders Log Files Derby Server Mode Configuration Variables Removing Hive Metastore Password from Hive Configuration Configuring HCatalog and WebHCat HCatalog WebHCat Configuring Hive A number of configuration variables in Hive can be used by the administrator to change the behavior for their installations and user sessions.</description></item><item><title>Apache Hive : AdminManual Installation</title><link>https://hive.apache.org/docs/latest/admin/adminmanual-installation/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/adminmanual-installation/</guid><description>Apache Hive : AdminManual Installation Apache Hive : AdminManual Installation Installing Hive Installing from a Tarball Installing from Source Code (Hive 1.2.0 and Later) Installing from Source Code (Hive 0.13.0 and Later) Installing from Source Code (Hive 0.12.0 and Earlier) Next Steps Hive CLI and Beeline CLI Hive Metastore HCatalog and WebHCat HCatalog WebHCat (Templeton) Installing Hive You can install a stable release of Hive by downloading and unpacking a tarball, or you can download the source code and build Hive using Maven (release 0.</description></item><item><title>Apache Hive : AdminManual Metastore 3.0 Administration</title><link>https://hive.apache.org/docs/latest/admin/adminmanual-metastore-3-0-administration/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/adminmanual-metastore-3-0-administration/</guid><description>Apache Hive : AdminManual Metastore 3.0 Administration Apache Hive : AdminManual Metastore 3.0 Administration Version Note Introduction Changes From Hive 2 to Hive 3 General Configuration RDBMS Option 1: Embedding Derby Option 2: External RDBMS Installing and Upgrading the Metastore Schema Running the Metastore Embedded Mode Metastore Server Running the Metastore Without Hive Performance Optimizations CachedStore Less Commonly Changed Configuration Parameters Version Note This document applies only to the Metastore in Hive 3.</description></item><item><title>Apache Hive : AdminManual Metastore Administration</title><link>https://hive.apache.org/docs/latest/admin/adminmanual-metastore-administration/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/adminmanual-metastore-administration/</guid><description>Apache Hive : AdminManual Metastore Administration This page only documents the MetaStore in Hive 2.x and earlier. For 3.x and later releases please see AdminManual Metastore 3.0 Administration
Apache Hive : AdminManual Metastore Administration Introduction Local/Embedded Metastore Database (Derby) Remote Metastore Database Local/Embedded Metastore Server Remote Metastore Server Supported Backend Databases for Metastore Metastore Schema Consistency and Upgrades Introduction All the metadata for Hive tables and partitions are accessed through the Hive Metastore.</description></item><item><title>Apache Hive : AdminManual SettingUpHiveServer</title><link>https://hive.apache.org/docs/latest/admin/adminmanual-settinguphiveserver/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/adminmanual-settinguphiveserver/</guid><description>Apache Hive : AdminManual SettingUpHiveServer Setting Up Hive Server Setting Up HiveServer2 Setting Up Thrift Hive Server Setting Up Hive JDBC Server Setting Up Hive ODBC Server</description></item><item><title>Apache Hive : Apache Hive SQL Conformance</title><link>https://hive.apache.org/docs/latest/language/apache-hive-sql-conformance/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/apache-hive-sql-conformance/</guid><description>Apache Hive : Apache Hive SQL Conformance This page documents which parts of the SQL standard are supported by Apache Hive. The information here is not a full statement of conformance but provides users detail sufficient to generally understand Hive&amp;rsquo;s SQL conformance.
This information is versioned by Hive release version, allowing a user to quickly identify features available to them.
The formal name of the current SQL standard is ISO/IEC 9075 &amp;ldquo;Database Language SQL&amp;rdquo;.</description></item><item><title>Apache Hive : AuthDev</title><link>https://hive.apache.org/docs/latest/user/authdev/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/authdev/</guid><description>Apache Hive : AuthDev This is the design document for the original Hive authorization mode. See Authorization for an overview of authorization modes, which include storage based authorization and SQL standards based authorization.
Apache Hive : AuthDev 1. Privilege 1.1 Access Privilege 2. Hive Operations 3. Metadata 3.1 user, group, and roles 3.1.1 Role management 3.1.2 role metadata 3.1.3 hive role user membership table 3.</description></item><item><title>Apache Hive : AvroSerDe</title><link>https://hive.apache.org/docs/latest/user/avroserde/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/avroserde/</guid><description>Apache Hive : AvroSerDe Apache Hive : AvroSerDe Availability Overview – Working with Avro from Hive Requirements Avro to Hive type conversion Creating Avro-backed Hive tables Writing tables to Avro files Specifying the Avro schema for a table HBase Integration If something goes wrong FAQ Availability Earliest version AvroSerde is available
The AvroSerde is available in Hive 0.9.1 and greater.</description></item><item><title>Apache Hive : BecomingACommitter</title><link>https://hive.apache.org/community/becomingcommitter/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/becomingcommitter/</guid><description>Apache Hive : BecomingACommitter Becoming A Hive Committer The Apache Software Foundation defines generic guidelines for what it means to be a committer. However, it leaves the question of whether a particular contributor is ready to become a committer on a project up to the judgement of that project&amp;rsquo;s PMC. This wiki page attempts to explain what that means for the Hive project.
Committer Zen Contributors often ask Hive PMC members the question, &amp;ldquo;What do I need to do in order to become a committer?</description></item><item><title>Apache Hive : Binary DataType Proposal</title><link>https://hive.apache.org/development/desingdocs/binary-datatype-proposal/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/binary-datatype-proposal/</guid><description>Apache Hive : Binary DataType Proposal Binary Type in Hive Motivation: Hive is designed to work with big data. Often in such cases, a row in a data might be very wide with hundreds of columns. Sometimes, user is just interested in few of those columns and doesn&amp;rsquo;t want to bother about exact type information for rest of columns. In such cases, he may just declare the types of those columns as binary and Hive will not try to interpret those columns.</description></item><item><title>Apache Hive : Books about Hive</title><link>https://hive.apache.org/community/resources/books-about-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/books-about-hive/</guid><description>Apache Hive : Books about Hive These books describe Apache Hive and explain how to use its features. If you know of others that should be listed here, or newer editions, please send a message to the Hive user mailing list or add the information yourself if you have wiki edit privileges. Most links go to the publishers although you can also buy most of these books from bookstores, either online or brick-and-mortar.</description></item><item><title>Apache Hive : Books, Blogs &amp; Talks</title><link>https://hive.apache.org/community/resources/books-blogs-talks/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/books-blogs-talks/</guid><description>Apache Hive : Books, Blogs &amp;amp; Talks Books: Programming Hive by Edward Capriolo, Dean Wampler, and Jason Rutherglen – O&amp;rsquo;Reilly Media, 2012 Apache Hive Essentials by Dayong Du – Packt Publishing, 2015 and 2018 (second edition) Apache Hive Cookbook by Hanish Bansal, Saurabh Chauhan, and Shrey Mehrotra – Packt Publishing, 2016 Instant Apache Hive Essentials How-to by Darren Lee – Packt Publishing, 2013 Practical Hive by Scott Shaw, Andreas François Vermeulen, Ankur Gupta, and David Kjerrumgaard – Apress, 2016 The Ultimate Guide to Programming Apache Hive by Fru Nde – NextGen Publishing, 2015 Learn Hive in 1 Day by Krishna Rungta – independently published, 2017 Books primarily about Hadoop, with some coverage of Hive:</description></item><item><title>Apache Hive : Building Hive from Source</title><link>https://hive.apache.org/community/resources/building-hive-from-source/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/building-hive-from-source/</guid><description>Apache Hive : Building Hive from Source Fetching the source code Using the source tar: Download the source tar from [TODO: Put link post release] and untar From Git tag: Checkout the release tag using git clone &amp;ndash;branch rel/release-4.0.0 https://github.com/apache/hive.git Building Distribution Run: mvn clean install -DskipTests -Pdist -Piceberg -Pitests Find the built tar under packaging/target/apache-hive-* Running Unit Tests Run: mvn clean install -Piceberg Running Integration Tests GoTo itests directory Run: mvn clean test -pl itest -Piceberg</description></item><item><title>Apache Hive : Bylaws</title><link>https://hive.apache.org/community/bylaws/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/bylaws/</guid><description>Apache Hive : Bylaws This document defines the bylaws under which the Apache Hive project operates. It defines the roles and responsibilities of the project, who may vote, how voting works, how conflicts are resolved, etc.
Hive is a project of the Apache Software Foundation. The foundation holds the copyright on Apache code including the code in the Hive codebase. The foundation FAQ explains the operation and background of the foundation.</description></item><item><title>Apache Hive : CAST...FORMAT with SQL:2016 datetime formats</title><link>https://hive.apache.org/docs/latest/language/cast-format-with-sql2016-datetime-formats/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/cast-format-with-sql2016-datetime-formats/</guid><description>Apache Hive : CAST&amp;hellip;FORMAT with SQL:2016 datetime formats Usage CAST(&amp;lt;timestamp/date&amp;gt; AS &amp;lt;varchar/char/string&amp;gt; [FORMAT &amp;lt;template&amp;gt;]) CAST(&amp;lt;varchar/char/string&amp;gt; AS &amp;lt;timestamp/date&amp;gt; [FORMAT &amp;lt;template&amp;gt;]) Example select cast(dt as string format 'DD-MM-YYYY') select cast('01-05-2017' as date format 'DD-MM-YYYY') Template elements, a.k.a. Tokens, a.k.a Patterns a.k.a SQL:2016 Datetime Formats Notes For all tokens:
Patterns are case-insensitive, except AM/PM and T/Z. See these sections for more details. For string to datetime conversion, no duplicate format tokens are allowed, including tokens</description></item><item><title>Apache Hive : ChangeLog</title><link>https://hive.apache.org/docs/latest/changelog/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/changelog/</guid><description>Apache Hive : ChangeLog Release 4.0.0 - 2024-03-29 NEW FEATURES: JIRA Summary Priority Component Reporter Contributor HIVE-27850 Iceberg: Major QB Compaction Major Iceberg integration Dmitriy Fingerman Dmitriy Fingerman HIVE-26222 Native GeoSpatial Support in Hive Major Hive, HiveServer2 mahesh kumar behera Ayush Saxena HIVE-27980 Hive Iceberg Compaction: add support for OPTIMIZE TABLE syntax Major . Dmitriy Fingerman Dmitriy Fingerman HIVE-26435 Add method for collecting HMS meta summary Major .</description></item><item><title>Apache Hive : Column Statistics in Hive</title><link>https://hive.apache.org/development/desingdocs/column-statistics-in-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/column-statistics-in-hive/</guid><description>Apache Hive : Column Statistics in Hive Apache Hive : Column Statistics in Hive Introduction HiveQL changes Metastore Schema Metastore Thrift API Introduction This document describes changes to a) HiveQL, b) metastore schema, and c) metastore Thrift API to support column level statistics in Hive. Please note that the document doesn’t describe the changes needed to persist histograms in the metastore yet.</description></item><item><title>Apache Hive : Common Table Expression</title><link>https://hive.apache.org/docs/latest/language/common-table-expression/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/common-table-expression/</guid><description>Apache Hive : Common Table Expression A Common Table Expression (CTE) is a temporary result set derived from a simple query specified in a WITH clause, which immediately precedes a SELECT or INSERT keyword. The CTE is defined only within the execution scope of a single statement. One or more CTEs can be used in a Hive SELECT, INSERT, CREATE TABLE AS SELECT, or CREATE VIEW AS SELECT statement.
Version</description></item><item><title>Apache Hive : Compaction pooling</title><link>https://hive.apache.org/docs/latest/language/compaction-pooling/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/compaction-pooling/</guid><description>Apache Hive : Compaction pooling Concept: Compaction requests and workers can be assigned to pools. A worker assigned to a specific pool will only process compaction requests in that pool. Workers and compaction requests without pool assignment are implicitly belong to the default pool. The pooling concept allows fine tuning of processing compaction requests. For example it is possible to create a pool name &amp;lsquo;high priority compaction&amp;rsquo;, assign some frequently modified tables to it, and dedicate a set of workers to this pool.</description></item><item><title>Apache Hive : CompressedStorage</title><link>https://hive.apache.org/docs/latest/user/compressedstorage/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/compressedstorage/</guid><description>Apache Hive : CompressedStorage Compressed Data Storage Keeping data compressed in Hive tables has, in some cases, been known to give better performance than uncompressed storage; both in terms of disk usage and query performance.
You can import text files compressed with Gzip or Bzip2 directly into a table stored as TextFile. The compression will be detected automatically and the file will be decompressed on-the-fly during query execution. For example:</description></item><item><title>Apache Hive : Configuration Properties</title><link>https://hive.apache.org/docs/latest/user/configuration-properties/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/configuration-properties/</guid><description>Apache Hive : Configuration Properties This document describes the Hive user configuration properties (sometimes called parameters, variables, or options), and notes which releases introduced new properties.
The canonical list of configuration properties is managed in the HiveConf Java class, so refer to the HiveConf.java file for a complete list of configuration properties available in your Hive release.
For information about how to use these configuration properties, see Configuring Hive. That document also describes administrative configuration properties for setting up Hive in the Configuration Variables section.</description></item><item><title>Apache Hive : ContributorDay2011</title><link>https://hive.apache.org/community/meetings/contributorday2011/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/contributorday2011/</guid><description>Apache Hive : ContributorDay2011 Apache Hive Contributor Day is a special event hosted as part of Yahoo&amp;rsquo;s Hadoop Summit.
Resources for mini-hackathon:
PluginDeveloperKit has info on the new pdk; download this snapshot build of Hive which includes it you&amp;rsquo;ll need a Mac or Linux development environment with Hive+Hadoop already installed on it per these instructions; for Hive, use the snapshot you&amp;rsquo;ll also need Apache ant installed. HIVE-1545 has the UDF libraries we&amp;rsquo;d like to get cleaned up for inclusion in Hive or extension libraries (download core.</description></item><item><title>Apache Hive : ContributorMinutes20110907</title><link>https://hive.apache.org/community/meetings/contributorminutes20110907/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/contributorminutes20110907/</guid><description>Apache Hive : ContributorMinutes20110907 Notes from the Hive Meetup at Hortonworks, 9/7/11
Attendees: http://www.meetup.com/Hive-Contributors-Group/events/30620561/
The Binary type proposed by Ashutosh Chauhan, HIVE-2380 was discussed. There was agreement that a design document is needed to explain the proposed changes for this feature. The design document should cover:
Can columns of binary type be used as a key in group by or join? What native functions exist to manipulate binary types? How does casting between binary and other types work?</description></item><item><title>Apache Hive : ContributorMinutes20111205</title><link>https://hive.apache.org/community/meetings/contributorminutes20111205/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/contributorminutes20111205/</guid><description>Apache Hive : ContributorMinutes20111205 Notes from the Hive Meetup at Facebook, 12/5/11
Attendees: http://www.meetup.com/Hive-Contributors-Group/events/41150912/
John gave a demo of the Phabricator instance at http://reviews.facebook.net, and proposed that we push through moving all code review over from Review Board to Phabricator. There were no objections.
Marek gave an overview of the new parallel test framework (https://issues.apache.org/jira/browse/HIVE-1487); he&amp;rsquo;ll publish a wiki page explaining how to use it once it gets committed.
Carl gave an update on the 0.</description></item><item><title>Apache Hive : ContributorMinutes20120418</title><link>https://hive.apache.org/community/meetings/contributorminutes20120418/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/contributorminutes20120418/</guid><description>Apache Hive : ContributorMinutes20120418 Notes from the Hive Contributors Meetup at Cloudera, 4/18/12
Attendees: http://www.meetup.com/Hive-Contributors-Group/events/59148562/
Ashutosh gave a status update on the Hive 0.9.0 release work. RC0 was put up for a vote last week, but it turned out there were several problems. Ashutosh is in the process of fixing those issues, and is also trying to get several other patches resolved and backported before cutting RC1.
Carl asked for more details about the impact of HIVE-2795 on the upgrade process for 0.</description></item><item><title>Apache Hive : ContributorsMinutes110726</title><link>https://hive.apache.org/community/meetings/contributorsminutes110726/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/contributorsminutes110726/</guid><description>Apache Hive : ContributorsMinutes110726 Meeting date: July 26, 2011
Location: Cloudera (Palo Alto)
Attendees: http://www.meetup.com/Hive-Contributors-Group/events/26345541/
Carl proposed end of August as target for 0.8 release, with branch cut in a couple of weeks. Work is still underway for publishing release artifacts in Maven for 0.7.1 and 0.8 (development snapshots are already being published).
Ashutosh gave an update on HCatalog development status; no blocking issues from Hive for the 0.2 release; some ideas are being discussed for the 0.</description></item><item><title>Apache Hive : Correlation Optimizer</title><link>https://hive.apache.org/development/desingdocs/correlation-optimizer/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/correlation-optimizer/</guid><description>Apache Hive : Correlation Optimizer This page documents Correlation Optimizer. It was originally introduced by HIVE-2206 and based on the idea of YSmart [1]. To turn on this optimizer, you can use &amp;hellip;
set hive.optimize.correlation=true; 1. Overview In Hadoop environments, an SQL query submitted to Hive will be evaluated in distributed systems. Thus, after generating a query operator tree representing the submitted SQL query, Hive needs to determine what operations can be executed in a task which will be evalauted in a single node.</description></item><item><title>Apache Hive : Cost-based optimization in Hive</title><link>https://hive.apache.org/docs/latest/user/cost-based-optimization-in-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/cost-based-optimization-in-hive/</guid><description>Apache Hive : Cost-based optimization in Hive Apache Hive : Cost-based optimization in Hive Abstract 1. INTRODUCTION 2. RELATED WORK STATS PAPERS 3. BACKGROUND Hive Query optimization issues TEZ Join algorithms in Hive Multi way Join Common Join Map Join Bucket Map Join SMB Join Skew Join 4. Implementation details Phase 1 Phase 2 Phase 3 Configuration Proposed Cost Model Table Scan Common Join Map Join Bucket Map Join SMB Join Skew Join Distinct/Group By Union All Filter/Having Select Filter Selectivity Join Cardinality (without Histogram) Distinct Estimation 5.</description></item><item><title>Apache Hive : CSV Serde</title><link>https://hive.apache.org/docs/latest/user/csv-serde/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/csv-serde/</guid><description>Apache Hive : CSV Serde Apache Hive : CSV Serde Availability Background Usage Versions Availability Earliest version CSVSerde is available
The CSVSerde is available in Hive 0.14 and greater.
Background The CSV SerDe is based on https://github.com/ogrodnek/csv-serde, and was added to the Hive distribution in HIVE-7777.
 Limitation
This SerDe treats all columns to be of type String. Even if you create a table with non-string column types using this SerDe, the DESCRIBE TABLE output would show string column type.</description></item><item><title>Apache Hive : Data Connector for Hive and Hive-like engines</title><link>https://hive.apache.org/docs/latest/user/data-connector-for-hive-and-hive-like-engines/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/data-connector-for-hive-and-hive-like-engines/</guid><description>Apache Hive : Data Connector for Hive and Hive-like engines What is a Data connector? Data connectors (referred to as &amp;ldquo;connector&amp;rdquo; in Hive Query Language) are top level objects in Hive where users can define a set of properties required to be able to connect to an external datasource from hive. This document illustrates example of the data connector framework can be used to do SQL query federation between two distinct &amp;ldquo;hive&amp;rdquo; clusters/installations or between Hive and another hive-like compute engines (eg: EMR).</description></item><item><title>Apache Hive : Data Connectors in Hive</title><link>https://hive.apache.org/docs/latest/user/data-connectors-in-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/data-connectors-in-hive/</guid><description>Apache Hive : Data Connectors in Hive What is a Data connector? Data connectors (referred to as &amp;ldquo;connector&amp;rdquo; in Hive Query Language) are top level objects in Hive where users can define a set of properties required to be able to connect to a datasource from hive. So a connector has a type (closed enumerated set) that allows Hive to determine the driver class (for JDBC) and other URL params, a URL and a set of properties that could include the default credentials for the remote datasource.</description></item><item><title>Apache Hive : Datasketches Integration</title><link>https://hive.apache.org/docs/latest/language/datasketches-integration/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/datasketches-integration/</guid><description>Apache Hive : Datasketches Integration Apache DataSketches (https://datasketches.apache.org/) is integrated into Hive via HIVE-22939.
This enables various kind of sketch operations thru regular sql statement.
Apache Hive : Datasketches Integration Sketch functions Naming convention sketchType functionName List declared sketch functions Integration with materialized views BI mode Rewrite COUNT(DISTINCT(X)) Rewrite percentile_disc(p) withing group(order by x) Rewrite cume_dist() over (order by id) Rewrite NTILE Rewrite RANK Examples Simple distinct counting examples using HLL Use HLL to compute distinct values using an intermediate table Use HLL to compute distinct values without intermediate table Use HLL to compute distinct values transparently thru BI mode Use HLL to compute distinct values transparently thru BI mode - while utilizing a Materialized View to store the intermediate sketches.</description></item><item><title>Apache Hive : Default Constraint (HIVE-18726)</title><link>https://hive.apache.org/development/desingdocs/default-constraint/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/default-constraint/</guid><description>Apache Hive : Default Constraint (HIVE-18726) Introduction This document proposes the addition of DEFAULT clause to Hive. DEFAULT clause is a domain constraint which lets user specify a value for domain i.e. column to be used in absence of user specified value i.e. in absence of column reference. Note that this does not propose to implement DEFAULT ON NULL like ORACLE which lets user specify DEFAULT value for explicit NULLs.</description></item><item><title>Apache Hive : DEFAULT Keyword (HIVE-19059)</title><link>https://hive.apache.org/development/desingdocs/default-keyword/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/default-keyword/</guid><description>Apache Hive : DEFAULT Keyword (HIVE-19059) Goal We propose to add DEFAULT keyword in INSERT INTO, UPDATE and MERGE statements to let user add DEFAULT values without specifying column schema.
Background With the addition of DEFAULT constraint (HIVE-18726) user can define columns to have default value which will be used in case user doesn’t explicitly specify it while INSERTING data. For DEFAULT constraint to kick in user has to explicitly specify column schema leaving out the column name for which user would like the sytem to use DEFAULT value.</description></item><item><title>Apache Hive : Dependent Tables</title><link>https://hive.apache.org/development/desingdocs/dependent-tables/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/dependent-tables/</guid><description>Apache Hive : Dependent Tables Hive supports both partitioned and unpartitioned external tables. In both cases, when a new table/partition is being added, the location is also specified for the new table/partition. Let us consider a specific example:
create table T (key string, value string) partitioned by (ds string, hr string);
insert overwrite table T partition (ds=&amp;lsquo;1&amp;rsquo;, hr=&amp;lsquo;1&amp;rsquo;) &amp;hellip;;
..
insert overwrite table T partition (ds=&amp;lsquo;1&amp;rsquo;, hr=&amp;lsquo;24&amp;rsquo;) &amp;hellip;;
T is a partitioned table by date and hour, and Tsignal is an external table which conceptually denotes the creation of the signal table.</description></item><item><title>Apache Hive : Design</title><link>https://hive.apache.org/development/desingdocs/design/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/design/</guid><description>Apache Hive : Design This page contains details about the Hive design and architecture. A brief technical report about Hive is available at hive.pdf.
Apache Hive : Design Hive Architecture Hive Data Model Metastore Motivation Metadata Objects Metastore Architecture Metastore Interface Hive Query Language Compiler Optimizer Hive APIs Attachments: Hive Architecture Figure 1
Figure 1 shows the major components of Hive and its interactions with Hadoop.</description></item><item><title>Apache Hive : DesignDocs</title><link>https://hive.apache.org/development/desingdocs/designdocs/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/designdocs/</guid><description>Apache Hive : DesignDocs Hive Design Documents Proposals that appear in the &amp;ldquo;Completed&amp;rdquo; and &amp;ldquo;In Progress&amp;rdquo; sections should include a link to a JIRA ticket
Completed Views (HIVE-1143) Partitioned Views (HIVE-1941) Storage Handlers (HIVE-705) HBase Integration HBase Bulk Load Locking (HIVE-1293) Indexes (HIVE-417) Bitmap Indexes (HIVE-1803) Filter Pushdown (HIVE-279) Table-level Statistics (HIVE-1361) Dynamic Partitions Binary Data Type (HIVE-2380) Decimal Precision and Scale Support HCatalog (formerly Howl) HiveServer2 (HIVE-2935) Column Statistics in Hive (HIVE-1362) List Bucketing (HIVE-3026) Group By With Rollup (HIVE-2397) Enhanced Aggregation, Cube, Grouping and Rollup (HIVE-3433) Optimizing Skewed Joins (HIVE-3086) Correlation Optimizer (HIVE-2206) Hive on Tez (HIVE-4660) Hive-Tez Compatibility Vectorized Query Execution (HIVE-4160) Cost Based Optimizer in Hive (HIVE-5775) Atomic Insert/Update/Delete (HIVE-5317) Transaction Manager (HIVE-5843) SQL Standard based secure authorization (HIVE-5837) Hybrid Hybrid Grace Hash Join (HIVE-9277) LLAP Daemons (HIVE-7926) Support for Hive Replication (HIVE-7973) In Progress Column Level Top K Statistics (HIVE-3421) Hive on Spark (HIVE-7292) Hive on Spark: Join Design (HIVE-7613) Improve ACID Performance – download docx file (HIVE-14035, HIVE-14199, HIVE-14233) Query Results Caching (HIVE-18513) Default Constraint (HIVE-18726) Different TIMESTAMP types (HIVE-21348) Support SAML 2.</description></item><item><title>Apache Hive : DeveloperGuide</title><link>https://hive.apache.org/community/resources/developerguide/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/developerguide/</guid><description>Apache Hive : DeveloperGuide Apache Hive : DeveloperGuide Code Organization and a Brief Architecture Introduction Hive SerDe MetaStore Query Processor Compiling and Running Hive Default Mode Advanced Mode Running Hive Without a Hadoop Cluster Unit tests and debugging Layout of the unit tests Debugging Hive Code Pluggable interfaces File Formats SerDe - how to add a new SerDe Map-Reduce Scripts UDFs and UDAFs - how to add new UDFs and UDAFs Code Organization and a Brief Architecture Introduction Hive has 3 main components:</description></item><item><title>Apache Hive : DeveloperGuide UDTF</title><link>https://hive.apache.org/community/resources/developerguide-udtf/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/developerguide-udtf/</guid><description>Apache Hive : DeveloperGuide UDTF GenericUDTF Interface A custom UDTF can be created by extending the GenericUDTF abstract class and then implementing the initialize, process, and possibly close methods. The initialize method is called by Hive to notify the UDTF the argument types to expect. The UDTF must then return an object inspector corresponding to the row objects that the UDTF will generate. Once initialize() has been called, Hive will give rows to the UDTF using the process() method.</description></item><item><title>Apache Hive : Development ContributorsMeetings</title><link>https://hive.apache.org/community/meetings/development-contributorsmeetings/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/development-contributorsmeetings/</guid><description>Apache Hive : Development ContributorsMeetings Hive Contributors Meetings Active contributors to the Hive project are invited to attend the monthly Hive Contributors Meeting. Meetings are announced on the Hive Contributors meetup group.
Meeting Minutes April 18, 2012 December 5, 2011 September 7, 2011 July 26, 2011 June 30, 2011 April 25, 2011 January 11, 2011 (forgot to take notes) October 25, 2010 September 13, 2010 August 8, 2010 July 6, 2010 June 1, 2010</description></item><item><title>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100601</title><link>https://hive.apache.org/community/meetings/development-contributorsmeetings-hivecontributorsminutes100601/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/development-contributorsmeetings-hivecontributorsminutes100601/</guid><description>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100601 Notes provided by Namit Jain.
The following people were present:
Facebook (Paul Yang; Ning Zhang; Yongqiang He; Ahmed Aly; John Sichi; Ashish Thusoo; Namit Jain) Netflix (Eva Tse; Jerome Boulon) Cloudera (Arvind Prabhakar; Vinithra Varadharajan; Carl Steinbach) Yahoo (Alan Gates) The following were the main meeting minutes:
We should have these meetings more often, say every month. Cloudera will host the next meeting.</description></item><item><title>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100706</title><link>https://hive.apache.org/community/meetings/development-contributorsmeetings-hivecontributorsminutes100706/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/development-contributorsmeetings-hivecontributorsminutes100706/</guid><description>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100706 Attendees: Amr Awadallah, John Sichi, Paul Yang, Olga Natkovich, Ajay Kidave, Yongqiang He, Basab Malik, Vinithra Varadharajan, bc Wong, Arvind Prabhakar, Carl Steinbach
bc Wong gave a live demo of Cloudera&amp;rsquo;s Hue framework and the Beeswax Hive web interface. Slides from this talk are available here: http://www.slideshare.net/cwsteinbach/cloudera-huebeeswax Hue was recently released as open source. The code is available on Github here: http://github.com/cloudera/hue Olga Natkovich gave a whiteboard talk on HOwl.</description></item><item><title>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100808</title><link>https://hive.apache.org/community/meetings/development-contributorsmeetings-hivecontributorsminutes100808/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/development-contributorsmeetings-hivecontributorsminutes100808/</guid><description>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100808 August 8th, 2010
Yongqiang He gave a presentation about his work on index support in Hive. Slides are available here: http://files.meetup.com/1658206/Hive%20Index.pptx John Sichi talked about his work on filter-pushdown optimizations. This is applicable to the HBase storage handler and the new index infrastructure. Pradeep Kamath gave an update on progress with Howl. The Howl source code is available on GitHub here: http://github.</description></item><item><title>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100913</title><link>https://hive.apache.org/community/meetings/development-contributorsmeetings-hivecontributorsminutes100913/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/development-contributorsmeetings-hivecontributorsminutes100913/</guid><description>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes100913 Meeting date: Sept 13, 2010
Location: Cloudera Palo Alto office
Attendees: http://www.meetup.com/Hive-Contributors-Group/calendar/14689507/
Carl Steinbach gave a status update on the 0.6 release. Since plans for documentation migration have been deferred to the next release, the only remaining issues are completion of the CREATE DATABASE feature (HIVE-675), metastore VARCHAR precision widening (HIVE-1364), and metastore upgrade scripts (HIVE-1427). HIVE-675 has already been committed to trunk and the backport for 0.</description></item><item><title>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes101025</title><link>https://hive.apache.org/community/meetings/development-contributorsmeetings-hivecontributorsminutes101025/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/development-contributorsmeetings-hivecontributorsminutes101025/</guid><description>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes101025 Meeting date: October 25, 2010
Location: Facebook Palo Alto
Attendees: http://www.meetup.com/Hive-Contributors-Group/calendar/14875663 plus Paul, Ning, Yongqiang, Liyin, Basab
The TLP and bylaws votes passed, so Hive is now officially an Apache top level project! We are going ahead with moving the following resources:
website (now at hive.apache.org) svn (new trunk location is http://svn.apache.org/repos/asf/hive/trunk); git will follow soon irc: we are making #hive the official channel on freenode.</description></item><item><title>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes110425</title><link>https://hive.apache.org/community/meetings/development-contributorsmeetings-hivecontributorsminutes110425/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/development-contributorsmeetings-hivecontributorsminutes110425/</guid><description>Apache Hive : Development ContributorsMeetings HiveContributorsMinutes110425 Meeting date: April 25, 2011
Location: Facebook Palo Alto
Attendees: http://www.meetup.com/Hive-Contributors-Group/events/17272914/
The 0.7 release is out, and Carl proposed an 0.7.1 release for items such as PostgreSQL metastore upgrade scripts and Maven artifact publication. Rules for a point release were discussed: no metastore changes, and no changes to API&amp;rsquo;s such as Thrift and extension interfaces. Everyone was fine with this; Carl will manage the release.</description></item><item><title>Apache Hive : Different TIMESTAMP types</title><link>https://hive.apache.org/development/desingdocs/different-timestamp-types/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/different-timestamp-types/</guid><description>Apache Hive : Different TIMESTAMP types Overview The following overview depicts the desired timestamp semantics in comparison to the SQL standard and selected database vendors:
TIMESTAMP and TIMESTAMP WITHOUT TIME ZONE The TIMESTAMP and TIMESTAMP WITHOUT TIME ZONE types shall behave like the LocalDateTime class of Java, i.e., each value is a recording of what can be seen on a calendar and a clock hanging on the wall, for example &amp;ldquo;1969-07-20 16:17:39&amp;rdquo;.</description></item><item><title>Apache Hive : Druid Integration</title><link>https://hive.apache.org/docs/latest/user/druid-integration/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/druid-integration/</guid><description>Apache Hive : Druid Integration This page documents the work done for the integration between Druid and Hive introduced in Hive 2.2.0 (HIVE-14217). Initially it was compatible with Druid 0.9.1.1, the latest stable release of Druid to that date.
Apache Hive : Druid Integration Objectives Preliminaries Druid Storage Handlers Usage Discovery and management of Druid datasources from Hive Create tables linked to existing Druid datasources Create Druid datasources from Hive Druid kafka ingestion from Hive INSERT, INSERT OVERWRITE and DROP statements Queries completely executed in Druid Queries across Druid and Hive Open Issues (JIRA) Objectives Our main goal is to be able to index data from Hive into Druid, and to be able to query Druid datasources from Hive.</description></item><item><title>Apache Hive : DynamicPartitions</title><link>https://hive.apache.org/development/desingdocs/dynamicpartitions/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/dynamicpartitions/</guid><description>Apache Hive : DynamicPartitions Apache Hive : DynamicPartitions Documentation Terminology Syntax Design Design issues Documentation This is the design document for dynamic partitions in Hive. Usage information is also available:
Tutorial: Dynamic-Partition Insert Hive DML: Dynamic Partition Inserts HCatalog Dynamic Partitioning Usage with Pig Usage from MapReduce References:
Original design doc HIVE-936 Terminology Static Partition (SP) columns: in DML/DDL involving multiple partitioning columns, the columns whose values are known at COMPILE TIME (given by user).</description></item><item><title>Apache Hive : Enabling gRPC in Hive/Hive Metastore (Proposal)</title><link>https://hive.apache.org/development/desingdocs/enabling-grpc-in-hive-metastore/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/enabling-grpc-in-hive-metastore/</guid><description>Apache Hive : Enabling gRPC in Hive/Hive Metastore (Proposal) Apache Hive : Enabling gRPC in Hive/Hive Metastore (Proposal) Contacts Objective Background Design Overview Implementation Pluggable gRPC Support Hive Metastore Server Hive Metastore Client Summary Future Work Attachments: Contacts Cameron Moberg (Google), Zhou Fang (Google), Feng Lu (Google), Thejas Nair (Cloudera), Vihang Karajgaonkar (Cloudera), Naveen Gangam (Cloudera)</description></item><item><title>Apache Hive : Enhanced Aggregation, Cube, Grouping and Rollup</title><link>https://hive.apache.org/docs/latest/language/enhanced-aggregation-cube-grouping-and-rollup/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/enhanced-aggregation-cube-grouping-and-rollup/</guid><description>Apache Hive : Enhanced Aggregation, Cube, Grouping and Rollup This document describes enhanced aggregation features for the GROUP BY clause of SELECT statements.
Apache Hive : Enhanced Aggregation, Cube, Grouping and Rollup GROUPING SETS clause Grouping__ID function Grouping function Cubes and Rollups hive.new.job.grouping.set.cardinality Grouping__ID function (before Hive 2.3.0) Version
Grouping sets, CUBE and ROLLUP operators, and the GROUPING__ID function were added in Hive 0.</description></item><item><title>Apache Hive : Exchange Partition</title><link>https://hive.apache.org/docs/latest/language/exchange-partition/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/exchange-partition/</guid><description>Apache Hive : Exchange Partition The EXCHANGE PARTITION command will move a partition from a source table to target table and alter each table&amp;rsquo;s metadata. The Exchange Partition feature is implemented as part of HIVE-4095. Exchanging multiple partitions is supported in Hive versions 1.2.2, 1.3.0, and 2.0.0+ as part of HIVE-11745.
When the command is executed, the source table&amp;rsquo;s partition folder in HDFS will be renamed to move it to the destination table&amp;rsquo;s partition folder.</description></item><item><title>Apache Hive : FileFormats</title><link>https://hive.apache.org/docs/latest/user/fileformats/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/fileformats/</guid><description>Apache Hive : FileFormats File Formats and Compression File Formats Hive supports several file formats:
Text File SequenceFile RCFile Avro Files ORC Files Parquet Custom INPUTFORMAT and OUTPUTFORMAT The hive.default.fileformat configuration parameter determines the format to use if it is not specified in a CREATE TABLE or ALTER TABLE statement. Text file is the parameter&amp;rsquo;s default value.
For more information, see the sections Storage Formats and Row Formats &amp;amp; SerDe on the DDL page.</description></item><item><title>Apache Hive : FilterPushdownDev</title><link>https://hive.apache.org/development/desingdocs/filterpushdowndev/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/filterpushdowndev/</guid><description>Apache Hive : Filter Pushdown This document explains how we are planning to add support in Hive&amp;rsquo;s optimizer for pushing filters down into physical access methods. This is an important optimization for minimizing the amount of data scanned and processed by an access method (e.g. for an indexed key lookup), as well as reducing the amount of data passed into Hive for further query evaluation.
Apache Hive : Filter Pushdown Use Cases Components Involved Primary Filter Representation Other Filter Representations Filter Passing Filter Collection Filter Decomposition Use Cases Below are the main use cases we are targeting.</description></item><item><title>Apache Hive : GenericUDAFCaseStudy</title><link>https://hive.apache.org/docs/latest/language/genericudafcasestudy/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/genericudafcasestudy/</guid><description>Apache Hive : Tutorial to write a GenericUDAF User-Defined Aggregation Functions (UDAFs) are an excellent way to integrate advanced data-processing into Hive. Hive allows two varieties of UDAFs: simple and generic. Simple UDAFs, as the name implies, are rather simple to write, but incur performance penalties because of the use of Java Reflection, and do not allow features such as variable-length argument lists. Generic UDAFs allow all these features, but are perhaps not quite as intuitive to write as Simple UDAFs.</description></item><item><title>Apache Hive : GettingStarted</title><link>https://hive.apache.org/development/gettingstarted-latest/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/gettingstarted-latest/</guid><description>Apache Hive : GettingStarted Apache Hive : GettingStarted Installation and Configuration Requirements Installing Hive from a Stable Release Building Hive from Source Running Hive Configuration Management Overview Runtime Configuration Hive, Map-Reduce and Local-Mode Hive Logging DDL Operations Creating Hive Tables Browsing through Tables Altering and Dropping Tables Metadata Store DML Operations SQL Operations Example Queries Simple Example Use Cases MovieLens User Ratings Apache Weblog Data Installation and Configuration You can install a stable release of Hive by downloading a tarball, or you can download the source code and build Hive from that.</description></item><item><title>Apache Hive : GroupByWithRollup</title><link>https://hive.apache.org/development/desingdocs/groupbywithrollup/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/groupbywithrollup/</guid><description>Apache Hive : Group By With Rollup Apache Hive : Group By With Rollup Terminology Design Map Aggr &amp;amp; No Skew: Map Aggr &amp;amp; Skew No Map Aggr &amp;amp; No Skew &amp;amp; No Rollup No Map Aggr &amp;amp; No Skew &amp;amp; With Rollup No Map Aggr &amp;amp; Skew &amp;amp; (No Distinct or No Rollup) No Map Aggr &amp;amp; Skew &amp;amp; Distinct &amp;amp; Rollup References Terminology (No) Map Aggr: Shorthand for whether the configuration variable hive.</description></item><item><title>Apache Hive : Hadoop-compatible Input-Output Format for Hive</title><link>https://hive.apache.org/development/desingdocs/hadoop-compatible-input-output-format-for-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hadoop-compatible-input-output-format-for-hive/</guid><description>Apache Hive : Hadoop-compatible Input-Output Format for Hive Overview This is a proposal for adding API to Hive which allows reading and writing using a Hadoop compatible API. Specifically, the interfaces being implemented are:
InputFormat: http://hadoop.apache.org/docs/mapreduce/r0.21.0/api/org/apache/hadoop/mapreduce/InputFormat.html OutputFormat: http://hadoop.apache.org/docs/mapreduce/r0.21.0/api/org/apache/hadoop/mapreduce/OutputFormat.html The classes will be named HiveApiInputFormat and HiveApiOutputFormat.
See HIVE-3752 for discussion of this proposal.
InputFormat (reading from Hive) Usage:
Create a HiveInputDescription object. Fill it with information about the table to read from (with database, partition, columns).</description></item><item><title>Apache Hive : Hbase execution plans for RawStore partition filter condition</title><link>https://hive.apache.org/development/desingdocs/hbase-execution-plans-for-rawstore-partition-filter-condition/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hbase-execution-plans-for-rawstore-partition-filter-condition/</guid><description>Apache Hive : Hbase execution plans for RawStore partition filter condition (Apologies for this doc being organized properly, I thought something is better than nothing - Thejas)
This is part of metastore on hbase work - HIVE-9452 Use HBase to store Hive metadata Open
Functionality needed
RawStore functions that support partition filtering are the following -
getPartitionsByExpr getPartitionsByFilter (takes filter string as argument, used from hcatalog) We need to generate a query execution plan in terms of Hbase scan api calls for a given filter condition.</description></item><item><title>Apache Hive : HBaseBulkLoad</title><link>https://hive.apache.org/development/desingdocs/hbasebulkload/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hbasebulkload/</guid><description>Apache Hive : HBase Bulk Load This page explains how to use Hive to bulk load data into a new (empty) HBase table per HIVE-1295. (If you&amp;rsquo;re not using a build which contains this functionality yet, you&amp;rsquo;ll need to build from source and make sure this patch and HIVE-1321 are both applied.)
Apache Hive : HBase Bulk Load Overview Decide on Target HBase Schema Estimate Resources Needed Add necessary JARs Prepare Range Partitioning Prepare Staging Location Sort Data Run HBase Script Map New Table Back Into Hive Followups Needed Overview Ideally, bulk load from Hive into HBase would be part of HBaseIntegration, making it as simple as this:</description></item><item><title>Apache Hive : HBaseIntegration</title><link>https://hive.apache.org/docs/latest/user/hbaseintegration/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hbaseintegration/</guid><description>Apache Hive : HBase Integration This page documents the Hive/HBase integration support originally introduced in HIVE-705. This feature allows Hive QL statements to access HBase tables for both read (SELECT) and write (INSERT). It is even possible to combine access to HBase tables with native Hive tables via joins and unions.
A presentation is available from the HBase HUG10 Meetup
This feature is a work in progress, and suggestions for its improvement are very welcome.</description></item><item><title>Apache Hive : HBaseMetastoreDevelopmentGuide</title><link>https://hive.apache.org/development/desingdocs/hbasemetastoredevelopmentguide/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hbasemetastoredevelopmentguide/</guid><description>Apache Hive : HBaseMetastoreDevelopmentGuide  Guide for contributors to the metastore on hbase development work. Umbrella JIRA - HIVE-9452
This work is discontinued and the code is removed in release 3.0.0 (HIVE-17234).
Apache Hive : HBaseMetastoreDevelopmentGuide Building Setup for running hive against hbase metastore - Importing metadata from rdbms to hbase Design Docs Building You will need to download the source for Tephra and build it from the develop branch.</description></item><item><title>Apache Hive : HCatalog</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-base/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-base/</guid><description>Apache Hive : HCatalog HCatalog is a table and storage management layer for Hadoop that enables users with different data processing tools — Pig, MapReduce — to more easily read and write data on the grid.
This is the HCatalog manual. Using HCatalog Installation from Tarball HCatalog Configuration Properties Load and Store Interfaces Input and Output Interfaces Reader and Writer Interfaces Command Line Interface Storage Formats Dynamic Partitioning Notification Storage Based Authorization The old HCatalog wiki page has many other documents including additional user documentation, further information on HBase integration, and resources for contributors.</description></item><item><title>Apache Hive : HCatalog Authorization</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-authorization/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-authorization/</guid><description>Apache Hive : HCatalog Authorization Apache Hive : HCatalog Authorization Storage Based Authorization Default Authorization Model of Hive Storage-System Based Authorization Model Minimum Permissions Unused DDL for Permissions Configuring Storage-System Based Authorization Creating New Tables or Databases Known Issues Storage Based Authorization Default Authorization Model of Hive The default authorization model of Hive supports a traditional RDBMS style of authorization based on users, groups and roles and granting them permissions to do operations on database or table.</description></item><item><title>Apache Hive : HCatalog CLI</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-cli/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-cli/</guid><description>Apache Hive : HCatalog Command Line Interface Apache Hive : HCatalog Command Line Interface Set Up HCatalog CLI Owner Permissions Hive CLI HCatalog DDL Create/Drop/Alter Table Create/Drop/Alter View Show/Describe Create/Drop Index Create/Drop Function &amp;ldquo;dfs&amp;rdquo; Command and &amp;ldquo;set&amp;rdquo; Command Other Commands CLI Errors Authentication Error Log Set Up The HCatalog command line interface (CLI) can be invoked as HIVE_HOME=hive_home hcat_home/bin/hcat where hive_home is the directory where Hive has been installed and hcat_home is the directory where HCatalog has been installed.</description></item><item><title>Apache Hive : HCatalog Configuration Properties</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-configuration-properties/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-configuration-properties/</guid><description>Apache Hive : HCatalog Configuration Properties Apache HCatalog&amp;rsquo;s behaviour can be modified through the use of a few configuration parameters specified in jobs submitted to it. This document details all the various knobs that users have available to them, and what they accomplish.  Apache Hive : HCatalog Configuration Properties Setup Storage Directives Cache Behaviour Directives Input Split Generation Behaviour Data Promotion Behaviour HCatRecordReader Error Tolerance Behaviour Setup The properties described in this page are meant to be job-level properties set on HCatalog through the jobConf passed into it.</description></item><item><title>Apache Hive : HCatalog DynamicPartitions</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-dynamicpartitions/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-dynamicpartitions/</guid><description>Apache Hive : HCatalog Dynamic Partitioning Apache Hive : HCatalog Dynamic Partitioning Overview External Tables Hive Dynamic Partitions Usage with Pig Usage from MapReduce Overview When writing data in HCatalog it is possible to write all records to a single partition. In this case the partition column(s) need not be in the output data.
The following Pig script illustrates this:</description></item><item><title>Apache Hive : HCatalog InputOutput</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-inputoutput/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-inputoutput/</guid><description>Apache Hive : HCatalog Input and Output Interfaces Apache Hive : HCatalog Input and Output Interfaces Set Up HCatInputFormat API HCatOutputFormat API HCatRecord Running MapReduce with HCatalog Authentication Read Example Filter Operators Scan Filter Write Filter Set Up No HCatalog-specific setup is required for the HCatInputFormat and HCatOutputFormat interfaces.
Note: HCatalog is not thread safe.</description></item><item><title>Apache Hive : HCatalog InstallHCat</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-installhcat/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-installhcat/</guid><description>Apache Hive : HCatalog Installation from Tarball Apache Hive : HCatalog Installation from Tarball HCatalog Installed with Hive HCatalog Command Line HCatalog Client Jars HCatalog Server HCatalog Installed with Hive Version
HCatalog is installed with Hive, starting with Hive release 0.11.0.
Hive installation is documented here.
HCatalog Command Line If you install Hive from the binary tarball, the hcat command is available in the hcatalog/bin directory.</description></item><item><title>Apache Hive : HCatalog LoadStore</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-loadstore/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-loadstore/</guid><description>Apache Hive : HCatalog Load and Store Interfaces Apache Hive : HCatalog Load and Store Interfaces Set Up Running Pig HCatLoader Usage HCatLoader Data Types Running Pig with HCatalog Load Examples HCatStorer Usage Store Examples HCatStorer Data Types Data Type Mappings Primitive Types Complex Types Set Up The HCatLoader and HCatStorer interfaces are used with Pig scripts to read and write data in HCatalog-managed tables.</description></item><item><title>Apache Hive : HCatalog Notification</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-notification/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-notification/</guid><description>Apache Hive : HCatalog Notification Apache Hive : HCatalog Notification Overview Notification for a New Partition Notification for a Set of Partitions Server Configuration Enable JMS Notifications Topic Names Overview Since version 0.2, HCatalog provides notifications for certain events happening in the system. This way applications such as Oozie can wait for those events and schedule the work that depends on them.</description></item><item><title>Apache Hive : HCatalog ReaderWriter</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-readerwriter/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-readerwriter/</guid><description>Apache Hive : HCatalog Reader and Writer Interfaces Apache Hive : HCatalog Reader and Writer Interfaces Overview HCatReader HCatWriter Complete Example Program Overview HCatalog provides a data transfer API for parallel input and output without using MapReduce. This API provides a way to read data from a Hadoop cluster or write data into a Hadoop cluster, using a basic storage abstraction of tables and rows.</description></item><item><title>Apache Hive : HCatalog StorageFormats</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-storageformats/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-storageformats/</guid><description>Apache Hive : HCatalog Storage Formats Apache Hive : HCatalog Storage Formats SerDes and Storage Formats Usage from Hive CTAS Issue with JSON SerDe SerDes and Storage Formats HCatalog uses Hive&amp;rsquo;s SerDe class to serialize and deserialize data. SerDes are provided for RCFile, CSV text, JSON text, and SequenceFile formats. Check the SerDe documentation for additional SerDes that might be included in new versions.</description></item><item><title>Apache Hive : HCatalog Streaming Mutation API</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-streaming-mutation-api/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-streaming-mutation-api/</guid><description>Apache Hive : HCatalog Streaming Mutation API A Java API focused on mutating (insert/update/delete) records into transactional tables using Hive’s ACID feature. It is introduced in Hive 2.0.0 (HIVE-10165).
Apache Hive : HCatalog Streaming Mutation API Background Structure Data Requirements Streaming Requirements Record Layout Connection and Transaction Management Writing Data Dynamic Partition Creation Reading Data Example Attachments: Background In certain data processing use cases it is necessary to modify existing data when new facts arrive.</description></item><item><title>Apache Hive : HCatalog UsingHCat</title><link>https://hive.apache.org/docs/latest/hcatalog/hcatalog-usinghcat/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/hcatalog/hcatalog-usinghcat/</guid><description>Apache Hive : HCatalog Usage Apache Hive : HCatalog Usage Version information Overview HCatalog Architecture Interfaces Data Model Data Flow Example First: Copy Data to the Grid Second: Prepare the Data Third: Analyze the Data HCatalog Web API Attachments: Version information HCatalog graduated from the Apache incubator and merged with the Hive project on March 26, 2013.</description></item><item><title>Apache Hive : Hive across Multiple Data Centers (Physical Clusters)</title><link>https://hive.apache.org/development/desingdocs/hive-across-multiple-data-centers/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hive-across-multiple-data-centers/</guid><description>Apache Hive : Hive across Multiple Data Centers (Physical Clusters) This project has been abandoned. We&amp;rsquo;re leaving the design doc here in case someone decides to attempt this project in the future.
Apache Hive : Hive across Multiple Data Centers (Physical Clusters) Use Cases Requirements Use Cases Inside facebook, we are running out of power inside a data center (physical cluster), and we have a need to have a bigger cluster.</description></item><item><title>Apache Hive : Hive APIs Overview</title><link>https://hive.apache.org/community/resources/hive-apis-overview/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/hive-apis-overview/</guid><description>Apache Hive : Hive APIs Overview This page aims to catalogue and describe the various public facing APIs exposed by Hive in order to inform developers wishing to integrate their applications and frameworks with the Hive ecosystem. To date the following APIs have been identified in the Hive project that are either considered public, or widely used in the public domain:
Apache Hive : Hive APIs Overview API categories Operation based APIs Query based APIs Available APIs HCatClient (Java) HCatalog Storage Handlers (Java) HCatalog CLI (Command Line) Metastore (Java) WebHCat (REST) Streaming Data Ingest (Java) Streaming Mutation (Java) hive-jdbc (JDBC) API categories The APIs can be segmented into two conceptual categories: operation based APIs and query based APIs.</description></item><item><title>Apache Hive : Hive Aws EMR</title><link>https://hive.apache.org/docs/latest/user/hive-aws-emr/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hive-aws-emr/</guid><description>Apache Hive : Hive Aws EMR Amazon Elastic MapReduce and Hive Amazon Elastic MapReduce is a web service that makes it easy to launch managed, resizable Hadoop clusters on the web-scale infrastructure of Amazon Web Services (AWS). Elastic Map Reduce makes it easy for you to launch a Hive and Hadoop cluster, provides you with flexibility to choose different cluster sizes, and allows you to tear them down automatically when processing has completed.</description></item><item><title>Apache Hive : Hive Configurations</title><link>https://hive.apache.org/docs/latest/user/hive-configurations/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hive-configurations/</guid><description>Apache Hive : Hive Configurations Hive has more than 1600 configs around the service. The hive-site.xml contains the default configurations for the service. In this config file, you can change the configs. Every config change needs to restart the service(s).
Here you can find the most important configurations and default values.
Config Name Default Value Description Config file hive.metastore.client.cache.v2.enabled true This property enabled a Caffaine Cache for Metastore client MetastoreConf More configs are in MetastoreConf.</description></item><item><title>Apache Hive : Hive deprecated authorization mode / Legacy Mode</title><link>https://hive.apache.org/docs/latest/user/hive-deprecated-authorization-mode/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hive-deprecated-authorization-mode/</guid><description>Apache Hive : Hive deprecated authorization mode / Legacy Mode This document describes Hive security using the basic authorization scheme, which regulates access to Hive metadata on the client side. This was the default authorization mode used when authorization was enabled. The default was changed to SQL Standard authorization in Hive 2.0 (HIVE-12429).
Apache Hive : Hive deprecated authorization mode / Legacy Mode Disclaimer Prerequisites Users, Groups, and Roles Creating/Dropping/Using Roles Privileges Hive Operations and Required Privileges Disclaimer Hive authorization is not completely secure.</description></item><item><title>Apache Hive : Hive HPL/SQL</title><link>https://hive.apache.org/docs/latest/user/hive-hpl-sql/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hive-hpl-sql/</guid><description>Apache Hive : Hive HPL/SQL Hive Hybrid Procedural SQL On Hadoop (HPL/SQL) is a tool that implements procedural SQL for Hive. It is available in Hive 2.0.0 (HIVE-11055).
HPL/SQL is an open source tool (Apache License 2.0) that implements procedural SQL language for Apache Hive, SparkSQL, Impala as well as any other SQL-on-Hadoop implementation, any NoSQL and any RDBMS.
HPL/SQL is a hybrid and heterogeneous language that understands syntaxes and semantics of almost any existing procedural SQL dialect, and you can use with any database, for example, running existing Oracle PL/SQL code on Apache Hive and Microsoft SQL Server, or running Transact-SQL on Oracle, Cloudera Impala or Amazon Redshift.</description></item><item><title>Apache Hive : Hive Metadata Caching Proposal</title><link>https://hive.apache.org/development/desingdocs/hive-metadata-caching-proposal/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hive-metadata-caching-proposal/</guid><description>Apache Hive : Hive Metadata Caching Proposal Why Metastore Cache During Hive 2 benchmark, we find Hive metastore operation take a lot of time and thus slow down Hive compilation. In some extreme case, it takes much longer than the actual query run time. Especially, we find the latency of cloud db is very high and 90% of total query runtime is waiting for metastore SQL database operations. Based on this observation, the metastore operation performance will be greatly enhanced if we have a memory structure which cache the database query result.</description></item><item><title>Apache Hive : Hive MetaTool</title><link>https://hive.apache.org/docs/latest/admin/hive-metatool/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/hive-metatool/</guid><description>Apache Hive : Hive MetaTool Introduced in Hive 0.10.0. See HIVE-3056 and HIVE-3443.
The Hive MetaTool enables administrators to do bulk updates on the location fields in database, table, and partition records in the metastore. It provides the following functionality:
Ability to search and replace the HDFS NN (NameNode) location in metastore records that reference the NN. One use is to transition a Hive deployment to HDFS HA NN (HDFS High Availability NameNode).</description></item><item><title>Apache Hive : Hive Metrics</title><link>https://hive.apache.org/docs/latest/user/hive-metrics/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hive-metrics/</guid><description>Apache Hive : Hive Metrics The metrics that Hive collects can be viewed in the HiveServer2 Web UI by using the &amp;ldquo;Metrics Dump&amp;rdquo; tab.
The metrics dump will display any metric available over JMX encoded in JSON: Alternatively the metrics can be written directly into HDFS, a JSON file on the local file system where the HS2 instance is running or to the console by enabling the corresponding metric reporters. By default only the JMX and the JSON file reporter are enabled.</description></item><item><title>Apache Hive : Hive on Spark</title><link>https://hive.apache.org/docs/latest/user/hive-on-spark/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hive-on-spark/</guid><description>Apache Hive : Hive on Spark Apache Hive : Hive on Spark 1. Introduction 1.1 Motivation 1.2 Design Principle 1.3 Comparison with Shark and Spark SQL 1.4 Other Considerations 2. High-Level Functionality 2.1 A New Execution Engine 2.2 Spark Configuration 2.3 Miscellaneous Functionality 3. Hive-Level Design 3.1 Query Planning 3.2 Job Execution 3.3 Design Considerations Table as RDD SparkWork SparkTask Shuffle, Group, and Sort Join Number of Tasks Local MapReduce Tasks Semantic Analysis and Logical Optimizations Job Diagnostics Counters and Metrics Explain Statements Hive Variables Union Concurrency and Thread Safety Build Infrastructure Mini Spark Cluster Testing 3.</description></item><item><title>Apache Hive : Hive on Spark: Getting Started</title><link>https://hive.apache.org/docs/latest/admin/hive-on-spark-getting-started/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/hive-on-spark-getting-started/</guid><description>Apache Hive : Hive on Spark: Getting Started Hive on Spark provides Hive with the ability to utilize Apache Spark as its execution engine.
set hive.execution.engine=spark; Hive on Spark was added in HIVE-7292.
Apache Hive : Hive on Spark: Getting Started Version Compatibility Spark Installation Configuring YARN Configuring Hive Configuration property details Configuring Spark Tuning Details Common Issues (Green are resolved, will be removed from this list) Recommended Configuration Design documents Attachments: Version Compatibility Hive on Spark is only tested with a specific version of Spark, so a given version of Hive is only guaranteed to work with a specific version of Spark.</description></item><item><title>Apache Hive : Hive on Spark: Join Design Master</title><link>https://hive.apache.org/development/desingdocs/hive-on-spark-join-design-master/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hive-on-spark-join-design-master/</guid><description>Apache Hive : Hive on Spark: Join Design Master Apache Hive : Hive on Spark: Join Design Master Purpose and Prerequisites MapReduce Summary Figure 1. Join Processors for Hive on MapReduce Tez Comparison Spark MapJoin Spark Join Design Figure 2: Join Processors for Hive on Spark Attachments: Purpose and Prerequisites The purpose of this document is to summarize the findings of all the research of different joins and describe a unified design to attack the problem in Spark.</description></item><item><title>Apache Hive : Hive on Tez</title><link>https://hive.apache.org/development/desingdocs/hive-on-tez/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hive-on-tez/</guid><description>Apache Hive : Hive on Tez Apache Hive : Hive on Tez Overview Multiple reduce stages Pipelining In memory versus disk writes Joins Fine-tuned algorithms Limit processing Scope Functional requirements of phase I Example Plan with TEZ Plan without TEZ Design Summary of changes Execution layer Job submission Job monitoring Job diagnostics Counters Job execution Query planning MapRedWork Semantic analysis and logical optimizations Physical Optimizations and Task generation Local Job Runner Number of tasks Explain statements Hive variables Build infrastructure Testing Mini Tez Cluster Installation and Configuration Hive-Tez Compatibility Overview Tez is a new application framework built on Hadoop Yarn that can execute complex directed acyclic graphs of general data processing tasks.</description></item><item><title>Apache Hive : Hive Operators</title><link>https://hive.apache.org/docs/latest/language/hive-operators/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/hive-operators/</guid><description>Apache Hive : Hive Operators Operators Precedences Example Operators Description A[B] , A.identifier bracket_op([]), dot(.) element selector, dot -A unary(+), unary(-), unary(~) unary prefix operators A IS [NOT] (NULL TRUE FALSE) A ^ B bitwise xor(^) bitwise xor A * B star(*), divide(/), mod(%), div(DIV) multiplicative operators A + B plus(+), minus(-) additive operators A B A &amp;amp; B bitwise and(&amp;amp;) bitwise and A B bitwise or( Relational Operators The following operators compare the passed operands and generate a TRUE or FALSE value depending on whether the comparison between the operands holds.</description></item><item><title>Apache Hive : Hive remote databases/tables</title><link>https://hive.apache.org/development/desingdocs/hive-remote-databases-tables/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hive-remote-databases-tables/</guid><description>Apache Hive : Hive remote databases/tables Abstract At the 2018 DataWorks conference in Berlin, Hotels.com presented Waggle Dance, a tool for federating multiple Hive clusters and providing the illusion of a unified data catalog from disparate instances. We’ve been running Waggle Dance in production for well over a year and it has formed a critical part of our data platform architecture and infrastructure.
We believe that this type of functionality will be of increasing importance as Hadoop and Hive workloads migrate to the cloud.</description></item><item><title>Apache Hive : Hive Transactions</title><link>https://hive.apache.org/docs/latest/user/hive-transactions/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hive-transactions/</guid><description>Apache Hive : ACID Transactions Apache Hive : ACID Transactions Upgrade to Hive 3+ What is ACID and why should you use it? Limitations Streaming APIs Grammar Changes Basic Design Base and Delta Directories Compactor Transaction/Lock Manager Configuration New Configuration Parameters for Transactions Configuration Values to Set for INSERT, UPDATE, DELETE Configuration Values to Set for Compaction Compaction pooling Table Properties Talks and Presentations Upgrade to Hive 3+ Any transactional tables created by a Hive version prior to Hive 3 require Major Compaction to be run on every partition before upgrading to 3.</description></item><item><title>Apache Hive : Hive Transactions (Hive ACID)</title><link>https://hive.apache.org/docs/latest/user/hive-transactions-acid/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hive-transactions-acid/</guid><description>Apache Hive : Hive Transactions (Hive ACID) Apache Hive : Hive Transactions (Hive ACID) What is ACID and why should you use it? Limitations Streaming APIs Grammar Changes Basic Design Base and Delta Directories Compactor Transaction/Lock Manager Configuration New Configuration Parameters for Transactions Configuration Values to Set for Hive ACID (INSERT, UPDATE, DELETE) Configuration Values to Set for Compaction Compaction pooling Table Properties Talks and Presentations What is ACID and why should you use it?</description></item><item><title>Apache Hive : Hive UDFs</title><link>https://hive.apache.org/docs/latest/language/hive-udfs/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/hive-udfs/</guid><description>Apache Hive : Hive UDFs Hive User-Defined Functions (UDFs) are custom functions developed in Java and seamlessly integrated with Apache Hive. UDFs are routines designed to accept parameters, execute a specific action, and return the resulting value. The return value can either be a single scalar row or a complete result set, depending on the UDF&amp;rsquo;s code and the implemented interface. UDFs represent a powerful capability that enhances classical SQL functionality by allowing the integration of custom code, providing Hive users with a versatile toolset.</description></item><item><title>Apache Hive : HIVE-24543: Support SAML 2.0 authentication mode</title><link>https://hive.apache.org/development/desingdocs/support-saml-2-0-authentication-mode/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/support-saml-2-0-authentication-mode/</guid><description>Apache Hive : HIVE-24543: Support SAML 2.0 authentication mode Description In cloud based deployments, it is common that the user identity is federated and managed externally by an identity provider (e.g Okta, PingIndentity, Azure AD). Integrating with such external identity providers (IDP) would help adoption and unlock use-cases where Hive is deployed in a cloud based environment and doesn&amp;rsquo;t need user managed authentication mechanisms (e.g Ldap, Kerberos). There are primarily two authentication protocols which are standardized with such external identity providers namely (SAML 2.</description></item><item><title>Apache Hive : Hive-Iceberg Integration</title><link>https://hive.apache.org/docs/latest/user/hive-iceberg-integration/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hive-iceberg-integration/</guid><description>Apache Hive : Hive-Iceberg Integration Apache Hive starting from 4.0 out of the box supports the Iceberg table format, the iceberg tables can be created like regular hive external or ACID tables, without adding any extra jars.
Creating an Iceberg Table
An iceberg table can be created using STORED BY ICEBERG keywords while creating a table.
Creating an Iceberg table using normal create command CREATE TABLE TBL_ICE (ID INT) STORED BY ICEBERG; The above creates an iceberg table named &amp;lsquo;TBL_ICE&amp;rsquo;</description></item><item><title>Apache Hive : Hive-Tez Compatibility</title><link>https://hive.apache.org/development/desingdocs/hive-tez-compatibility/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hive-tez-compatibility/</guid><description>Apache Hive : Hive-Tez Compatibility This is derived from the pom files of the respective releases. Other releases with compatibility are listed in parenthesis.
Hive (Works with) Tez 0.13 0.4.0-incubating 0.14 0.5.2+, (through 0.7.0) 1.0 0.5.2, (through 0.7.0) 1.1 0.5.2, (through 0.7.0) 1.2* 0.5.3, (through 0.7.0) 2.0 0.8.2 *Hive-1.2 is the latest release of Hive as of 07/2015.</description></item><item><title>Apache Hive : HiveAmazonElasticMapReduce</title><link>https://hive.apache.org/docs/latest/admin/hiveamazonelasticmapreduce/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/hiveamazonelasticmapreduce/</guid><description>Apache Hive : HiveAmazonElasticMapReduce Amazon Elastic MapReduce and Hive Amazon Elastic MapReduce is a web service that makes it easy to launch managed, resizable Hadoop clusters on the web-scale infrastructure of Amazon Web Services (AWS). Elastic Map Reduce makes it easy for you to launch a Hive and Hadoop cluster, provides you with flexibility to choose different cluster sizes, and allows you to tear them down automatically when processing has completed.</description></item><item><title>Apache Hive : HiveAws</title><link>https://hive.apache.org/docs/latest/admin/hiveaws/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/hiveaws/</guid><description>Apache Hive : HiveAws = Hive and Amazon Web Services =
Background This document explores the different ways of leveraging Hive on Amazon Web Services - namely S3, EC2 and Elastic Map-Reduce.
Hadoop already has a long tradition of being run on EC2 and S3. These are well documented in the links below which are a must read:
Hadoop and S3 Amazon and EC2 The second document also has pointers on how to get started using EC2 and S3.</description></item><item><title>Apache Hive : HiveAws HivingS3nRemotely</title><link>https://hive.apache.org/docs/latest/user/hiveaws-hivings3nremotely/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hiveaws-hivings3nremotely/</guid><description>Apache Hive : HiveAws HivingS3nRemotely = Querying S3 files from your PC (using EC2, Hive and Hadoop) =
Usage Scenario The scenario being covered here goes as follows:
A user has data stored in S3 - for example Apache log files archived in the cloud, or databases backed up into S3. The user would like to declare tables over the data sets here and issue SQL queries against them These SQL queries should be executed using computed resources provisioned from EC2.</description></item><item><title>Apache Hive : HiveClient</title><link>https://hive.apache.org/docs/latest/user/hiveclient/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hiveclient/</guid><description>Apache Hive : HiveClient This page describes the different clients supported by Hive. The command line client currently only supports an embedded server. The JDBC and Thrift-Java clients support both embedded and standalone servers. Clients in other languages only support standalone servers.
For details about the standalone server see Hive Server or HiveServer2.
Apache Hive : HiveClient Command Line JDBC JDBC Client Sample Code Running the JDBC Sample Code JDBC Client Setup for a Secure Cluster Python PHP ODBC Thrift Thrift Java Client Thrift C++ Client Thrift Node Clients Thrift Ruby Client Command Line Operates in embedded mode only, that is, it needs to have access to the Hive libraries.</description></item><item><title>Apache Hive : HiveContributorsMinutes100601</title><link>https://hive.apache.org/community/meetings/hivecontributorsminutes100601/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/hivecontributorsminutes100601/</guid><description>Apache Hive : HiveContributorsMinutes100601 Notes provided by Namit Jain.
The following people were present:
Facebook (Paul Yang; Ning Zhang; Yongqiang He; Ahmed Aly; John Sichi; Ashish Thusoo; Namit Jain) Netflix (Eva Tse; Jerome Boulon) Cloudera (Arvind Prabhakar; Vinithra Varadharajan; Carl Steinbach) Yahoo (Alan Gates) The following were the main meeting minutes:
We should have these meetings more often, say every month. Cloudera will host the next meeting.</description></item><item><title>Apache Hive : HiveContributorsMinutes100706</title><link>https://hive.apache.org/community/meetings/hivecontributorsminutes100706/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/meetings/hivecontributorsminutes100706/</guid><description>Apache Hive : HiveContributorsMinutes100706 Attendees: Amr Awadallah, John Sichi, Paul Yang, Olga Natkovich, Ajay Kidave, Yongqiang He, Basab Malik, Vinithra Varadharajan, bc Wong, Arvind Prabhakar, Carl Steinbach
bc Wong gave a live demo of Cloudera&amp;rsquo;s Hue framework and the Beeswax Hive web interface. Slides from this talk are available here: http://www.slideshare.net/cwsteinbach/cloudera-huebeeswax Hue was recently released as open source. The code is available on Github here: http://github.com/cloudera/hue Olga Natkovich gave a whiteboard talk on HOwl.</description></item><item><title>Apache Hive : HiveCounters</title><link>https://hive.apache.org/docs/latest/user/hivecounters/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hivecounters/</guid><description>Apache Hive : HiveCounters Task counters created by Hive during query execution
 For Tez execution, %context is set to the mapper/reducer name. For other execution engines it is not included in the counter name.
Counter Name Description RECORDS_IN[_%context] Input records read RECORDS_OUT[_%context] Output records written RECORDS_OUT_INTERMEDIATE[_%context] Records written as intermediate records to ReduceSink (which become input records to other tasks) CREATED_FILES Number of files created DESERIALIZE_ERRORS Deserialization errors encountered while reading data</description></item><item><title>Apache Hive : HiveDerbyServerMode</title><link>https://hive.apache.org/docs/latest/admin/hivederbyservermode/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/hivederbyservermode/</guid><description>Apache Hive : Using Derby in Server Mode Hive in embedded mode has a limitation of one active user at a time. You may want to run Derby as a Network Server, this way multiple users can access it simultaneously from different systems.
See Metadata Store and Embedded Metastore for more information.
Apache Hive : Using Derby in Server Mode Download Derby Set Environment Starting Derby Configure Hive to Use Network Derby Copy Derby Jar Files Start Up Hive The Result Download Derby It is suggested you download the version of Derby that ships with Hive.</description></item><item><title>Apache Hive : HiveDeveloperFAQ</title><link>https://hive.apache.org/community/resources/hivedeveloperfaq/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/hivedeveloperfaq/</guid><description>Apache Hive : HiveDeveloperFAQ Apache Hive : HiveDeveloperFAQ Developing How do I move some files? Building Maven settings How to build all source? How do I import into Eclipse? How to generate tarball? How to generate protobuf code? How to generate Thrift code? HIVE-26769 How to compile ODBC? How do I publish Hive artifacts to my local Maven repository? Testing How do I run precommit tests on a patch?</description></item><item><title>Apache Hive : HiveJDBCInterface</title><link>https://hive.apache.org/docs/latest/admin/hivejdbcinterface/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/hivejdbcinterface/</guid><description>Apache Hive : JDBC Driver The current JDBC interface for Hive only supports running queries and fetching results. Only a small subset of the metadata calls are supported.
To see how the JDBC interface can be used, see sample code.
Apache Hive : JDBC Driver Integration with Pentaho Integration with SQuirrel SQL Client Integration with Pentaho Download pentaho report designer from the pentaho website.</description></item><item><title>Apache Hive : HiveODBC</title><link>https://hive.apache.org/docs/latest/admin/hiveodbc/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/hiveodbc/</guid><description>Apache Hive : ODBC Driver These instructions are for the Hive ODBC driver available in Hive for HiveServer1.
There is no ODBC driver available for HiveServer2 as part of Apache Hive. There are third party ODBC drivers available from different vendors, and most of them seem to be free.
Apache Hive : ODBC Driver Introduction Suggested Reading Software Requirements Driver Architecture Building and Setting Up ODBC Components Hive Client Build/Setup unixODBC API Wrapper Build/Setup Connecting the Driver to a Driver Manager Testing with ISQL Build libodbchive.</description></item><item><title>Apache Hive : HivePlugins</title><link>https://hive.apache.org/docs/latest/language/hiveplugins/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/hiveplugins/</guid><description>Apache Hive : Plugins Apache Hive : Plugins Creating Custom UDFs Deploying Jars for User Defined Functions and User Defined SerDes Creating Custom UDFs First, you need to create a new class that extends UDF, with one or more methods named evaluate.
package com.example.hive.udf; import org.apache.hadoop.hive.ql.exec.UDF; import org.apache.hadoop.io.Text; public final class Lower extends UDF { public Text evaluate(final Text s) { if (s == null) { return null; } return new Text(s.</description></item><item><title>Apache Hive : HiveQL</title><link>https://hive.apache.org/docs/latest/language/hiveql/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/hiveql/</guid><description>Apache Hive : HiveQL This page is deprecated
Please see the HiveQL Language Manual</description></item><item><title>Apache Hive : HiveReplicationDevelopment</title><link>https://hive.apache.org/development/desingdocs/hivereplicationdevelopment/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hivereplicationdevelopment/</guid><description>Apache Hive : HiveReplicationDevelopment Apache Hive : HiveReplicationDevelopment Introduction Purposes of Replication Disaster Recovery Load Balancing Replication Taxonomy Transaction Source Synchronization Strategy Design Taxonomy Design Choices Primary-Copy vs Update-Anywhere Eager vs Lazy Other Design Choices Basic Approach Implementation Events Event IDs, State IDs, and Sequencing of Exports/Imports Handling of Events Future Features References Introduction Replication in the context of databases and warehouses is the process of duplication of entities from one warehouse to another.</description></item><item><title>Apache Hive : HiveReplicationv2Development</title><link>https://hive.apache.org/development/desingdocs/hivereplicationv2development/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hivereplicationv2development/</guid><description>Apache Hive : HiveReplicationv2Development This document describes the second version of Hive Replication. Please refer to the first version of Hive Replication for details on prior implementation.
This work is under development and interfaces are subject to change. This has been designed for use in conjunction with external orchestration tools, which would be responsible for co-ordinating the right sequence of commands between source and target clusters, fault tolerance/failure handling, and also providing correct configuration options that are necessary to be able to do cross cluster replication.</description></item><item><title>Apache Hive : HiveServer</title><link>https://hive.apache.org/docs/latest/admin/hiveserver/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/hiveserver/</guid><description>Apache Hive : HiveServer Thrift Hive Server HiveServer is an optional service that allows a remote client to submit requests to Hive, using a variety of programming languages, and retrieve results. HiveServer is built on Apache ThriftTM (http://thrift.apache.org/), therefore it is sometimes called the Thrift server although this can lead to confusion because a newer service named HiveServer2 is also built on Thrift. Since the introduction of HiveServer2, HiveServer has also been called HiveServer1.</description></item><item><title>Apache Hive : HiveServer2 Clients</title><link>https://hive.apache.org/docs/latest/user/hiveserver2-clients/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hiveserver2-clients/</guid><description>Apache Hive : HiveServer2 Clients This page describes the different clients supported by HiveServer2.
Apache Hive : HiveServer2 Clients Version information Beeline – Command Line Shell Beeline Example Beeline Commands Beeline Properties Beeline Hive Commands Beeline Command Options Output Formats HiveServer2 Logging Cancelling the Query Background Query in Terminal Script JDBC Connection URLs Connection URL Format Connection URL for Remote or Embedded Mode Connection URL When HiveServer2 Is Running in HTTP Mode Connection URL When SSL Is Enabled in HiveServer2 Connection URL When ZooKeeper Service Discovery Is Enabled Named Connection URLs Reconnecting Using hive-site.</description></item><item><title>Apache Hive : HiveServer2 Overview</title><link>https://hive.apache.org/docs/latest/user/hiveserver2-overview/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/hiveserver2-overview/</guid><description>Apache Hive : HiveServer2 Overview Apache Hive : HiveServer2 Overview Introduction HS2 Architecture Server Transport Protocol Processor Dependencies of HS2 JDBC Client Source Code Description Server Side Client Side Interaction between Client and Server Resources Introduction HiveServer2 (HS2) is a service that enables clients to execute queries against Hive. HiveServer2 is the successor to HiveServer1 which has been deprecated. HS2 supports multi-client concurrency and authentication.</description></item><item><title>Apache Hive : HiveServer2 Thrift API</title><link>https://hive.apache.org/development/desingdocs/hiveserver2-thrift-api/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hiveserver2-thrift-api/</guid><description>Apache Hive : HiveServer2 Thrift API Introduction This document is a proposal for a new HiveServer2 Thrift API.
Motivations Concurrency Many users have reported that the current HiveServer implementation has concurrency bugs (for example, see HIVE-80). In fact, it&amp;rsquo;s impossible for HiveServer to support concurrent connections using the current Thrift API, a result of the fact that Thrift doesn&amp;rsquo;t provide server-side access to connection handles. Since the current API does not provide explicit support for sessions or connections, HiveServer has no way of mapping incoming requests to client sessions, which makes it impossible for HiveServer to maintain session state in between calls.</description></item><item><title>Apache Hive : Howl</title><link>https://hive.apache.org/development/desingdocs/howl/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/howl/</guid><description>Apache Hive : Howl This page collects some pointers to resources about Howl (an effort to create a metastore for all of Hadoop) and how its first incarnation is being built by reusing and extending Hive&amp;rsquo;s metastore and CLI.
Howl wiki Yahoo group for Howl developers (including mailing list archive) Howl source code at github Howl CLI functional spec Original plans for Owl (predecessor to Howl)</description></item><item><title>Apache Hive : HowToCommit</title><link>https://hive.apache.org/community/resources/howtocommit/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/howtocommit/</guid><description>Apache Hive : Guide for Committers This page contains guidelines for committers of the Apache Hive project. (If you&amp;rsquo;re currently a contributor, and are interested in how we add new committers, read BecomingACommitter)
Apache Hive : Guide for Committers New committers Review Reject PreCommit runs, and committing patches Commit Backporting commits to previous branches Dialog New committers New committers are encouraged to first read Apache&amp;rsquo;s generic committer documentation:</description></item><item><title>Apache Hive : HowToContribute</title><link>https://hive.apache.org/community/resources/howtocontribute/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/howtocontribute/</guid><description>Apache Hive : How to Contribute This page describes the mechanics of how to contribute software to Apache Hive. For ideas about what you might contribute, please see open tickets in Jira.
Apache Hive : How to Contribute Getting the Source Code Becoming a Contributor Making Changes Coding Conventions Understanding Maven Understanding Hive Branches Hadoop Dependencies Unit Tests Add a Unit Test Submitting a PR Fetching a PR from Github Contributing Your Work JIRA Guidelines Generating Thrift Code See Also Getting the Source Code First of all, you need the Hive source code.</description></item><item><title>Apache Hive : HowToRelease</title><link>https://hive.apache.org/community/resources/howtorelease/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/howtorelease/</guid><description>Apache Hive : HowToRelease Apache Hive : HowToRelease Introduction Storage API Release Storage API Prepare Master Branch Storage API Branching Making Storage API Release Artifacts Publishing the Storage API Artifacts Preparing Branch for further development Cleaning Up Storage API Artifacts Hive Release Preparation Branching Updating Release Branch Building Voting Verifying the Release Candidate Publishing Archive old releases Preparing Branch for Future Maintenance Release See Also Introduction This page is prepared for Hive committers.</description></item><item><title>Apache Hive : Hybrid Hybrid Grace Hash Join, v1.0</title><link>https://hive.apache.org/development/desingdocs/hybrid-grace-hash-join-v1-0/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/hybrid-grace-hash-join-v1-0/</guid><description>Apache Hive : Hybrid Hybrid Grace Hash Join, v1.0 Apache Hive : Hybrid Hybrid Grace Hash Join, v1.0 Overview Scope Notation and Assumptions Brief Review on Hash Join Algorithms Simple Hash Join GRACE Hash Join Hybrid GRACE Hash Join Hash Join in Hive Motivation for “Hybrid Hybrid GRACE Hash Join” Algorithm Recursive Hashing and Spilling Skewed Data Distribution Bloom Filter References Overview We are proposing an enhanced hash join algorithm called “hybrid hybrid grace hash join”.</description></item><item><title>Apache Hive : IndexDev</title><link>https://hive.apache.org/development/desingdocs/indexdev/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/indexdev/</guid><description>Apache Hive : Indexes Apache Hive : Indexes Indexing Is Removed since 3.0 Introduction Scope CREATE INDEX Metastore Model Metastore Upgrades REBUILD DROP INDEX Plugin Interface Reference Implementation TBD Current Status (JIRA) Indexing Is Removed since 3.0 There are alternate options which might work similarily to indexing:
Materialized views with automatic rewriting can result in very similar results. Hive 2.3.0 adds support for materialzed views.</description></item><item><title>Apache Hive : IndexDev Bitmap</title><link>https://hive.apache.org/development/desingdocs/indexdev-bitmap/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/indexdev-bitmap/</guid><description>Apache Hive : Bitmap Indexing Apache Hive : Bitmap Indexing Introduction Approach Proposal First implementation Second iteration Example Introduction This document explains the proposed design for adding a bitmap index handler (https://issues.apache.org/jira/browse/HIVE-1803).
Bitmap indexing (http://en.wikipedia.org/wiki/Bitmap_index) is a standard technique for indexing columns with few distinct
values, such as gender.
Approach We want to develop a bitmap index that can reuse as much of the existing Compact Index code as possible.</description></item><item><title>Apache Hive : JDBC Storage Handler</title><link>https://hive.apache.org/docs/latest/user/jdbc-storage-handler/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/jdbc-storage-handler/</guid><description>Apache Hive : JDBC Storage Handler Apache Hive : JDBC Storage Handler Syntax Table Properties Supported Data Type Column/Type Mapping Auto Shipping Securing Password Partitioning Computation Pushdown Using a Non-default Schema MariaDB MS SQL Oracle PostgreSQL Syntax JdbcStorageHandler supports reading from jdbc data source in Hive. Currently writing to a jdbc data source is not supported. To use JdbcStorageHandler, you need to create an external table using JdbcStorageHandler.</description></item><item><title>Apache Hive : Kudu Integration</title><link>https://hive.apache.org/docs/latest/user/kudu-integration/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/kudu-integration/</guid><description>Apache Hive : Kudu Integration Apache Hive : Kudu Integration Overview Implementation Hive Configuration Table Creation Impala Tables Data Ingest Examples Overview Apache Kudu is a an Open Source data storage engine that makes fast analytics on fast and changing data easy. Implementation The initial implementation was added to Hive 4.0 in HIVE-12971 and is designed to work with Kudu 1.</description></item><item><title>Apache Hive : LanguageManual</title><link>https://hive.apache.org/docs/latest/language/languagemanual/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual/</guid><description>Apache Hive : LanguageManual This is the Hive Language Manual. For other Hive documentation, see the Hive wiki&amp;rsquo;s Home page.
Commands and CLIs
Commands Hive CLI (old) Beeline CLI (new) Variable Substitution HCatalog CLI File Formats
Avro Files ORC Files Parquet Compressed Data Storage LZO Compression Data Types
Data Definition Statements
DDL Statements Bucketed Tables Write Ordering (Type-Native &amp;amp; Z-Order) Statistics (Analyze and Describe) Indexes Archiving Data Manipulation Statements</description></item><item><title>Apache Hive : LanguageManual Archiving</title><link>https://hive.apache.org/docs/latest/language/languagemanual-archiving/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-archiving/</guid><description>Apache Hive : LanguageManual Archiving Archiving for File Count Reduction.
Apache Hive : LanguageManual Archiving Overview Settings Usage Archive Unarchive Cautions and Limitations Under the Hood Overview Due to the design of HDFS, the number of files in the filesystem directly affects the memory consumption in the namenode. While normally not a problem for small clusters, memory usage may hit the limits of accessible memory on a single machine when there are &amp;gt;50-100 million files.</description></item><item><title>Apache Hive : LanguageManual Authorization</title><link>https://hive.apache.org/docs/latest/language/languagemanual-authorization/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-authorization/</guid><description>Apache Hive : LanguageManual Authorization Apache Hive : LanguageManual Authorization Introduction Hive Authorization Options Use Cases Overview of Authorization Modes Addressing Authorization Needs of Multiple Use Cases Explain Authorization More Information Introduction Note that this documentation is referring to Authorization which is verifying if a user has permission to perform a certain action, and not about Authentication (verifying the identity of the user).</description></item><item><title>Apache Hive : LanguageManual Cli</title><link>https://hive.apache.org/docs/latest/language/languagemanual-cli/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-cli/</guid><description>Apache Hive : LanguageManual Hive CLI $HIVE_HOME/bin/hive is a shell utility which can be used to run Hive queries in either interactive or batch mode.
Apache Hive : LanguageManual Hive CLI Deprecation in favor of Beeline CLI Hive Command Line Options Examples The hiverc File Logging Tool to Clear Dangling Scratch Directories Hive Batch Mode Commands Hive Interactive Shell Commands Hive Resources HCatalog CLI Deprecation in favor of Beeline CLI HiveServer2 (introduced in Hive 0.</description></item><item><title>Apache Hive : LanguageManual Commands</title><link>https://hive.apache.org/docs/latest/language/languagemanual-commands/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-commands/</guid><description>Apache Hive : LanguageManual Commands Commands are non-SQL statements such as setting a property or adding a resource. They can be used in HiveQL scripts or directly in the CLI or Beeline.
Command Description quit exit Use quit or exit to leave the interactive shell. reset Resets the configuration to the default values (as of Hive 0.10: see HIVE-3202). Any configuration parameters that were set using the set command or -hiveconf parameter in hive commandline will get reset to default value.</description></item><item><title>Apache Hive : LanguageManual DDL</title><link>https://hive.apache.org/docs/latest/language/languagemanual-ddl/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-ddl/</guid><description>Apache Hive : LanguageManual DDL Apache Hive : LanguageManual DDL Overview Keywords, Non-reserved Keywords and Reserved Keywords Create/Drop/Alter/Use Database Create Database Drop Database Alter Database Use Database Create/Drop/Alter Connector Create Connector Drop Connector Alter Connector Create/Drop/Truncate Table Create Table Drop Table Truncate Table Alter Table/Partition/Column Alter Table Alter Partition Alter Either Table or Partition Alter Column Create/Drop/Alter View Create View Drop View Alter View Properties Alter View As Select Create/Drop/Alter Materialized View Create Materialized View Drop Materialized View Alter Materialized View Create/Drop/Alter Index Create Index Drop Index Alter Index Create/Drop Macro Create Temporary Macro Drop Temporary Macro Create/Drop/Reload Function Temporary Functions Permanent Functions Create/Drop/Grant/Revoke Roles and Privileges Show Show Databases Show Connectors Show Tables/Views/Materialized Views/Partitions/Indexes Show Columns Show Functions Show Granted Roles and Privileges Show Locks Show Conf Show Transactions Show Compactions Describe Describe Database Describe Dataconnector Describe Table/View/Materialized View/Column Describe Partition Hive 2.</description></item><item><title>Apache Hive : LanguageManual DDL BucketedTables</title><link>https://hive.apache.org/docs/latest/language/languagemanual-ddl-bucketedtables/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-ddl-bucketedtables/</guid><description>Apache Hive : LanguageManual DDL BucketedTables This is a brief example on creating and populating bucketed tables. (For another example, see Bucketed Sorted Tables.)
Bucketed tables are fantastic in that they allow much more efficient sampling than do non-bucketed tables, and they may later allow for time saving operations such as mapside joins. However, the bucketing specified at table creation is not enforced when the table is written to, and so it is possible for the table&amp;rsquo;s metadata to advertise properties which are not upheld by the table&amp;rsquo;s actual layout.</description></item><item><title>Apache Hive : LanguageManual DML</title><link>https://hive.apache.org/docs/latest/language/languagemanual-dml/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-dml/</guid><description>Apache Hive : LanguageManual DML Hive Data Manipulation Language Apache Hive : LanguageManual DML Hive Data Manipulation Language Loading files into tables Inserting data into Hive Tables from queries Writing data into the filesystem from queries Inserting values into tables from SQL Update Delete Merge Loading files into tables Hive does not do any transformation while loading data into tables.</description></item><item><title>Apache Hive : LanguageManual Explain</title><link>https://hive.apache.org/docs/latest/language/languagemanual-explain/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-explain/</guid><description>Apache Hive : LanguageManual Explain Apache Hive : LanguageManual Explain EXPLAIN Syntax Example The CBO Clause The AST Clause The DEPENDENCY Clause The AUTHORIZATION Clause The LOCKS Clause The VECTORIZATION Clause The ANALYZE Clause User-level Explain Output EXPLAIN Syntax Hive provides an EXPLAIN command that shows the execution plan for a query. The syntax for this statement is as follows:</description></item><item><title>Apache Hive : LanguageManual GroupBy</title><link>https://hive.apache.org/docs/latest/language/languagemanual-groupby/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-groupby/</guid><description>Apache Hive : LanguageManual GroupBy Apache Hive : LanguageManual GroupBy Group By Syntax Simple Examples Select statement and group by clause Advanced Features Multi-Group-By Inserts Map-side Aggregation for Group By Grouping Sets, Cubes, Rollups, and the GROUPING__ID Function Group By Syntax groupByClause: GROUP BY groupByExpression (, groupByExpression)* groupByExpression: expression groupByQuery: SELECT expression (, expression)* FROM src groupByClause? In groupByExpression columns are specified by name, not by position number.</description></item><item><title>Apache Hive : LanguageManual ImportExport</title><link>https://hive.apache.org/docs/latest/language/languagemanual-importexport/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-importexport/</guid><description>Apache Hive : LanguageManual Import/Export Apache Hive : LanguageManual Import/Export Version information Overview Export Syntax Import Syntax Replication usage Examples Version information The EXPORT and IMPORT commands were added in Hive 0.8.0 (see HIVE-1918).
Replication extensions to the EXPORT and IMPORT commands were added in Hive 1.2.0 (see HIVE-7973 and Hive Replication Development).
Overview The EXPORT command exports the data of a table or partition, along with the metadata, into a specified output location.</description></item><item><title>Apache Hive : LanguageManual Indexing</title><link>https://hive.apache.org/docs/latest/language/languagemanual-indexing/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-indexing/</guid><description>Apache Hive : LanguageManual Indexing Apache Hive : LanguageManual Indexing Indexing Is Removed since 3.0 Overview of Hive Indexes Indexing Resources Configuration Parameters for Hive Indexes Simple Examples Indexing Is Removed since 3.0 There are alternate options which might work similarily to indexing:
Materialized views with automatic rewriting can result in very similar results. Hive 2.3.0 adds support for materialzed views.</description></item><item><title>Apache Hive : LanguageManual JoinOptimization</title><link>https://hive.apache.org/docs/latest/language/languagemanual-joinoptimization/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-joinoptimization/</guid><description>Apache Hive : LanguageManual Join Optimization Apache Hive : LanguageManual Join Optimization Improvements to the Hive Optimizer Star Join Optimization Star Schema Example Prior Support for MAPJOIN Enhancements for Star Joins Improvements to the Hive Optimizer Version
The join optimizations described here were added in Hive version 0.11.0. See HIVE-3784 and related JIRAs.
This document describes optimizations of Hive&amp;rsquo;s query execution planning to improve the efficiency of joins and reduce the need for user hints.</description></item><item><title>Apache Hive : LanguageManual Joins</title><link>https://hive.apache.org/docs/latest/language/languagemanual-joins/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-joins/</guid><description>Apache Hive : LanguageManual Joins Apache Hive : LanguageManual Joins Join Syntax Examples MapJoin Restrictions Join Optimization Predicate Pushdown in Outer Joins Enhancements in Hive Version 0.11 Join Syntax Hive supports the following syntax for joining tables:
join_table: table_reference [INNER] JOIN table_factor [join_condition] | table_reference {LEFT|RIGHT|FULL} [OUTER] JOIN table_reference join_condition | table_reference LEFT SEMI JOIN table_reference join_condition | table_reference CROSS JOIN table_reference [join_condition] (as of Hive 0.</description></item><item><title>Apache Hive : LanguageManual LateralView</title><link>https://hive.apache.org/docs/latest/language/languagemanual-lateralview/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-lateralview/</guid><description>Apache Hive : LanguageManual LateralView Apache Hive : LanguageManual LateralView Lateral View Syntax Description Example Multiple Lateral Views Outer Lateral Views Lateral View Syntax lateralView: LATERAL VIEW udtf(expression) tableAlias AS columnAlias (',' columnAlias)* fromClause: FROM baseTable (lateralView)* Description Lateral view is used in conjunction with user-defined table generating functions such as explode(). As mentioned in Built-in Table-Generating Functions, a UDTF generates zero or more output rows for each input row.</description></item><item><title>Apache Hive : LanguageManual LZO</title><link>https://hive.apache.org/docs/latest/language/languagemanual-lzo/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-lzo/</guid><description>Apache Hive : LanguageManual LZO Compression Apache Hive : LanguageManual LZO Compression General LZO Concepts Prerequisites Lzo/Lzop Installations core-site.xml Table Definition Hive Queries Option 1: Directly Create LZO Files Option 2: Write Custom Java to Create LZO Files General LZO Concepts LZO is a lossless data compression library that favors speed over compression ratio. See http://www.oberhumer.com/opensource/lzo and http://www.</description></item><item><title>Apache Hive : LanguageManual ORC</title><link>https://hive.apache.org/docs/latest/language/languagemanual-orc/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-orc/</guid><description>Apache Hive : LanguageManual ORC Apache Hive : LanguageManual ORC ORC Files ORC File Format File Structure Stripe Structure HiveQL Syntax Serialization and Compression Integer Column Serialization String Column Serialization Compression ORC File Dump Utility ORC Configuration Parameters ORC Format Specification Attachments: ORC Files ORC File Format Version
Introduced in Hive version 0.11.0.
The Optimized Row Columnar (ORC) file format provides a highly efficient way to store Hive data.</description></item><item><title>Apache Hive : LanguageManual Sampling</title><link>https://hive.apache.org/docs/latest/language/languagemanual-sampling/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-sampling/</guid><description>Apache Hive : LanguageManual Sampling Apache Hive : LanguageManual Sampling Sampling Syntax Sampling Bucketized Table Block Sampling Sampling Syntax Sampling Bucketized Table table_sample: TABLESAMPLE (BUCKET x OUT OF y [ON colname]) The TABLESAMPLE clause allows the users to write queries for samples of the data instead of the whole table. The TABLESAMPLE clause can be added to any table in the FROM clause.</description></item><item><title>Apache Hive : LanguageManual Select</title><link>https://hive.apache.org/docs/latest/language/languagemanual-select/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-select/</guid><description>Apache Hive : LanguageManual Select Apache Hive : LanguageManual Select Select Syntax WHERE Clause ALL and DISTINCT Clauses Partition Based Queries HAVING Clause LIMIT Clause REGEX Column Specification More Select Syntax Select Syntax [WITH CommonTableExpression (, CommonTableExpression)*] (Note: Only available starting with Hive 0.13.0) SELECT [ALL | DISTINCT] select_expr, select_expr, ... FROM table_reference [WHERE where_condition] [GROUP BY col_list] [ORDER BY col_list] [CLUSTER BY col_list | [DISTRIBUTE BY col_list] [SORT BY col_list] ] [LIMIT [offset,] rows] A SELECT statement can be part of a union query or a subquery of another query.</description></item><item><title>Apache Hive : LanguageManual SortBy</title><link>https://hive.apache.org/docs/latest/language/languagemanual-sortby/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-sortby/</guid><description>Apache Hive : LanguageManual SortBy Apache Hive : LanguageManual SortBy Order, Sort, Cluster, and Distribute By Syntax of Order By Syntax of Sort By Difference between Sort By and Order By Setting Types for Sort By Syntax of Cluster By and Distribute By Order, Sort, Cluster, and Distribute By This describes the syntax of SELECT clauses ORDER BY, SORT BY, CLUSTER BY, and DISTRIBUTE BY.</description></item><item><title>Apache Hive : LanguageManual SubQueries</title><link>https://hive.apache.org/docs/latest/language/languagemanual-subqueries/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-subqueries/</guid><description>Apache Hive : LanguageManual SubQueries Apache Hive : LanguageManual SubQueries Subqueries in the FROM Clause Subqueries in the WHERE Clause Subqueries in the FROM Clause SELECT ... FROM (subquery) name ... SELECT ... FROM (subquery) AS name ... (Note: Only valid starting with Hive 0.13.0) Hive supports subqueries only in the FROM clause (through Hive 0.12). The subquery has to be given a name because every table in a FROM clause must have a name.</description></item><item><title>Apache Hive : LanguageManual Transform</title><link>https://hive.apache.org/docs/latest/language/languagemanual-transform/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-transform/</guid><description>Apache Hive : LanguageManual Transform Apache Hive : LanguageManual Transform Transform/Map-Reduce Syntax Schema-less Map-reduce Scripts Typing the output of TRANSFORM Transform/Map-Reduce Syntax Users can also plug in their own custom mappers and reducers in the data stream by using features natively supported in the Hive language. e.g. in order to run a custom mapper script - map_script - and a custom reducer script - reduce_script - the user can issue the following command which uses the TRANSFORM clause to embed the mapper and the reducer scripts.</description></item><item><title>Apache Hive : LanguageManual Types</title><link>https://hive.apache.org/docs/latest/language/languagemanual-types/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-types/</guid><description>Apache Hive : LanguageManual Data Types Apache Hive : LanguageManual Data Types Overview Numeric Types Date/Time Types String Types Misc Types Complex Types Column Types Integral Types (TINYINT, SMALLINT, INT/INTEGER, BIGINT) Strings Varchar Char Timestamps Dates Intervals Decimals Union Types Literals Floating Point Types Handling of NULL Values Change Types Allowed Implicit Conversions Overview This lists all supported data types in Hive.</description></item><item><title>Apache Hive : LanguageManual UDF</title><link>https://hive.apache.org/docs/latest/language/languagemanual-udf/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-udf/</guid><description>Apache Hive : LanguageManual Operators and User-Defined Functions Apache Hive : LanguageManual Operators and User-Defined Functions Overview Built-in Operators Operators Precedences Relational Operators Arithmetic Operators Logical Operators String Operators Complex Type Constructors Operators on Complex Types Built-in Functions Mathematical Functions Collection Functions Type Conversion Functions Date Functions Conditional Functions String Functions Data Masking Functions Misc. Functions Built-in Aggregate Functions (UDAF) Built-in Table-Generating Functions (UDTF) Usage Examples explode posexplode json_tuple parse_url_tuple GROUPing and SORTing on f(column) Utility Functions UDF internals Creating Custom UDFs Attachments: Overview All Hive keywords are case-insensitive, including the names of Hive operators and functions.</description></item><item><title>Apache Hive : LanguageManual Union</title><link>https://hive.apache.org/docs/latest/language/languagemanual-union/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-union/</guid><description>Apache Hive : LanguageManual Union Apache Hive : LanguageManual Union Union Syntax Union Syntax select_statement UNION [ALL | DISTINCT] select_statement UNION [ALL | DISTINCT] select_statement ... UNION is used to combine the result from multiple SELECT statements into a single result set.
Hive versions prior to 1.2.0 only support UNION ALL (bag union), in which duplicate rows are not eliminated.</description></item><item><title>Apache Hive : LanguageManual VariableSubstitution</title><link>https://hive.apache.org/docs/latest/language/languagemanual-variablesubstitution/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-variablesubstitution/</guid><description>Apache Hive : LanguageManual VariableSubstitution Apache Hive : LanguageManual VariableSubstitution Introduction Using Variables Substitution During Query Construction Disabling Variable Substitution Introduction Hive is used for batch and interactive queries. Variable Substitution allows for tasks such as separating environment-specific configuration variables from code.
The Hive variable substitution mechanism was designed to avoid some of the code that was getting baked into the scripting language on top of Hive.</description></item><item><title>Apache Hive : LanguageManual VirtualColumns</title><link>https://hive.apache.org/docs/latest/language/languagemanual-virtualcolumns/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-virtualcolumns/</guid><description>Apache Hive : LanguageManual VirtualColumns Apache Hive : LanguageManual VirtualColumns Virtual Columns Simple Examples Virtual Columns Hive 0.8.0 provides support for two virtual columns:
One is INPUT__FILE__NAME, which is the input file&amp;rsquo;s name for a mapper task.
the other is BLOCK__OFFSET__INSIDE__FILE, which is the current global file position.
For block compressed file, it is the current block&amp;rsquo;s file offset, which is the current block&amp;rsquo;s first byte&amp;rsquo;s file offset.</description></item><item><title>Apache Hive : LanguageManual WindowingAndAnalytics</title><link>https://hive.apache.org/docs/latest/language/languagemanual-windowingandanalytics/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-windowingandanalytics/</guid><description>Apache Hive : LanguageManual WindowingAndAnalytics Apache Hive : LanguageManual WindowingAndAnalytics Enhancements to Hive QL Examples Enhancements to Hive QL Introduced in Hive version 0.11.
This section introduces the Hive QL enhancements for windowing and analytics functions. See &amp;ldquo;Windowing Specifications in HQL&amp;rdquo; (attached to HIVE-4197) for details. HIVE-896 has more information, including links to earlier documentation in the initial comments.</description></item><item><title>Apache Hive : LanguageManual XPathUDF</title><link>https://hive.apache.org/docs/latest/language/languagemanual-xpathudf/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/languagemanual-xpathudf/</guid><description>Apache Hive : LanguageManual XPathUDF Documentation for Built-In User-Defined Functions Related To XPath
UDFs xpath, xpath_short, xpath_int, xpath_long, xpath_float, xpath_double, xpath_number, xpath_string Functions for parsing XML data using XPath expressions. Since version: 0.6.0 Overview The xpath family of UDFs are wrappers around the Java XPath library javax.xml.xpath provided by the JDK. The library is based on the XPath 1.0 specification. Please refer to http://java.sun.com/javase/6/docs/api/javax/xml/xpath/package-summary.html for detailed information on the Java XPath library.</description></item><item><title>Apache Hive : Links</title><link>https://hive.apache.org/development/desingdocs/links/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/links/</guid><description>Apache Hive : Links Motivation Today, the infrastructure provided by Hive allows for the setup of a single shared warehouse and the authorization model allows for access control within this warehouse if needed. Growth beyond a single warehouse (when datacenter capacity limits are reached) OR separation of capacity usage and allocation requires the creation of multiple warehouses with each warehouse mapping to it&amp;rsquo;s own Hive metastore. Let&amp;rsquo;s define the term physical warehouse to map to a single Hive metastore, the Hadoop cluster it maps to and the data in it.</description></item><item><title>Apache Hive : ListBucketing</title><link>https://hive.apache.org/development/desingdocs/listbucketing/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/listbucketing/</guid><description>Apache Hive : ListBucketing Apache Hive : ListBucketing Goal Basic Partitioning List Bucketing Skewed Table vs. List Bucketing Table List Bucketing Validation DDL DML Alter Table Concatenate Hive Enhancements Create Table Alter Table Design Implementation Goal The top level problem is as follows:
There are many tables of the following format:
create table T(a, b, c, .</description></item><item><title>Apache Hive : Literals</title><link>https://hive.apache.org/docs/latest/language/literals/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/literals/</guid><description>Apache Hive : Literals Literals Integral types Integral literals are assumed to be INT by default, unless the number exceeds the range of INT in which case it is interpreted as a BIGINT, or if one of the following postfixes is present on the number.
Type Postfix Example TINYINT Y 100Y SMALLINT S 100S BIGINT L 100L String types String literals can be expressed with either single quotes (') or double quotes (&amp;quot;).</description></item><item><title>Apache Hive : LLAP</title><link>https://hive.apache.org/development/desingdocs/llap/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/llap/</guid><description>Apache Hive : LLAP Live Long And Process (LLAP) functionality was added in Hive 2.0 (HIVE-7926 and associated tasks). HIVE-9850 links documentation, features, and issues for this enhancement. For configuration of LLAP, see the LLAP Section of Configuration Properties.
Apache Hive : LLAP Overview Persistent Daemon Execution Engine Query Fragment Execution I/O Caching Workload Management ACID Support Security Monitoring Web Services SLIDER on YARN Deployment LLAP Status Resources Attachments: Overview Hive has become significantly faster thanks to various features and improvements that were built by the community in recent years, including Tez and Cost-based-optimization.</description></item><item><title>Apache Hive : Locking</title><link>https://hive.apache.org/development/desingdocs/locking/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/locking/</guid><description>Apache Hive : Locking Apache Hive : Locking Hive Concurrency Model Use Cases Turn Off Concurrency Debugging Configuration Locking in Hive Transactions Hive Concurrency Model Use Cases Concurrency support (http://issues.apache.org/jira/browse/HIVE-1293) is a must in databases and their use cases are well understood. At a minimum, we want to support concurrent readers and writers whenever possible. It would be useful to add a mechanism to discover the current locks which have been acquired.</description></item><item><title>Apache Hive : Managed vs. External Tables</title><link>https://hive.apache.org/docs/latest/language/managed-vs-external-tables/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/managed-vs-external-tables/</guid><description>Apache Hive : Managed vs. External Tables Hive fundamentally knows two different types of tables:
Managed (Internal) External Introduction This document lists some of the differences between the two but the fundamental difference is that Hive assumes that it owns the data for managed tables. That means that the data, its properties and data layout will and can only be changed via Hive command. The data still lives in a normal file system and nothing is stopping you from changing it without telling Hive about it.</description></item><item><title>Apache Hive : Manual Installation</title><link>https://hive.apache.org/docs/latest/admin/manual-installation/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/manual-installation/</guid><description>Apache Hive : Manual Installation Apache Hive : Manual Installation Installing, configuring and running Hive Prerequisites Install the prerequisites Java 8 Maven: Protobuf Hadoop Tez Extra hadoop configurations to make everything working Installing Hive from a Tarball Installing from Source Code Installing with old version hadoop(greater than or equal 3.1.0) Next Steps Beeline CLI Hive Metastore HCatalog and WebHCat HCatalog WebHCat (Templeton) Installing, configuring and running Hive You can install a stable release of Hive by downloading and unpacking a tarball, or you can download the source code and build Hive using Maven (release 3.</description></item><item><title>Apache Hive : MapJoin and Partition Pruning</title><link>https://hive.apache.org/development/desingdocs/mapjoin-and-partition-pruning/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/mapjoin-and-partition-pruning/</guid><description>Apache Hive : MapJoin and Partition Pruning Apache Hive : MapJoin and Partition Pruning Overview Problem Proposed Solution Possible Extensions Optimization Details Compile Time Runtime Pseudo Code Overview In Hive, Map-Join is a technique that materializes data for all tables involved in the join except for the largest table and then large table is streamed over the materialized data from small tables.</description></item><item><title>Apache Hive : MapJoinOptimization</title><link>https://hive.apache.org/development/desingdocs/mapjoinoptimization/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/mapjoinoptimization/</guid><description>Apache Hive : MapJoinOptimization Apache Hive : MapJoinOptimization 1. Map Join Optimization 1.1 Using Distributed Cache to Propagate Hashtable File 1.2 Removing JDBM 1.3 Performance Evaluation 2. Converting Join into Map Join Automatically 2.1 New Join Execution Flow 2.2 Resolving the Join Operation at Run Time 2.3 Backup Task 2.4 Performance Evaluation 1. Map Join Optimization 1.1 Using Distributed Cache to Propagate Hashtable File Previously, when 2 large data tables need to do a join, there will be 2 different Mappers to sort these tables based on the join key and emit an intermediate file, and the Reducer will take the intermediate file as input file and do the real join work.</description></item><item><title>Apache Hive : Materialized views</title><link>https://hive.apache.org/docs/latest/language/materialized-views/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/materialized-views/</guid><description>Apache Hive : Materialized views This page documents the work done for the supporting materialized views in Apache Hive.
Apache Hive : Materialized views Version information Objectives Management of materialized views in Hive Materialized views creation Other operations for materialized view management Materialized view-based query rewriting Example 1 Example 2 Example 3 Materialized view maintenance Materialized view lifecycle Open issues (JIRA) Version information Materialized views support is introduced in Hive 3.</description></item><item><title>Apache Hive : Materialized views in Hive</title><link>https://hive.apache.org/docs/latest/user/materialized-views-in-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/materialized-views-in-hive/</guid><description>Apache Hive : Materialized views in Hive Objectives Traditionally, one of the most powerful techniques used to accelerate query processing in data warehouses is the pre-computation of relevant summaries or materialized views.
The initial implementation focuses on introducing materialized views and automatic query rewriting based on those materializations in the project. In particular, materialized views can be stored natively in Hive or in other systems such as Druid using custom storage handlers, and they can seamlessly exploit new exciting Hive features such as LLAP acceleration.</description></item><item><title>Apache Hive : MetaStore API Tests</title><link>https://hive.apache.org/community/resources/metastore-api-tests/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/metastore-api-tests/</guid><description>Apache Hive : MetaStore API Tests IMetaStoreClient Tests IMetaStoreClient Tests One option for Java clients to access the MetaStore is to connect through the IMetaStoreClient interface implementations.
To ensure that the IMetaStoreClient implementations provide the same API we created a set of tests to validate their workings.
Currently the following implementations are tested:
EmbeddedMetaStore – when the MetaStore is running in the same thread, and in process communication is used.</description></item><item><title>Apache Hive : Metastore TLP Proposal</title><link>https://hive.apache.org/development/desingdocs/metastore-tlp-proposal/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/metastore-tlp-proposal/</guid><description>Apache Hive : Metastore TLP Proposal Summary of the Proposal from the Email Hive’s metastore has long been used by other projects in the Hadoop ecosystem to store and access metadata. Apache Impala, Apache Spark, Apache Drill, Presto, and other systems all use Hive’s metastore. Some, like Impala and Presto, can use it as their own metadata system with the rest of Hive not present.
This sharing is excellent for the ecosystem.</description></item><item><title>Apache Hive : MultiDelimitSerDe</title><link>https://hive.apache.org/docs/latest/user/multidelimitserde/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/multidelimitserde/</guid><description>Apache Hive : MultiDelimitSerDe Introduction Introduced in HIVE-5871, MultiDelimitSerDe allows user to specify multiple-character string as the field delimiter when creating a table.
Version Hive 0.14.0 and later.
Hive QL Syntax You can use MultiDelimitSerDe in a create table statement like this:
CREATE TABLE test ( id string, hivearray array&amp;lt;binary&amp;gt;, hivemap map&amp;lt;string,int&amp;gt;) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.MultiDelimitSerDe' WITH SERDEPROPERTIES (&amp;quot;field.delim&amp;quot;=&amp;quot;[,]&amp;quot;,&amp;quot;collection.delim&amp;quot;=&amp;quot;:&amp;quot;,&amp;quot;mapkey.delim&amp;quot;=&amp;quot;@&amp;quot;); where field.delim is the field delimiter, collection.delim and mapkey.delim is the delimiter for collection items and key value pairs, respectively.</description></item><item><title>Apache Hive : OperatorsAndFunctions</title><link>https://hive.apache.org/docs/latest/language/operatorsandfunctions/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/operatorsandfunctions/</guid><description>Apache Hive : OperatorsAndFunctions Hive Operators and Functions Hive Plug-in Interfaces - User-Defined Functions and SerDes
Guide to Hive Operators and Functions
Reflect UDF Generic UDAF Case Study Functions for Statistics and Data Mining</description></item><item><title>Apache Hive : OuterJoinBehavior</title><link>https://hive.apache.org/development/desingdocs/outerjoinbehavior/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/outerjoinbehavior/</guid><description>Apache Hive : OuterJoinBehavior Hive Outer Join Behavior Apache Hive : OuterJoinBehavior Hive Outer Join Behavior Definitions Predicate Pushdown Rules Hive Implementation Examples Case J1: Join Predicate on Preserved Row Table Case J2: Join Predicate on Null Supplying Table Case W1: Where Predicate on Preserved Row Table Case W2: Where Predicate on Null Supplying Table This document is based on a writeup of DB2 Outer Join Behavior.</description></item><item><title>Apache Hive : Parquet</title><link>https://hive.apache.org/docs/latest/user/parquet/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/parquet/</guid><description>Apache Hive : Parquet Parquet is supported by a plugin in Hive 0.10, 0.11, and 0.12 and natively in Hive 0.13 and later.
Apache Hive : Parquet Introduction Native Parquet Support Hive 0.10, 0.11, and 0.12 Hive 0.13 HiveQL Syntax Hive 0.10 - 0.12 Hive 0.13 and later Versions and Limitations Hive 0.13.0 Hive 0.14.0 Hive 1.1.0 Hive 1.2.0 Resources Introduction Parquet (http://parquet.</description></item><item><title>Apache Hive : Partition Filter Syntax</title><link>https://hive.apache.org/docs/latest/language/partition-filter-syntax/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/partition-filter-syntax/</guid><description>Apache Hive : Partition Filter Syntax Example: for a table having partition keys country and state, one could construct the following filter:
country = &amp;quot;USA&amp;quot; AND (state = &amp;quot;CA&amp;quot; OR state = &amp;quot;AZ&amp;quot;)
In particular notice that it is possible to nest sub-expressions within parentheses.
The following operators are supported when constructing filters for partition columns (derived from HIVE-1862):
= &amp;lt; &amp;lt;= &amp;gt; &amp;gt;= &amp;lt;&amp;gt; AND OR LIKE (on keys of type string only, supports literal string template with &amp;lsquo;.</description></item><item><title>Apache Hive : PartitionedViews</title><link>https://hive.apache.org/development/desingdocs/partitionedviews/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/partitionedviews/</guid><description>Apache Hive : PartitionedViews This is a followup to ViewDev for adding partition-awareness to views.
Apache Hive : PartitionedViews Use Cases Approaches Syntax Metastore Strict Mode View Definition Changes Hook Information Use Cases An administrator wants to create a set of views as a table/column renaming layer on top of an existing set of base tables, without breaking any existing dependencies on those tables.</description></item><item><title>Apache Hive : Performance</title><link>https://hive.apache.org/community/resources/performance/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/performance/</guid><description>Apache Hive : Performance YourKit Java Profiler Collaboration To measure Hive&amp;rsquo;s internal performance, we use the YourKit Java Profiler. YourKit LLC is kindly supporting open source projects with its full-featured Java Profiler. The Hive project has been granted YourKit open source licenses to be used by its developers. For more information on this collaboration, ask on the developers mailing list.
 Benchmarks Here are some JIRA issues about benchmarks for Hive:</description></item><item><title>Apache Hive : Permission Inheritance in Hive</title><link>https://hive.apache.org/docs/latest/user/permission-inheritance-in-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/permission-inheritance-in-hive/</guid><description>Apache Hive : Permission Inheritance in Hive This document describes how attributes (permission, group, extended ACL&amp;rsquo;s) of files representing Hive data are determined.
HDFS Background When a file or directory is created, its owner is the user identity of the client process, and its group is inherited from parent (the BSD rule). Permissions are taken from default umask. Extended Acl&amp;rsquo;s are taken from parent unless they are set explicitly. Goals To reduce need to set fine-grain file security props after every operation, users may want the following Hive warehouse file/dir to auto-inherit security properties from their directory parents:</description></item><item><title>Apache Hive : PluginDeveloperKit</title><link>https://hive.apache.org/community/resources/plugindeveloperkit/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/plugindeveloperkit/</guid><description>Apache Hive : PluginDeveloperKit Hive Plugin Developer Kit This page explains Apache Hive&amp;rsquo;s Plugin Developer Kit, or PDK. This allows developers to build and test Hive plugins without having to set up a Hive source build; only a Hive binary release is needed.
The PDK is planned for inclusion in the Hive 0.8.0 release; until that is available, please download a recent snapshot build from Jenkins; make sure it includes HIVE-2244.</description></item><item><title>Apache Hive : PoweredBy</title><link>https://hive.apache.org/general/poweredby/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/general/poweredby/</guid><description>Apache Hive : PoweredBy Applications and organizations using Hive include (alphabetically):
Bizo We use Hive for reporting and ad hoc queries.
Chitika We use Hive for data mining and analysis on our 435M monthly global users.
CNET We use Hive for data mining, internal log analysis and ad hoc queries.
Digg We use Hive for data mining, internal log analysis, R&amp;amp;D, and reporting/analytics.
eHarmony We use Hadoop to store copies of internal log and dimension data sources and use it as a source for reporting/analytics and machine learning.</description></item><item><title>Apache Hive : Presentations</title><link>https://hive.apache.org/community/resources/presentations/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/presentations/</guid><description>Apache Hive : Presentations Apache Hive : Presentations Hive Meetups January 2016 Hive User Group Meetup November 2015 Hive Contributor Meetup April 2015 Hive Contributor Meetup Presentations February 2015 Hive User Meetup Presentation November 2013 Hive Contributors Meetup Presentations June 2013 Hadoop Summit Hive Meetup Presentations February 2013 Hive User Group Meetup June 2012 Hadoop Summit Hive Meetup Presentations November 2011 NYC Hive Meetup Presentations Older Hive Presentations Related Work Attachments: Hive Meetups January 2016 Hive User Group Meetup attachments/27362054/61337098-pptx attachments/27362054/61337312-ppsx attachments/27362054/61337398-ppsx Hive on Spark: now and future - Xuefu Zhang November 2015 Hive Contributor Meetup attachments/27362054/61329032-pptx attachments/27362054/61329033-pptx attachments/27362054/61329034-pptx attachments/27362054/61329036-pptx attachments/27362054/61329038-pptx attachments/27362054/61329039.</description></item><item><title>Apache Hive : Query ReExecution</title><link>https://hive.apache.org/docs/latest/user/query-reexecution/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/query-reexecution/</guid><description>Apache Hive : Query ReExecution Query reexecution provides a facility to re-run the query multiple times in case of an unfortunate event happens. Introduced in Hive 3.0 (HIVE-17626)
Apache Hive : Query ReExecution ReExecition strategies Overlay Reoptimize Operator Matching Configuration ReExecition strategies Overlay Enables to change the hive settings for all reexecutions which will be happening. It works by adding a configuration subtree as an overlay to the actual hive settings(reexec.</description></item><item><title>Apache Hive : Query Results Caching (HIVE-18513)</title><link>https://hive.apache.org/development/desingdocs/query-results-caching/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/query-results-caching/</guid><description>Apache Hive : Query Results Caching (HIVE-18513) Introduction This document proposes the addition of a query results cache to Hive. Caching query results allows a previously computed query result to be re-used in the event that the same query is processed by Hive. This can save both time and resources spent running the cluster tasks required for the query.
Background Existing behavior for Hive query processing (very simplified):
Hive query compilation takes the query string and produces a QueryPlan.</description></item><item><title>Apache Hive : RCFile</title><link>https://hive.apache.org/docs/latest/user/rcfile/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/rcfile/</guid><description>Apache Hive : RCFile RCFile (Record Columnar File) is a data placement structure designed for MapReduce-based data warehouse systems. Hive added the RCFile format in version 0.6.0.
RCFile stores table data in a flat file consisting of binary key/value pairs. It first partitions rows horizontally into row splits, and then it vertically partitions each row split in a columnar way. RCFile stores the metadata of a row split as the key part of a record, and all the data of a row split as the value part.</description></item><item><title>Apache Hive : RCFileCat</title><link>https://hive.apache.org/docs/latest/user/rcfilecat/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/rcfilecat/</guid><description>Apache Hive : RCFileCat $HIVE_HOME/bin/hive &amp;ndash;rcfilecat is a shell utility which can be used to print data or metadata from RC files.
Apache Hive : RCFileCat Data Metadata Data Prints out the rows stored in an RCFile, columns are tab separated and rows are newline separated.
Usage:
hive --rcfilecat [--start=start_offset] [--length=len] [--verbose] fileName --start=start_offset Start offset to begin reading in the file --length=len Length of data to read from the file --verbose Prints periodic stats about the data read, how many records, how many bytes, scan rate Metadata New in 0.</description></item><item><title>Apache Hive : Rebalance compaction</title><link>https://hive.apache.org/docs/latest/user/rebalance-compaction/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/rebalance-compaction/</guid><description>Apache Hive : Rebalance compaction In order to improve performance, Hive under the hood creates bucket files even for non-explicitly bucketed tables. Depending on the usage, the data loaded into these non-explicitly bucketed full-acid ORC tables may lead to unbalanced distribution, where some of the buckets are much larger (&amp;gt; 100 times) than the others. Unbalanced tables has performance penalty, as larger buckets takes more time to read. Rebalance compaction addresses this issue by equally redistributing the data among the implicit bucket files.</description></item><item><title>Apache Hive : ReflectUDF</title><link>https://hive.apache.org/docs/latest/language/reflectudf/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/reflectudf/</guid><description>Apache Hive : ReflectUDF Reflect (Generic) UDF A Java class and method often exists to handle the exact function a user would like to use in Hive. Rather than having to write a wrapper UDF to call this method, the majority of these methods can be called using reflect UDF. Reflect uses Java reflection to instantiate and call methods of objects; it can also call static functions. The method must return a primitive type or a type that Hive knows how to serialize.</description></item><item><title>Apache Hive : RelatedProjects</title><link>https://hive.apache.org/community/resources/relatedprojects/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/relatedprojects/</guid><description>Apache Hive : RelatedProjects Shark Shark is a fork of Apache Hive that uses Spark in place of MapReduce.
Apache Hivemall (incubating) Apache Hivemall is a scalable machine learning library for Apache Hive, Apache Spark, and Apache Pig.
Apache Sentry (incubating) Sentry is a role-based authorization system for Apache Hive.</description></item><item><title>Apache Hive : Replacing the Implementation of Hive CLI Using Beeline</title><link>https://hive.apache.org/docs/latest/user/replacing-the-implementation-of-hive-cli-using-beeline/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/replacing-the-implementation-of-hive-cli-using-beeline/</guid><description>Apache Hive : Replacing the Implementation of Hive CLI Using Beeline Apache Hive : Replacing the Implementation of Hive CLI Using Beeline Why Replace the Existing Hive CLI? Hive CLI Functionality Support Hive CLI Options Support Examples Hive CLI Interactive Shell Commands Support Hive CLI Configuration Support Performance Impacts Why Replace the Existing Hive CLI? Hive CLI is a legacy tool which had two main use cases.</description></item><item><title>Apache Hive : Replication</title><link>https://hive.apache.org/docs/latest/admin/replication/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/replication/</guid><description>Apache Hive : Replication Apache Hive : Replication Overview Potential Uses Prerequisites Limitations Configuration Typical Mode of Operation Replication to AWS/EMR/S3 Overview Hive Replication builds on the metastore event and ExIm features to provide a framework for replicating Hive metadata and data changes between clusters. There is no requirement for the source cluster and replica to run the same Hadoop distribution, Hive version, or metastore RDBMS.</description></item><item><title>Apache Hive : Running Yetus</title><link>https://hive.apache.org/community/resources/running-yetus/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/running-yetus/</guid><description>Apache Hive : Running Yetus Overview Yetus is added to Hive in release 3.0.0 to run checks on the new patches. See HIVE-15051.
There are several rules already defined by the community, but most of them are not enforced.
Yetus helps us by checking these rules for newly introduced errors. Note that Yetus checks only the changed part of the code. If any unchanged code contains errors, then Yetus will not report them, but all of the new code should conform to the rules.</description></item><item><title>Apache Hive : Scheduled Queries</title><link>https://hive.apache.org/docs/latest/language/scheduled-queries/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/scheduled-queries/</guid><description>Apache Hive : Scheduled Queries Apache Hive : Scheduled Queries Introduction Maintaining scheduled queries Create Scheduled query syntax Alter Scheduled query syntax Drop syntax scheduleSpecification syntax CRON based schedule syntax EVERY based schedule syntax ExecutedAs syntax enableSpecification syntax Defined AS syntax executeSpec syntax System tables/views information_schema.scheduled_queries information_schema.scheduled_executions Execution states Configuration Hive metastore related configuration HiveServer2 related configuration Examples Example 1 – basic example of using schedules Example 2 – analyze external table periodically Example 3 – materialized view rebuild Example 4 – Ingestion Introduction Executing statements periodically can be usefull in</description></item><item><title>Apache Hive : Security</title><link>https://hive.apache.org/development/desingdocs/security/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/security/</guid><description>Apache Hive : Security This page collects some resources and pointers for various efforts underway to add security features to Hive and related projects.
Authorization modes
The links below refer to the original Hive authorization mode. See Authorization for an overview of authorization modes, which include storage based authorization and SQL standards based authorization.
Thoughts on security from Venkatesh Howl&amp;rsquo;s approach for persisting and validating DDL authorization via HDFS permissions HIVE-1264: Hadoop security integration THRIFT-889: allow Kerberos authentication over Thrift HTTP THRIFT-876: SASL integration Howl Authorization Proposal Hive Authorization Proposal Note that Howl was the precursor to HCatalog.</description></item><item><title>Apache Hive : SerDe</title><link>https://hive.apache.org/docs/latest/user/serde/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/serde/</guid><description>Apache Hive : SerDe Apache Hive : SerDe SerDe Overview Built-in and Custom SerDes Built-in SerDes Custom SerDes HiveQL for SerDes Input Processing Output Processing Additional Notes SerDe Overview SerDe is short for Serializer/Deserializer. Hive uses the SerDe interface for IO. The interface handles both serialization and deserialization and also interpreting the results of serialization as individual fields for processing.</description></item><item><title>Apache Hive : Setting Up Hive with Docker</title><link>https://hive.apache.org/docs/latest/admin/setting-up-hive-with-docker/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/setting-up-hive-with-docker/</guid><description>Apache Hive : Setting Up Hive with Docker Introduction Run Apache Hive inside docker container in pseudo-distributed mode
STEP 1: Pull the image Pull the 4.0.0 image from Hive DockerHub docker pull apache/hive:4.0.0 STEP 2: Export the Hive version export HIVE_VERSION=4.0.0 STEP 3: Launch the HiveServer2 with an embedded Metastore. This is lightweight and for a quick setup, it uses Derby as metastore db.
docker run -d -p 10000:10000 -p 10002:10002 --env SERVICE_NAME=hiveserver2 --name hive4 apache/hive:${HIVE_VERSION} STEP 4: Connect to beeline docker exec -it hiveserver2 beeline -u 'jdbc:hive2://hiveserver2:10000/' Note: Launch Standalone Metastore To use standalone Metastore with Derby,</description></item><item><title>Apache Hive : Setting Up HiveServer2</title><link>https://hive.apache.org/docs/latest/admin/setting-up-hiveserver2/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/setting-up-hiveserver2/</guid><description>Apache Hive : Setting Up HiveServer2 HiveServer2 (HS2) is a server interface that enables remote clients to execute queries against Hive and retrieve the results (a more detailed intro here). The current implementation, based on Thrift RPC, is an improved version of HiveServer and supports multi-client concurrency and authentication. It is designed to provide better support for open API clients like JDBC and ODBC.
The Thrift interface definition language (IDL) for HiveServer2 is available at https://github.</description></item><item><title>Apache Hive : Skewed Join Optimization</title><link>https://hive.apache.org/development/desingdocs/skewed-join-optimization/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/skewed-join-optimization/</guid><description>Apache Hive : Skewed Join Optimization Optimizing Skewed Joins The Problem A join of 2 large data tables is done by a set of MapReduce jobs which first sorts the tables based on the join key and then joins them. The Mapper gives all rows with a particular key to the same Reducer.
e.g., Suppose we have table A with a key column, &amp;ldquo;id&amp;rdquo; which has values 1, 2, 3 and 4, and table B with a similar column, which has values 1, 2 and 3.</description></item><item><title>Apache Hive : Spatial queries</title><link>https://hive.apache.org/development/desingdocs/spatial-queries/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/spatial-queries/</guid><description>Apache Hive : Spatial queries Overview Hadoop-GIS is a scalable and high performance spatial data warehousing system for running large-scale spatial queries on Hadoop. Hadoop-GIS relies on RESQUE for spatial query processing. RESQUE is a internally developed tile based spatial query engine which is written in C++ and deployed as shared library.
Hive****SP: we integrate Hadoop-GIS with Hive, to support both structured queries and spatial queries with a unified query language (HQL) and interface (Hive Shell).</description></item><item><title>Apache Hive : SQL Standard Based Hive Authorization</title><link>https://hive.apache.org/docs/latest/language/sql-standard-based-hive-authorization/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/sql-standard-based-hive-authorization/</guid><description>Apache Hive : SQL Standard Based Hive Authorization Apache Hive : SQL Standard Based Hive Authorization Status of Hive Authorization before Hive 0.13 SQL Standards Based Hive Authorization (New in Hive 0.13) Restrictions on Hive Commands and Statements Privileges Objects Object Ownership Users and Roles Names of Users and Roles Role Management Commands Managing Object Privileges Object Privilege Commands Examples of Managing Object Privileges Privileges Required for Hive Operations Configuration For Hive 0.</description></item><item><title>Apache Hive : StarRocks Integration</title><link>https://hive.apache.org/docs/latest/user/starrocks-integration/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/starrocks-integration/</guid><description>Apache Hive : StarRocks Integration StarRocks has the ability to setup a Hive catalog which enables you to query data from Hive without loading data into StarRocks or creating external tables. See here for more information. </description></item><item><title>Apache Hive : StatisticsAndDataMining</title><link>https://hive.apache.org/docs/latest/language/statisticsanddatamining/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/statisticsanddatamining/</guid><description>Apache Hive : Statistics and Data Mining This page is the secondary documentation for the slightly more advanced statistical and data mining functions that are being integrated into Hive, and especially the functions that warrant more than one-line descriptions.
Apache Hive : Statistics and Data Mining ngrams() and context_ngrams(): N-gram frequency estimation Use Cases Usage Example histogram_numeric(): Estimating frequency distributions Use Cases Usage Example ngrams() and context_ngrams(): N-gram frequency estimation N-grams are subsequences of length N drawn from a longer sequence.</description></item><item><title>Apache Hive : StatsDev</title><link>https://hive.apache.org/development/desingdocs/statsdev/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/statsdev/</guid><description>Apache Hive : Statistics This document describes the support of statistics for Hive tables (see HIVE-33).
Apache Hive : Statistics Motivation Scope Table and Partition Statistics Column Statistics Top K Statistics Quick overview Implementation Usage Configuration Variables Newly Created Tables Existing Tables – ANALYZE Examples ANALYZE TABLE &amp;lt;table1&amp;gt; CACHE METADATA Current Status (JIRA) Motivation Statistics such as the number of rows of a table or partition and the histograms of a particular interesting column are important in many ways.</description></item><item><title>Apache Hive : Storage API Release Proposal</title><link>https://hive.apache.org/development/desingdocs/storage-api-release-proposal/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/storage-api-release-proposal/</guid><description>Apache Hive : Storage API Release Proposal To enable faster and more direct integration of file formats like ORC and Parquet, Hive has separated out the Storage API as a distinct subproject and will release it independently of the rest of Hive. The storage-api source code will remain in the Hive git repository. The initial work on the pom files was done in HIVE-15419. The plan is to start the Storage API releases at 2.</description></item><item><title>Apache Hive : Storage Based Authorization in the Metastore Server</title><link>https://hive.apache.org/docs/latest/user/storage-based-authorization-in-the-metastore-server/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/storage-based-authorization-in-the-metastore-server/</guid><description>Apache Hive : Storage Based Authorization in the Metastore Server The metastore server security feature with storage based authorization was added to Hive in release 0.10. This feature was introduced previously in HCatalog.
HIVE-3705 added metastore server security to Hive in release 0.10.0.
For additional information about storage based authorization in the metastore server, see the HCatalog document Storage Based Authorization. For an overview of Hive authorization models and other security options, see the Authorization document.</description></item><item><title>Apache Hive : StorageHandlers</title><link>https://hive.apache.org/development/desingdocs/storagehandlers/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/storagehandlers/</guid><description>Apache Hive : StorageHandlers Hive Storage Handlers Hive Storage Handlers Introduction Terminology DDL Storage Handler Interface HiveMetaHook Interface Open Issues Introduction This page documents the storage handler support being added to Hive as part of work on HBaseIntegration. The motivation is to make it possible to allow Hive to access data stored and managed by other systems in a modular, extensible fashion.
Besides HBase, a storage handler implementation is also available for Hypertable, and others are being developed for Cassandra, Azure Table, JDBC (MySQL and others), MongoDB, ElasticSearch, Phoenix HBase, VoltDB and Google Spreadsheets.</description></item><item><title>Apache Hive : Streaming Data Ingest</title><link>https://hive.apache.org/docs/latest/user/streaming-data-ingest/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/streaming-data-ingest/</guid><description>Apache Hive : Streaming Data Ingest Apache Hive : Streaming Data Ingest Hive 3 Streaming API Hive HCatalog Streaming API Streaming Mutation API Streaming Requirements Limitations API Usage Transaction and Connection Management HiveEndPoint StreamingConnection TransactionBatch Notes about the HiveConf Object I/O – Writing Data RecordWriter DelimitedInputWriter StrictJsonWriter StrictRegexWriter AbstractRecordWriter Error Handling Example – Non-secure Mode Example – Secure Streaming Knowledge Base Hive 3 Streaming API Hive 3 Streaming API Documentation - new API available in Hive 3</description></item><item><title>Apache Hive : Streaming Data Ingest V2</title><link>https://hive.apache.org/docs/latest/user/streaming-data-ingest-v2/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/streaming-data-ingest-v2/</guid><description>Apache Hive : Streaming Data Ingest V2 Starting in release Hive 3.0.0, Streaming Data Ingest is deprecated and is replaced by newer V2 API (HIVE-19205).  Apache Hive : Streaming Data Ingest V2 Hive Streaming API Streaming Mutation API Deprecation and Removal Streaming Requirements Limitations API Usage Transaction and Connection Management HiveStreamingConnection Notes about the HiveConf Object I/O – Writing Data RecordWriter StrictDelimitedInputWriter StrictJsonWriter StrictRegexWriter AbstractRecordWriter Error Handling Example Hive Streaming API Traditionally adding new data into Hive requires gathering a large amount of data onto HDFS and then periodically adding a new partition.</description></item><item><title>Apache Hive : Subqueries in SELECT</title><link>https://hive.apache.org/development/desingdocs/subqueries-in-select/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/subqueries-in-select/</guid><description>Apache Hive : Subqueries in SELECT Problem Currently Hive doesn&amp;rsquo;t support subqueries in a SELECT statement, for example, the following query will not run on Hive:
SELECT customer.customer_num, (SELECT SUM(ship_charge) FROM orders WHERE customer.customer_num = orders.customer_num ) AS total_ship_chg FROM customer Recently a lot of work has been done to extend support for subqueries (HIVE-15456). But this work primarily targeted extending subquery support in WHERE and HAVING clauses. We plan to continue the work done in HIVE-15456 to support subqueries in a select list (see HIVE-16091).</description></item><item><title>Apache Hive : Suggestion for DDL Commands in HMS schema upgrade scripts</title><link>https://hive.apache.org/development/desingdocs/suggestion-for-ddl-commands-in-hms-schema-upgrade-scripts/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/suggestion-for-ddl-commands-in-hms-schema-upgrade-scripts/</guid><description>Apache Hive : Suggestion for DDL Commands in HMS schema upgrade scripts In this page, I would like to share the information I learned from Braintree&amp;rsquo;s Blog about how they handle DB schema migration while application is up and serving requests. I think this should benefits to developer who is working on HMS&amp;rsquo;s schema upgrade scripts. As for some DDL commands, they can lock out updates to a table for a long time and database operation that locks for more than a few seconds is indistinguishable from an outage for customers.</description></item><item><title>Apache Hive : Supported Features: Apache Hive 3.1</title><link>https://hive.apache.org/docs/latest/language/supported-features/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/supported-features/</guid><description>Apache Hive : Supported Features: Apache Hive 3.1 This table covers all mandatory features from SQL:2016 as well as optional features that Hive implements.
Feature ID Feature Name Implemented Mandatory Comments E011 Numeric data types Yes Mandatory E011-01 INTEGER and SMALLINT data types (including all spellings) Yes Mandatory E011-02 REAL, DOUBLE PRECISON, and FLOAT data types Yes Mandatory E011-03 DECIMAL and NUMERIC data types Yes Mandatory E011-04 Arithmetic operators Yes Mandatory E011-05 Numeric comparison Yes Mandatory E011-06 Implicit casting among the numeric data types Yes Mandatory E021 Character string types Yes Mandatory E021-01 CHARACTER data type (including all its spellings) Partial Mandatory Only support CHAR, not CHARACTER E021-02 CHARACTER VARYING data type (including all its spellings) Partial Mandatory Only support VARCHAR, not CHARACTER VARYING or CHAR VARYING E021-03 Character literals Yes Mandatory E021-04 CHARACTER_LENGTH function Yes Mandatory E021-05 OCTET_LENGTH function Yes Mandatory E021-06 SUBSTRING function Partial Mandatory Standard: SUBSTRING(val FROM startpos [FOR len]).</description></item><item><title>Apache Hive : Supported Features: Apache Hive 2.1</title><link>https://hive.apache.org/docs/latest/language/supported-features-apache-hive-2-1/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/supported-features-apache-hive-2-1/</guid><description>Apache Hive : Supported Features: Apache Hive 2.1 Identifier Description Hive 2.1 Comment E011 Numeric data types Yes E011-01 INTEGER and SMALLINT data types (including all spellings) Yes Int instead of Integer E011-02 REAL, DOUBLE PRECISON,and FLOAT data types Yes Double instead of Double Precision E011-03 DECIMAL and NUMERIC data types Yes E011-04 Arithmetic operators Yes E011-05 Numeric comparison Yes E011-06 Implicit casting among the numeric data types Yes E021 Character data types Yes E021-01 CHARACTER data type Yes Char instead of Character E021-02 CHARACTER VARYING data type Yes Varchar instead of Character Varying E021-03 Character literals Yes E021-04 CHARACTER_LENGTH function Partial length UDF provided E021-06 SUBSTRING function Yes E021-07 Character concatenation Yes concat UDF instead of standard E021-08 UPPER and LOWER functions Yes E021-09 TRIM function Partial leading / trailing / both from not supported E021-10 Implicit casting among the fixed-length and variablelength character string types Yes E021-12 Character comparison Yes E031 Identifiers Yes E031-01 Delimited identifiers Partial Backtick (`) used instead of (&amp;quot;).</description></item><item><title>Apache Hive : Supported Features: Apache Hive 2.3</title><link>https://hive.apache.org/docs/latest/language/supported-features-apache-hive-2-3/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/language/supported-features-apache-hive-2-3/</guid><description>Apache Hive : Supported Features: Apache Hive 2.3 Identifier Description Hive 2.3 Comment E011 Numeric data types Yes E011-01 INTEGER and SMALLINT data types (including all spellings) Yes E011-02 REAL, DOUBLE PRECISON,and FLOAT data types Yes E011-03 DECIMAL and NUMERIC data types Yes E011-04 Arithmetic operators Yes E011-05 Numeric comparison Yes E011-06 Implicit casting among the numeric data types Yes E021 Character data types Yes E021-01 CHARACTER data type Yes Char instead of Character E021-02 CHARACTER VARYING data type Yes Varchar instead of Character Varying E021-03 Character literals Yes E021-04 CHARACTER_LENGTH function Yes E021-05 OCTET_LENGTH function Yes E021-06 SUBSTRING function Yes E021-07 Character concatenation Yes E021-08 UPPER and LOWER functions Yes E021-09 TRIM function Partial leading / trailing / both from not supported E021-10 Implicit casting among the fixed-length and variablelength character string types Yes E021-12 Character comparison Yes E031 Identifiers Yes E031-01 Delimited identifiers Yes E031-03 Trailing underscore Yes E051 Basic query specification Yes E051-01 SELECT DISTINCT Yes E051-02 GROUP BY clause Partial Empty grouping sets not supported E051-04 GROUP BY can contain columns not in Yes E051-05 Select list items can be renamed Yes E051-06 HAVING clause Yes E051-07 Qualified * in select list Yes E051-08 Correlation names in the FROM clause Yes E061 Basic predicates and search conditions Yes E061-01 Comparison predicate Yes E061-02 BETWEEN predicate Yes E061-03 IN predicate with list of values Yes E061-04 LIKE predicate Yes E061-06 NULL predicate Yes E061-08 EXISTS predicate Yes E061-09 Subqueries in comparison predicate Yes E061-11 Subqueries in IN predicate Yes E061-13 Correlated subqueries Yes E071 Basic query expressions Yes E071-01 UNION DISTINCT table operator Yes E071-02 UNION ALL table operator Yes E071-03 EXCEPT DISTINCT table operator Yes E071-05 Columns combined via table operators need not have exactly the same data type.</description></item><item><title>Apache Hive : Synchronized Metastore Cache</title><link>https://hive.apache.org/development/desingdocs/synchronized-metastore-cache/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/synchronized-metastore-cache/</guid><description>Apache Hive : Synchronized Metastore Cache Overview This work is to solve the consistency problem if we use HMS HA with metadata cache. Note it does not aim to address any existing consistency issues already exist in non-cached HMS. For example, it won’t fix the transaction semantic between metadata and data. If the problem exists today in non-cached HMS, it stays a problem after this work.
The problem we try to solve here is the cache consistency issue.</description></item><item><title>Apache Hive : TeradataBinarySerde</title><link>https://hive.apache.org/docs/latest/user/teradatabinaryserde/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/teradatabinaryserde/</guid><description>Apache Hive : TeradataBinarySerde Apache Hive : TeradataBinarySerde Availability Overview How to export How to import Usage Availability Earliest version CSVSerde is available
The TeradataBinarySerDe is available in Hive 2.4 or greater.
Overview Teradata can use TPT(Teradata Parallel Transporter) or BTEQ(Basic Teradata Query) to export and import data files compressed by gzip in very high speed. However such binary files are encoded in Teradata’s proprietary format and can’t be directly consumed by Hive without a customized SerDe.</description></item><item><title>Apache Hive : TestingDocs</title><link>https://hive.apache.org/community/resources/testingdocs/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/testingdocs/</guid><description>Apache Hive : TestingDocs Hive Testing Documents The following documents describe aspects of testing for Hive:
Hive Developer FAQ: Testing Developer Guide: Unit Tests Unit Testing Hive SQL Running Yetus MetaStore API Tests Query File Test(qtest)</description></item><item><title>Apache Hive : Theta Join</title><link>https://hive.apache.org/development/desingdocs/theta-join/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/theta-join/</guid><description>Apache Hive : Theta Join Apache Hive : Theta Join Preliminaries Overview Specific Use Cases Requirements Literature Review Map-Reduce-Merge: Simplified Relational Data Processing on Large Clusters [1] Efficient Parallel Set-Similarity Joins Using MapReduce [2] Processing Theta-Joins using MapReduce [3] Efficient Multi-way Theta-Join Processing Using MapReduce [4] Design Map-side Reduce-side References Preliminaries Overview HIVE-556 requests that Hive support non-equality joins commonly called theta joins.</description></item><item><title>Apache Hive : Top K Stats</title><link>https://hive.apache.org/development/desingdocs/top-k-stats/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/top-k-stats/</guid><description>Apache Hive : Column Level Top K Statistics This document is an addition to Statistics in Hive. It describes the support of collecting column level top K values for Hive tables (see HIVE-3421).
Apache Hive : Column Level Top K Statistics Scope Implementation Usage Example Newly Created Tables Existing Tables Current Status (JIRA) Scope In addition to the partition statistics, column level top K values can also be estimated for Hive tables.</description></item><item><title>Apache Hive : Transitivity on predicate pushdown</title><link>https://hive.apache.org/docs/latest/user/transitivity-on-predicate-pushdown/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/transitivity-on-predicate-pushdown/</guid><description>Apache Hive : Transitivity on predicate pushdown Before Hive 0.8.0, the query
set hive.mapred.mode=strict; create table invites (foo int, bar string) partitioned by (ds string); create table invites2 (foo int, bar string) partitioned by (ds string); select count(*) from invites join invites2 on invites.ds=invites2.ds where invites.ds='2011-01-01'; would give the error
Error in semantic analysis: No Partition Predicate Found for Alias &amp;quot;invites2&amp;quot; Table &amp;quot;invites2&amp;quot; Here, the filter is applied to the table invites as invites.</description></item><item><title>Apache Hive : Tutorial</title><link>https://hive.apache.org/docs/latest/user/tutorial/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/tutorial/</guid><description>Apache Hive : Tutorial Apache Hive : Tutorial Concepts What Is Hive What Hive Is NOT Getting Started Data Units Type System Primitive Types Complex Types Timestamp Built In Operators and Functions Built In Operators Built In Functions Language Capabilities Usage and Examples Creating, Showing, Altering, and Dropping Tables Creating Tables Browsing Tables and Partitions Altering Tables Dropping Tables and Partitions Loading Data HIVE-5999 HIVE-11996 Querying and Inserting Data Simple Query Partition Based Query Joins Aggregations Multi Table/File Inserts Dynamic-Partition Insert Inserting into Local Files Sampling Union All Array Operations Map (Associative Arrays) Operations Custom Map/Reduce Scripts Co-Groups Concepts What Is Hive Hive is a data warehousing infrastructure based on Apache Hadoop.</description></item><item><title>Apache Hive : Type Qualifiers in Hive</title><link>https://hive.apache.org/development/desingdocs/type-qualifiers-in-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/type-qualifiers-in-hive/</guid><description>Apache Hive : Type Qualifiers in Hive Intro Hive will need to support some kind of type qualifiers/parameters in its type metadata to be able to enforce type features such as decimal precision/scale or char/varchar length and collation. This involves changes to the PrimitiveTypeEntry/TypeInfo/ObjectInspectors, possibly metastore changes,
My impression is that the actual enforcement of the type qualifiers should be done by the ObjectInspectors/Converters/casts operations. It should be ok to do col * col when col is a decimal(2) value of 99, it would fail if you try to cast the result to decimal(2) or try to insert it to a decimal(2) column.</description></item><item><title>Apache Hive : Union Optimization</title><link>https://hive.apache.org/docs/latest/user/union-optimization/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/union-optimization/</guid><description>Apache Hive : Union Optimization Consider the query
select * from
(subq1
UNION ALL
sub2) u;
If the parents to union were map reduce jobs, they will write the output to temporary files. The Union will then read the rows from these temporary files and write to a final directory. In effect, the results are read and written twice unnecessarily. We can avoid this by directly writing to the final directory.</description></item><item><title>Apache Hive : Unit Testing Hive SQL</title><link>https://hive.apache.org/community/resources/unit-testing-hive-sql/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/community/resources/unit-testing-hive-sql/</guid><description>Apache Hive : Unit Testing Hive SQL Apache Hive : Unit Testing Hive SQL Motivations Challenges Modularisation Encapsulation of column level logic Encapsulation of set level logic Tools and frameworks Useful practices Relevant issues Other Hive unit testing concerns Motivations Hive is widely applied as a solution to numerous distinct problem types in the domain of big data. Quite clearly it is often used for the ad hoc querying of large datasets.</description></item><item><title>Apache Hive : UpdatableViews</title><link>https://hive.apache.org/development/desingdocs/updatableviews/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/updatableviews/</guid><description>Apache Hive : UpdatableViews Proposal Hive will consider a view updatable if:
The view refers to exactly one base table or updatable view in the FROM clause without a WHERE clause. Each column in the view is a column in the underlying table/updatable view with no underlying columns duplicated. Views must have the same partition columns as the underlying table/updatable view. When inserting into a view:
If a view does not specify all underlying columns, NULL will be inserted for each column not specified.</description></item><item><title>Apache Hive : User and Group Filter Support with LDAP Atn Provider in HiveServer2</title><link>https://hive.apache.org/docs/latest/admin/user-and-group-filter-support-with-ldap-atn-provider-in-hiveserver2/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/admin/user-and-group-filter-support-with-ldap-atn-provider-in-hiveserver2/</guid><description>Apache Hive : User and Group Filter Support with LDAP Atn Provider in HiveServer2 Apache Hive : User and Group Filter Support with LDAP Atn Provider in HiveServer2 User and Group Filter Support with LDAP Group Membership User Search List Custom Query String Order of Precedence User and Group Filter Support with LDAP Starting in Hive 1.3.0, HIVE-7193 adds support in HiveServer2 for</description></item><item><title>Apache Hive : User FAQ</title><link>https://hive.apache.org/docs/latest/user/user-faq/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/user-faq/</guid><description>Apache Hive : User FAQ Apache Hive : User FAQ General I see errors like: Server access Error: Connection timed out url=http://archive.apache.org/dist/hadoop/core/hadoop-0.20.1/hadoop-0.20.1.tar.gz How to change the warehouse.dir location for older tables? When running a JOIN query, I see out-of-memory errors. I am using MySQL as metastore and I see errors: &amp;ldquo;com.mysql.jdbc.exceptions.jdbc4.!CommunicationsException: Communications link failure&amp;rdquo; Does Hive support Unicode? Hive SQL Are Hive SQL identifiers (e.</description></item><item><title>Apache Hive : Using TiDB as the Hive Metastore database</title><link>https://hive.apache.org/docs/latest/user/using-tidb-as-the-hive-metastore-database/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/user/using-tidb-as-the-hive-metastore-database/</guid><description>Apache Hive : Using TiDB as the Hive Metastore database Apache Hive : Using TiDB as the Hive Metastore database Why use TiDB in Hive as the Metastore database? How to create a Hive cluster with TiDB Components required Install a Hive cluster Step 1: Deploy a TiDB cluster Step 2: Configure Hive Step 3: Initialize metadata Step 4: Launch Metastore and test Conclusion FAQ Why use TiDB in Hive as the Metastore database?</description></item><item><title>Apache Hive : Vectorized Query Execution</title><link>https://hive.apache.org/development/desingdocs/vectorized-query-execution/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/vectorized-query-execution/</guid><description>Apache Hive : Vectorized Query Execution Apache Hive : Vectorized Query Execution Introduction Using Vectorized Query Execution Enabling vectorized execution Supported data types and operations Seeing whether vectorization is used for a query Limitations Version Information Introduction Vectorized query execution is a Hive feature that greatly reduces the CPU usage for typical query operations like scans, filters, aggregates, and joins. A standard query execution system processes one row at a time.</description></item><item><title>Apache Hive : ViewDev</title><link>https://hive.apache.org/development/desingdocs/viewdev/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/development/desingdocs/viewdev/</guid><description>Apache Hive : Views Apache Hive : Views Use Cases Scope Syntax Implementation Sketch Issues Stored View Definition Metastore Modeling Dependency Tracking Dependency Invalidation View Modification Fast Path Execution ORDER BY and LIMIT in view definition Underlying Partition Dependencies Metastore Upgrades Automatic ALTER TABLE Explicit ALTER TABLE Existing Row UPDATE Use Cases Views (http://issues.apache.org/jira/browse/HIVE-972) are a standard DBMS feature and their uses are well understood.</description></item><item><title>Apache Hive : WebHCat</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-base/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-base/</guid><description>Apache Hive : WebHCat This is the manual for WebHCat, previously known as Templeton. WebHCat is the REST API for HCatalog, a table and storage management layer for Hadoop.  Using WebHCat Installation Configuration Reference See the HCatalog Manual for general HCatalog documentation.
Navigation Links Next: Using WebHCat</description></item><item><title>Apache Hive : WebHCat Configure</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-configure/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-configure/</guid><description>Apache Hive : WebHCat Configure Apache Hive : WebHCat Configure Configuration Files Configuration Variables Configuration Files The configuration for WebHCat (Templeton) merges the normal Hadoop configuration with the WebHCat-specific variables. Because WebHCat is designed to connect services that are not normally connected, the configuration is more complex than might be desirable.
The WebHCat-specific configuration is split into two layers:</description></item><item><title>Apache Hive : WebHCat InstallWebHCat</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-installwebhcat/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-installwebhcat/</guid><description>Apache Hive : WebHCat Installation Apache Hive : WebHCat Installation WebHCat Installed with Hive WebHCat Installation Procedure Server Commands Requirements Hadoop Distributed Cache Permissions Secure Cluster Proxy User Support WebHCat Installed with Hive WebHCat and HCatalog are installed with Hive, starting with Hive release 0.11.0.
If you install Hive from the binary tarball, the WebHCat server command webhcat_server.sh is in the hcatalog/sbin directory.</description></item><item><title>Apache Hive : WebHCat Reference</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference/</guid><description>Apache Hive : WebHCat Reference Reference: WebHCat Resources This overview page lists all of the WebHCat resources. (DDL resources are listed here and on another overview page. For information about HCatalog DDL commands, see HCatalog DDL. For information about Hive DDL commands, see Hive Data Definition Language.)
  Category Resource (Type) Description General :version (GET) Return a list of supported response types.   status (GET) Return the WebHCat server status.</description></item><item><title>Apache Hive : WebHCat Reference AllDDL</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-allddl/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-allddl/</guid><description>Apache Hive : WebHCat Reference AllDDL WebHCat Reference: DDL Resources This is an overview page for the WebHCat DDL resources. The full list of WebHCat resources is on this overview page.
For information about HCatalog DDL commands, see HCatalog DDL. For information about Hive DDL commands, see Hive Data Definition Language. Object Resource (Type) Description DDL Command ddl (POST) Perform an HCatalog DDL command.</description></item><item><title>Apache Hive : WebHCat Reference DDL</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-ddl/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-ddl/</guid><description>Apache Hive : WebHCat Reference DDL Apache Hive : WebHCat Reference DDL Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description Performs an HCatalog DDL command. The command is executed immediately upon request. Responses are limited to 1 MB. For requests which may return longer results consider using the Hive resource as an alternative.
URL http://www.myserver.com/templeton/ddl</description></item><item><title>Apache Hive : WebHCat Reference DeleteDB</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-deletedb/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-deletedb/</guid><description>Apache Hive : WebHCat Reference DeleteDB Apache Hive : WebHCat Reference DeleteDB Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description Delete a database.
URL http://www.myserver.com/templeton/v1/ddl/database/:db
Parameters Name Description Required? Default :db The database name Required None ifExists Hive returns an error if the database specified does not exist, unless ifExists is set to true.</description></item><item><title>Apache Hive : WebHCat Reference DeleteJob</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-deletejob/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-deletejob/</guid><description>Apache Hive : WebHCat Reference DeleteJob Apache Hive : WebHCat Reference DeleteJob Description URL Parameters Results Example Curl Command JSON Output Description Kill a job given its job ID. Substitute &amp;ldquo;:jobid&amp;rdquo; with the job ID received when the job was created.
Version: Deprecated in 0.12.0
DELETE queue/:jobid is deprecated starting in Hive release 0.12.0. Users are encouraged to use DELETE jobs/:jobid instead.</description></item><item><title>Apache Hive : WebHCat Reference DeleteJobID</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-deletejobid/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-deletejobid/</guid><description>Apache Hive : WebHCat Reference DeleteJobID Apache Hive : WebHCat Reference DeleteJobID Description URL Parameters Results Example Curl Command JSON Output Description Kill a job given its job ID. Substitute &amp;ldquo;:jobid&amp;rdquo; with the job ID received when the job was created.
Version: Hive 0.12.0 and later
DELETE jobs/:jobid is introduced in Hive release 0.12.0. It is equivalent to [DELETE queue/:jobid](https://hive.apache.org/docs/latest/webhcat/webhcat-reference-deletejob/) in prior releases.</description></item><item><title>Apache Hive : WebHCat Reference DeletePartition</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-deletepartition/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-deletepartition/</guid><description>Apache Hive : WebHCat Reference DeletePartition Apache Hive : WebHCat Reference DeletePartition Description URL Parameters Results Example Curl Command JSON Output Description Delete (drop) a partition in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/partition/:partition
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :partition The partition name, col_name=&amp;lsquo;value&amp;rsquo; list.</description></item><item><title>Apache Hive : WebHCat Reference DeleteTable</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-deletetable/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-deletetable/</guid><description>Apache Hive : WebHCat Reference DeleteTable Apache Hive : WebHCat Reference DeleteTable Description URL Parameters Results Example Curl Command JSON Output Description Delete (drop) an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None ifExists Hive 0.70 and later returns an error if the table specified does not exist, unless ifExists is set to true.</description></item><item><title>Apache Hive : WebHCat Reference GetColumn</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getcolumn/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getcolumn/</guid><description>Apache Hive : WebHCat Reference GetColumn Apache Hive : WebHCat Reference GetColumn Description URL Parameters Results Example Curl Command JSON Output Description Describe a single column in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/column/:column
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :column The column name Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetColumns</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getcolumns/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getcolumns/</guid><description>Apache Hive : WebHCat Reference GetColumns Apache Hive : WebHCat Reference GetColumns Description URL Parameters Results Example Curl Command JSON Output Description List the columns in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/column
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetDB</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getdb/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getdb/</guid><description>Apache Hive : WebHCat Reference GetDB Apache Hive : WebHCat Reference GetDB Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description Describe a database. (Note: This resource has a &amp;ldquo;format=extended&amp;rdquo; parameter however the output structure does not change if it is used.)
URL http://www.myserver.com/templeton/v1/ddl/database/:db
Parameters Name Description Required? Default :db The database name Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetDBs</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getdbs/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getdbs/</guid><description>Apache Hive : WebHCat Reference GetDBs Apache Hive : WebHCat Reference GetDBs Description URL Parameters Results Example Curl Command JSON Output Description List the databases in HCatalog.
URL http://www.myserver.com/templeton/v1/ddl/database
Parameters Name Description Required? Default like List only databases whose names match the specified pattern. Optional &amp;ldquo;*&amp;rdquo; (List all) The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetPartition</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getpartition/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getpartition/</guid><description>Apache Hive : WebHCat Reference GetPartition Apache Hive : WebHCat Reference GetPartition Description URL Parameters Results Example Curl Command JSON Output Description Describe a single partition in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/partition/:partition
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :partition The partition name, col_name=&amp;lsquo;value&amp;rsquo; list.</description></item><item><title>Apache Hive : WebHCat Reference GetPartitions</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getpartitions/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getpartitions/</guid><description>Apache Hive : WebHCat Reference GetPartitions Apache Hive : WebHCat Reference GetPartitions Description URL Parameters Results Example Curl Command JSON Output Description List all the partitions in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/partition
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetProperties</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getproperties/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getproperties/</guid><description>Apache Hive : WebHCat Reference GetProperties Apache Hive : WebHCat Reference GetProperties Description URL Parameters Results Example Curl Command JSON Output Description List all the properties of an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/property
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetProperty</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getproperty/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-getproperty/</guid><description>Apache Hive : WebHCat Reference GetProperty Apache Hive : WebHCat Reference GetProperty Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description Return the value of a single table property.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/property/:property
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :property The property name Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference GetTable</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-gettable/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-gettable/</guid><description>Apache Hive : WebHCat Reference GetTable Apache Hive : WebHCat Reference GetTable Description URL Parameters Results Example Curl Command (simple) JSON Output (simple) Curl Command (extended) JSON Output (extended) JSON Output (error) Description Describe an HCatalog table. Normally returns a simple list of columns (using &amp;ldquo;desc table&amp;rdquo;), but the extended format will show more information (using &amp;ldquo;show table extended like&amp;rdquo;).</description></item><item><title>Apache Hive : WebHCat Reference GetTables</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-gettables/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-gettables/</guid><description>Apache Hive : WebHCat Reference GetTables Apache Hive : WebHCat Reference GetTables Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description List the tables in an HCatalog database.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table
Parameters Name Description Required? Default :db The database name Required None like List only tables whose names match the specified pattern Optional &amp;ldquo;*&amp;rdquo; (List all tables) The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference Hive</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-hive/</guid><description>Apache Hive : WebHCat Reference Hive Apache Hive : WebHCat Reference Hive Description URL Parameters Results Example Curl Command JSON Output Example Results Description Runs a Hive query or set of commands.
Version: Hive 0.13.0 and later
As of Hive 0.13.0, GET version/hive displays the Hive version used for the query or commands.
URL http://www.myserver.com/templeton/v1/hive
Parameters Name Description Required?</description></item><item><title>Apache Hive : WebHCat Reference Job</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-job/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-job/</guid><description>Apache Hive : WebHCat Reference Job Apache Hive : WebHCat Reference Job Description URL Parameters Results Example Curl Command JSON Output Description Check the status of a job and get related job information given its job ID. Substitute &amp;ldquo;:jobid&amp;rdquo; with the job ID received when the job was created.
Version: Hive 0.12.0 and later
GET jobs/:jobid is introduced in Hive release 0.</description></item><item><title>Apache Hive : WebHCat Reference JobIDs</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-jobids/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-jobids/</guid><description>Apache Hive : WebHCat Reference JobIDs Apache Hive : WebHCat Reference JobIDs Description URL Parameters Results Example Curl Command JSON Output Description Return a list of all job IDs.
Version: Deprecated in 0.12.0
GET queue is deprecated starting in Hive release 0.12.0. (See HIVE-4443.) Users are encouraged to use [GET jobs](https://hive.apache.org/docs/latest/webhcat/webhcat-reference-jobs/) instead.
Version: Obsolete in 0.14.0
GET queue will be removed in Hive release 0.</description></item><item><title>Apache Hive : WebHCat Reference JobInfo</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-jobinfo/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-jobinfo/</guid><description>Apache Hive : WebHCat Reference JobInfo Apache Hive : WebHCat Reference JobInfo Description URL Parameters Results Example Curl Command JSON Output JSON Output (Hive 0.12.0 and later) Description Check the status of a job and get related job information given its job ID. Substitute &amp;ldquo;:jobid&amp;rdquo; with the job ID received when the job was created.
Version: Deprecated in 0.12.0
GET queue/:jobid is deprecated starting in Hive release 0.</description></item><item><title>Apache Hive : WebHCat Reference Jobs</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-jobs/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-jobs/</guid><description>Apache Hive : WebHCat Reference Jobs Apache Hive : WebHCat Reference Jobs Description URL Parameters Results Examples Curl Command JSON Output Curl Command (showall) JSON Output (showall) Curl Command (fields) JSON Output (fields) Description Return a list of all job IDs.
Version: Hive 0.12.0 and later
GET jobs is introduced in Hive release 0.12.0. It is equivalent to [GET queue](https://hive.apache.org/docs/latest/webhcat/webhcat-reference-jobids/) in prior releases.</description></item><item><title>Apache Hive : WebHCat Reference MapReduceJar</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-mapreducejar/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-mapreducejar/</guid><description>Apache Hive : WebHCat Reference MapReduceJar Apache Hive : WebHCat Reference MapReduceJar Description URL Parameters Results Example Code and Data Setup Curl Command JSON Output Description Creates and queues a standard Hadoop MapReduce job.
Version: Hive 0.13.0 and later
As of Hive 0.13.0, GET version/hadoop displays the Hadoop version used for the MapReduce job.
URL http://www.myserver.com/templeton/v1/mapreduce/jar
Parameters Name Description Required?</description></item><item><title>Apache Hive : WebHCat Reference MapReduceStream</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-mapreducestream/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-mapreducestream/</guid><description>Apache Hive : WebHCat Reference MapReduceStream Apache Hive : WebHCat Reference MapReduceStream Description URL Parameters Results Example Code and Data Setup Curl Command JSON Output Example Results Description Create and queue a Hadoop streaming MapReduce job.
Version: Hive 0.13.0 and later
As of Hive 0.13.0, GET version/hadoop displays the Hadoop version used for the MapReduce job.
URL http://www.myserver.com/templeton/v1/mapreduce/streaming
Parameters Name Description Required?</description></item><item><title>Apache Hive : WebHCat Reference Pig</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-pig/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-pig/</guid><description>Apache Hive : WebHCat Reference Pig Apache Hive : WebHCat Reference Pig Description URL Parameters Results Example Code and Data Setup Curl Command JSON Output Description Create and queue a Pig job.
URL http://www.myserver.com/templeton/v1/pig
Parameters Name Description Required? Default execute String containing an entire, short Pig program to run. One of either &amp;ldquo;execute&amp;rdquo; or &amp;ldquo;file&amp;rdquo; is required.</description></item><item><title>Apache Hive : WebHCat Reference PostTable</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-posttable/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-posttable/</guid><description>Apache Hive : WebHCat Reference PostTable Apache Hive : WebHCat Reference PostTable Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description Rename an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table
Parameters Name Description Required? Default :db The database name Required None :table The existing (old) table name Required None rename The new table name Required None group The user group to use Optional None permissions The permissions string to use.</description></item><item><title>Apache Hive : WebHCat Reference PutColumn</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-putcolumn/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-putcolumn/</guid><description>Apache Hive : WebHCat Reference PutColumn Apache Hive : WebHCat Reference PutColumn Description URL Parameters Results Example Curl Command JSON Output Description Create a column in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/column/:column
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :column The column name Required None group The user group to use Optional None permissions The permissions string to use Optional None type The type of column to add, like &amp;ldquo;string&amp;rdquo; or &amp;ldquo;int&amp;rdquo; Required None comment The column comment, like a description Optional None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference PutDB</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-putdb/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-putdb/</guid><description>Apache Hive : WebHCat Reference PutDB Apache Hive : WebHCat Reference PutDB Description URL Parameters Results Example Curl Command JSON Output Description Create a database.
URL http://www.myserver.com/templeton/v1/ddl/database/:db
Parameters Name Description Required? Default :db The database name Required None group The user group to use Optional None permissions The permissions string to use Optional None location The database location Optional None comment A comment for the database, like a description Optional None properties The database properties Optional None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference PutPartition</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-putpartition/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-putpartition/</guid><description>Apache Hive : WebHCat Reference PutPartition Apache Hive : WebHCat Reference PutPartition Description URL Parameters Results Example Curl Command JSON Output Description Create a partition in an HCatalog table.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/partition/:partition
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :partition The partition name, col_name=&amp;lsquo;value&amp;rsquo; list.</description></item><item><title>Apache Hive : WebHCat Reference PutProperty</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-putproperty/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-putproperty/</guid><description>Apache Hive : WebHCat Reference PutProperty Apache Hive : WebHCat Reference PutProperty Description URL Parameters Results Example Curl Command JSON Output Description Add a single property on an HCatalog table. This will also reset an existing property.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table/property/:property
Parameters Name Description Required? Default :db The database name Required None :table The table name Required None :property The property name Required None group The user group to use Optional None permissions The permissions string to use Optional None value The property value Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference PutTable</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-puttable/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-puttable/</guid><description>Apache Hive : WebHCat Reference PutTable Apache Hive : WebHCat Reference PutTable Description URL Parameters Results Example Curl Command Curl Command (using clusteredBy) JSON Output JSON Output (error) Description Create a new HCatalog table. For more information, please refer to the Hive documentation for CREATE TABLE.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:table
Parameters Name Description Required? Default :db The database name.</description></item><item><title>Apache Hive : WebHCat Reference PutTableLike</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-puttablelike/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-puttablelike/</guid><description>Apache Hive : WebHCat Reference PutTableLike Apache Hive : WebHCat Reference PutTableLike Description URL Parameters Results Example Curl Command JSON Output Description Create a new HCatalog table like an existing one.
URL http://www.myserver.com/templeton/v1/ddl/database/:db/table/:existingtable/like/:newtable
Parameters Name Description Required? Default :db The database name Required None :existingtable The existing table name Required None :newtable The new table name Required None group The user group to use when creating a table Optional None permissions The permissions string to use when creating a table Optional None external Allows you to specify a location so that Hive does not use the default location for this table.</description></item><item><title>Apache Hive : WebHCat Reference ResponseTypes</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-responsetypes/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-responsetypes/</guid><description>Apache Hive : WebHCat Reference ResponseTypes Apache Hive : WebHCat Reference ResponseTypes Description URL Parameters Results Example Curl Command JSON Output JSON Output (error) Description Returns a list of the response types supported by WebHCat (Templeton).
URL http://www.myserver.com/templeton/:version
Parameters Name Description Required? Default :version The WebHCat version number. (Currently this must be &amp;ldquo;v1&amp;rdquo;.) Required None The standard parameters are also supported.</description></item><item><title>Apache Hive : WebHCat Reference Status</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-status/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-status/</guid><description>Apache Hive : WebHCat Reference Status Apache Hive : WebHCat Reference Status Description URL Parameters Results Example Curl Command JSON Output Description Returns the current status of the WebHCat (Templeton) server. Useful for heartbeat monitoring.
URL http://www.myserver.com/templeton/v1/status
Parameters Only the standard parameters are accepted.
Results Name Description status &amp;ldquo;ok&amp;rdquo; if the WebHCat server was contacted.</description></item><item><title>Apache Hive : WebHCat Reference Version</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-version/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-version/</guid><description>Apache Hive : WebHCat Reference Version Apache Hive : WebHCat Reference Version Description URL Parameters Results Example Curl Command JSON Output Description Returns a list of supported versions and the current version.
URL http://www.myserver.com/templeton/v1/version
Parameters Only the standard parameters are accepted.
Results Name Description supportedVersions A list of all supported versions. version The current version.</description></item><item><title>Apache Hive : WebHCat Reference VersionHadoop</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-versionhadoop/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-versionhadoop/</guid><description>Apache Hive : WebHCat Reference VersionHadoop Apache Hive : WebHCat Reference VersionHadoop Description URL Parameters Results Example Curl Command JSON Output Description Return the version of Hadoop being run when WebHCat creates a MapReduce job (POST mapreduce/jar or mapreduce/streaming).
Version: Hive 0.13.0 and later
GET version/hadoop is introduced in Hive release 0.13.0 (HIVE-6226).
URL http://www.myserver.com/templeton/v1/version/hadoop
Parameters Only the standard parameters are accepted.</description></item><item><title>Apache Hive : WebHCat Reference VersionHive</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-versionhive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-reference-versionhive/</guid><description>Apache Hive : WebHCat Reference VersionHive Apache Hive : WebHCat Reference VersionHive Description URL Parameters Results Example Curl Command JSON Output Description Return the version of Hive being run when WebHCat issues Hive queries or commands (POST hive).
Version: Hive 0.13.0 and later
GET version/hive is introduced in Hive release 0.13.0 (HIVE-6226).
URL http://www.myserver.com/templeton/v1/version/hive
Parameters Only the standard parameters are accepted.</description></item><item><title>Apache Hive : WebHCat UsingWebHCat</title><link>https://hive.apache.org/docs/latest/webhcat/webhcat-usingwebhcat/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/webhcat/webhcat-usingwebhcat/</guid><description>Apache Hive : WebHCat UsingWebHCat Apache Hive : WebHCat UsingWebHCat Version information Introduction to WebHCat URL Format Security Standard Parameters Security Error Response WebHDFS and Code Push Error Codes and Responses Log Files Project Name Attachments: Version information The HCatalog project graduated from the Apache incubator and merged with the Hive project on March 26, 2013.
Hive version 0.11.0 is the first release that includes HCatalog and its REST API, WebHCat.</description></item><item><title>Hive 4.0 - Overview of Major Changes</title><link>https://hive.apache.org/docs/latest/overview-of-major-changes/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/overview-of-major-changes/</guid><description>Hive 4.0 - Overview of Major Changes Iceberg Integration Advanced Snapshot management Branches &amp;amp; Tags support DML (insert/update/delete/merge) COW &amp;amp; MOR modes Vectorised Reads &amp;amp; Writes Table migration command LOAD DATA statements support Partition-level operations support Improved statistics (column stats support) Hive ACID Use sequences for TXN_ID generation (performance) Read-only transactions optimization Zero-wait readers Optimistic and Pessimistic concurrency control Lockless reads Compaction Rebalance compaction (Hive ACID) Compaction requests prioritization (compaction pooling) Iceberg compaction (Major) Hive Metastore API optimization (performance) Dynamic leader election External data sources support HMS support for Thrift over HTTP JWT authentication for Thrift over HTTP HMS metadata summary Use Zookeeper for service discovery HiveServer2 Support SAML 2.</description></item><item><title>Introduction to Apache Hive</title><link>https://hive.apache.org/docs/latest/introduction-to-apache-hive/</link><pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><guid>https://hive.apache.org/docs/latest/introduction-to-apache-hive/</guid><description>The Apache Hive™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage and queried using SQL syntax.
Built on top of Apache Hadoop™, Hive provides the following features:
Tools to enable easy access to data via SQL, thus enabling data warehousing tasks such as extract/transform/load (ETL), reporting, and data analysis. A mechanism to impose structure on a variety of data formats Access to files stored either directly in Apache HDFS™ or in other data storage systems such as Apache HBase™ Query execution via Apache Tez™ or MapReduce Procedural language with HPL-SQL Sub-second query retrieval via Hive LLAP, Apache YARN and Apache Slider.</description></item><item><title>QuickStarted</title><link>https://hive.apache.org/development/quickstart/</link><pubDate>Fri, 12 May 2023 17:51:06 +0530</pubDate><guid>https://hive.apache.org/development/quickstart/</guid><description>Introduction Run Apache Hive inside docker container in pseudo-distributed mode, inorder to provide the following Quick-start/Debugging/Prepare a test env for Hive
Quickstart STEP 1: Pull the image Pull the image from DockerHub: https://hub.docker.com/r/apache/hive/tags. Here are the latest images: 4.0.0 3.1.3 docker pull apache/hive:4.0.0
STEP 2: Export the Hive version export HIVE_VERSION=4.0.0
STEP 3: Launch the HiveServer2 with an embedded Metastore.</description></item><item><title>Getting Started</title><link>https://hive.apache.org/development/gettingstarted/</link><pubDate>Tue, 10 Jan 2023 12:35:11 +0530</pubDate><guid>https://hive.apache.org/development/gettingstarted/</guid><description>The Apache Hive ™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage. A command line tool and JDBC driver are provided to connect users to Hive.
Getting Started With Apache Hive Software Check out the Getting Started Guide. Learn more About Hive&amp;rsquo;s Functionality. Read the Getting Started Guide to learn how to install Hive The User and Hive SQL documentation shows how to program Hive Quick start with Docker Checkout the quickstart with Docker here: DOCKER_QUICKSTART</description></item><item><title>People</title><link>https://hive.apache.org/community/people/</link><pubDate>Wed, 14 Sep 2022 01:23:03 +0530</pubDate><guid>https://hive.apache.org/community/people/</guid><description>People Apache Hive is a community developed project. The list below is a partial list of contributors to the project, for a complete list you would have to look at all contributors to our issue tracker, mailing list and version control.
Hive PMC Apache username Name Organization Role aihuaxu Aihua Xu Cloudera anishek Anishek Agarwal athusoo Ashish Thusoo Qubole ayushsaxena Ayush Saxena Cloudera brock Brock Noland StreamSets ctang Chaoyu Tang Cloudera cws Carl Steinbach LinkedIn denys Denys Kuzmenko Cloudera daijy Daniel Dai Hortonworks ecapriolo Edward Capriolo gopalv Gopal Vijayaraghavan Hortonworks gunther Gunther Hagleitner Hortonworks hashutosh Ashutosh Chauhan Hortonworks heyongqiang Yongqiang He Dropbox jcamacho Jesus Camacho Rodriguez Hortonworks jdere Jason Dere Hortonworks jpullokk Laljo John Pullokkaran Hortonworks jssarma Joydeep Sensarma Qubole jxiang Jimmy Xiang Cloudera kevinwilfong Kevin Wilfong Facebook leftyl Lefty Leverenz IBM namit Namit Jain Nutanix navis Navis Ryu NexR ngangam Naveen Gangam Cloudera VP nzhang Ning Zhang Facebook omalley Owen O&amp;rsquo;Malley LinkedIn prasadm Prasad Mujumdar Cloudera prasanth_j Prasanth Jayachandran Hortonworks pvary Peter Vary Cloudera pxiong Pengcheng Xiong Hortonworks rhbutani Harish Butani Hortonworks rmurthy Raghotham Murthy Facebook sershe Sergey Shelukhin Hortonworks spena Sergio Peña Cloudera sunchao Chao Sun Cloudera szehon Szehon Ho Cloudera thejas Thejas Nair Hortonworks vgumashta Vaibhav Gumashta Hortonworks vikram Vikram Dixit Hortonworks xuefu Xuefu Zhang Alibaba Inc ychena Yongzhi Chen Cloudera zabetak Stamatis Zampetakis Cloudera zhangbutao Butao Zhang China Mobile Hive Committers Apache username name organization amareshwari Amareshwari Sriramadasu InMobi apivovarov Alexander Pivovarov Foster City Hadoop Lab LLC asherman Andrew Sherman Cloudera ayushsaxena Ayush Saxena Cloudera bharos92 Bharath Krishna Cloudera chengxiang Chengxiang Li Intel chinnaraol Chinna Rao Lalam Intel cdrome Chris Drome Oath difin Dmitriy Fingerman Cloudera djaiswal Deepak Jaiswal Hortonworks dmtolpeko Dmitry Tolpeko EPAM dongc Dong Chen Intel ehans Eric Hanson Microsoft gangtimliu Gang Tim Liu Facebook harisankar Hari Sankar Sivarama Subramaniyan Hortonworks janaki Janaki Lahorani Cloudera jitendra Jitendra Pandey Hortonworks kgyrtkirk Zoltan Haindrich Hortonworks kuczoram Marta Kuczora Cloudera larsfrancke Lars Francke Freelancer mithun Mithun Radhakrishnan Oath mmccline Matt McCline Hortonworks mohits Mohit Sabharwal Cloudera okumin Shohei Okumiya Treasure Data rbalamohan Rajesh Balamohan Hortonworks remusr Remus Rusanu Hortonworks sankarh Sankar Hariappan Hortonworks sbadhya Sourabh Badhya Cloudera sdong Siying Dong Facebook simhadrig Simhadri Govindappa sseth Siddharth Seth Hortonworks szita Adam Szita Cloudera tchoi Teddy Choi Hortonworks vgarg Vineet Garg Hortonworks weiz Wei Zheng Hortonworks xuf Ferdinand Xu Intel yhuai Yin Huai Databricks PMC members are also Hive committers.</description></item><item><title>Issue Tracking</title><link>https://hive.apache.org/community/issuetracking/</link><pubDate>Wed, 14 Sep 2022 01:05:14 +0530</pubDate><guid>https://hive.apache.org/community/issuetracking/</guid><description>Issue Tracking Hive tracks both bugs and enhancement requests using Apache JIRA. We welcome input, however, before filing a request, please make sure you do the following:
Search the JIRA database. Check the user mailing list, both by searching the archives and by asking questions.</description></item><item><title>Mailing Lists</title><link>https://hive.apache.org/community/mailinglists/</link><pubDate>Wed, 14 Sep 2022 01:01:04 +0530</pubDate><guid>https://hive.apache.org/community/mailinglists/</guid><description>Mailing Lists We welcome you to join our mailing lists and let us know about your thoughts or ideas about Hive.
User Mailing List The user list is for general discussion or questions on using Hive. Hive developers monitor this list and provide assistance when needed.
Subscribe: user-subscribe@hive.apache.org Post: user@hive.apache.org Unsubscribe: user-unsubscribe@hive.apache.org Archives: Apache Developer Mailing List The developer list is for Hive developers to discuss ongoing work, make decisions, and vote on technical issues.</description></item><item><title>Version Control</title><link>https://hive.apache.org/development/versioncontrol/</link><pubDate>Wed, 14 Sep 2022 00:34:39 +0530</pubDate><guid>https://hive.apache.org/development/versioncontrol/</guid><description>Version Control The Hive source code resides in Apache&amp;rsquo;s Hive GitHub
Anonymous clone via http - https://github.com/apache/hive.git Authenticated clone via ssh - git@github.com:apache/hive.git Instructions: Apache committer git instructions</description></item><item><title>Privacy Policy</title><link>https://hive.apache.org/general/privacypolicy/</link><pubDate>Tue, 13 Sep 2022 19:35:56 +0530</pubDate><guid>https://hive.apache.org/general/privacypolicy/</guid><description>Privacy Policy Information about your use of this website is collected using server access logs and a tracking cookie. The collected information consists of the following:
The IP address from which you access the website; The type of browser and operating system you use to access our site; The date and time you access our site; The pages you visit; and The addresses of pages from where you followed a link to our site.</description></item><item><title>Downloads</title><link>https://hive.apache.org/general/downloads/</link><pubDate>Tue, 13 Sep 2022 19:16:15 +0530</pubDate><guid>https://hive.apache.org/general/downloads/</guid><description>Downloads All recent supported releases may be downloaded from Apache mirrors: Download a release now! Old releases can be found in the archives.
News 31 July 2025: release 4.1.0 available Apache Hive 4.1.x adds JDK 17 support and provides the Hive Metastore as a standalone component available in both binary and Docker image formats. Key improvements include enhanced Iceberg table support (storage-partitioned joins, partition-level column statistics, table compaction), IPv6 compatibility, a REST-based catalog server backed by the Hive Metastore, and upgraded Calcite to 1.</description></item><item><title>Javadocs</title><link>https://hive.apache.org/docs/javadocs/</link><pubDate>Mon, 29 Aug 2022 04:01:38 +0530</pubDate><guid>https://hive.apache.org/docs/javadocs/</guid><description>Recent versions: javadoc and sources jars for use in an IDE are also available via Nexus Hive 4.1.0 Javadocs Hive 4.0.1 Javadocs Hive 4.0.0 Javadocs Hive 4.0.0-beta-1 Javadocs Hive 4.0.0-alpha-2 Javadocs Hive 3.1.3 Javadocs Hive 4.0.0-alpha-1 Javadocs Hive 3.1.2 Javadocs Hive 3.0.0 Javadocs Hive 2.3.9 Javadocs Hive 2.2.0 Javadocs Hive 2.1.1 Javadocs Hive 1.2.2 Javadocs</description></item></channel></rss>